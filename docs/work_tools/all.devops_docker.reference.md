

<!-- toc -->

- [Code organization](#code-organization)

<!-- tocstop -->

# Code organization

- A repo or directory is "runnable" if it can build a Docker container and run
  its code inside the container
  - E.g., `//helpers`, `//amp`, `//orange`, `optimizer`
- Each directory that is runnable contains the files:
  - `changelog.txt`: store the changelog
  - `devops`: dir with all the Docker files needed to build and run a container

- There are several types of `devops` dirs
  - A `devops` where a container is built, run, and released
    - E.g., `//amp`, `//helpers`, `//optimizer`, `//sports_analytics`,
      `//tutorials`, `//demo`
  - A `devops` where a container from a different dir is run
    - E.g., `//orange` reuses `cmamp` container

## Devops to build, run, release a container

- An example of the `devops` structure is:
  ```
  > cd //amp
  > tree.sh -p devops
  devops/
  |-- compose/
  |   `-- __init__.py
  |-- debug/
  |   `-- repo_compare.sh*
  |-- docker_build/
  |   |-- create_users.sh*
  |   |-- dev.Dockerfile
  |   |-- etc_sudoers
  |   |-- fstab
  |   |-- install_cprofile.sh
  |   |-- install_dind.sh*
  |   |-- install_jupyter_extensions.sh*
  |   |-- install_os_packages.sh*
  |   |-- install_python_packages.sh*
  |   |-- poetry.lock
  |   |-- poetry.toml
  |   |-- prod.Dockerfile
  |   `-- pyproject.toml
  |-- docker_run/
  |   |-- aws_credentials.sh
  |   |-- bashrc
  |   |-- entrypoint.sh*
  |   |-- run_jupyter_server.sh*
  |   |-- setenv.sh
  |   `-- test_setup.sh*
  |-- env/
  |   `-- default.env
  |-- notebooks/
  ...
  |-- test/
  ...
  `-- __init__.py
  ```

- The organization of a `devops` dir is:
  - `compose`: Docker compose files
  - `docker_build`: everything related to building a Docker image
  - `docker_run`: everything related to running a Docker image
  - `env`: Docker env files

- Optional dirs are:
  - `debug`: scripts to debug and maintain the dir
  - `notebooks`: notebooks used to analyze, monitor Docker container
    - E.g., `Master_buildmeister_dashboard.ipynb`
  - `test`: everything needed to test a Docker image

## Detailed description of files
- In `devops/compose/`
    - `devops/compose/docker-compose.yml`: file generated by the `invoke` system
      based on templates, to run a Docker compose

- In `devops/docker_build/`
  - `create_users.sh`: create the needed users inside the container
  - `dev.Dockerfile`: Dockerfile to build the dev version of the container
  - `etc_sudoers`: give sudo permission to all users inside the container
  - `fstab`: mount S3 and other dir in the container
    - TODO(gp): Not sure if it's needed anymore
  - `install_cprofile.sh`: install the packages needed to profile Python code
    inside the repo
  - `install_dind.sh`: install docker-in-docker
    - This workflow has been superseded by Docker sibling approach
  - `install_jupyter_extensions.sh`: install Jupyter
  - `install_os_packages.sh`: install the OS packages
  - `install_python_packages.sh`: install the Python packages with `poetry` and
    `pip`
  - `poetry.lock`: file generated by `poetry` after the list of packages has been
    generated
    - This tracks what packages were installed by `poetry`
  - `poetry.toml`: configuration file for `poetry`
  - `prod.Dockerfile`: Dockerfile to build the prod version of the container
  - `pyproject.toml`: list of package specification for `poetry`

- In `devops/docker_run/`
  - `aws_credentials.sh`: loads the AWS credentials in the corresponding env vars
    - TODO(gp): This seems useless
  - `bashrc`: basic configuration for bash shells inside a container
  - `entrypoint.sh`: configures the container on startup
    - E.g., run `setenv.sh`, start dind, setup Git to run inside the container
  - `run_jupyter_server.sh`: start Jupyter notebook
  - `setenv.sh`: configure the virtual environment inside the container
    - E.g., update `$PATH` and `$PYTHONPATH`
    - This is equivalent to `setenv.sh` for the thin environment
  - `test_setup.sh`: check that the major systems are configured properly
    - E.g., `AWS`, `gspread`, ...
    - TODO(gp): Probably obsolete

- In `env/`
  - `default.env`: set some variables and their defaults
    - TODO(gp): This seems useless

## Devops to run an already existing container

- To reuse a Docker container from a different dir / repo, `devops` doesn't need
  the `docker_build` dir
  ```bash
  > tree.sh -p devops
  devops/
  |-- debug/
  |   `-- repo_compare.sh*
  |-- docker_build/
  |   `-- prod.Dockerfile -> ../../amp/devops/docker_build/prod.Dockerfile
  |-- docker_run/
  |   |-- aws_credentials.sh
  ...
  `-- env/
      `-- default.env
  ```

# Docker invoke flow

## `docker_bash`

- When `invoke docker_bash` is called, it generates a Docker compose command line like:
  ```
  > IMAGE=623860924167.dkr.ecr.eu-north-1.amazonaws.com/sports_analytics:dev \
      docker compose \
        --file /Users/saggese/src/sports_analytics1/devops/compose/docker-compose.yml \
        --env-file devops/env/default.env \
        run \
        --rm \
        --name saggese.sports_analytics.app.sports_analytics1.20240817_113504 \
        --user $(id -u):$(id -g) \
        app \
        bash
  ```

- The Docker compose file is generated programmatically based on the command line
  options
  ```
  version: '3'

  services:
    base_app:
      cap_add:
        - SYS_ADMIN
      environment:
        - AM_AWS_ACCESS_KEY_ID=$AM_AWS_ACCESS_KEY_ID
        ...
        - AM_ENABLE_DIND=0
        - AM_FORCE_TEST_FAIL=$AM_FORCE_TEST_FAIL
        - AM_HOST_NAME=gpmac.local
        - AM_HOST_OS_NAME=Darwin
        - AM_HOST_USER_NAME=saggese
        - AM_HOST_VERSION=22.3.0
        - AM_REPO_CONFIG_CHECK=True
        # Use inferred path for `repo_config.py`.
        - AM_REPO_CONFIG_PATH=
        - AM_TELEGRAM_TOKEN=$AM_TELEGRAM_TOKEN
        ...
        - CK_TELEGRAM_TOKEN=$CK_TELEGRAM_TOKEN
        # TODO(Vlad): consider removing, locally we use our personal tokens from files and
        # inside GitHub actions we use the `GH_TOKEN` environment variable.
        - GH_ACTION_ACCESS_TOKEN=$GH_ACTION_ACCESS_TOKEN
        # Inside GitHub Actions we use `GH_TOKEN` environment variable,
        # see https://cli.github.com/manual/gh_auth_login.
        - GH_TOKEN=$GH_ACTION_ACCESS_TOKEN
        # This env var is used by GH Action to signal that we are inside the CI.
        - CI=$CI
      image: ${IMAGE}

      restart: "no"
      volumes:
        # TODO(gp): We should pass the value of $HOME from dev.Dockerfile to here.
        # E.g., we might define $HOME in the env file.
        - ~/.aws:/home/.aws
        - ~/.config/gspread_pandas/:/home/.config/gspread_pandas/
        - ~/.config/gh:/home/.config/gh

        # Use sibling-container approach.
        - /var/run/docker.sock:/var/run/docker.sock

    # Mount `amp` when it is used as supermodule.
    app:
      extends:
        base_app
      volumes:
        - ../../:/app

    linter:
      extends:
        base_app
      volumes:
        - /Users/saggese/src/sports_analytics1:/src
        - ../../:/app
      working_dir: /src
      environment:
        - MYPYPATH

    jupyter_server:
      command: devops/docker_run/run_jupyter_server.sh
      environment:
        - PORT=${PORT}
      extends:
        app
      network_mode: ${NETWORK_MODE:-bridge}
      ports:
        # TODO(gp): Rename `AM_PORT`.
        - "${PORT}:${PORT}"

    jupyter_server_test:
      command: jupyter notebook -h 2>&1 >/dev/null
      environment:
        - PORT=${PORT}
      extends:
        app
      network_mode: ${NETWORK_MODE:-bridge}
      ports:
        - "${PORT}:${PORT}"

  networks:
    default:
      name: main_network
  ```

## `docker_jupyter`

- This invokes a different service
- To disable vim go to Settings -> Enable Vim Mode
- We use the percent format for Jupytext
