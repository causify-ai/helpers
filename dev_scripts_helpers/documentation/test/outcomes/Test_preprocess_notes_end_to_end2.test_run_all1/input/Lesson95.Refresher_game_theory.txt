::: columns
:::: {.column width=15%}
![](lectures_source/UMD_Logo.png)
::::
:::: {.column width=75%}

\vspace{0.4cm}
\begingroup \large
MSML610: Advanced Machine Learning
\endgroup
::::
:::

\vspace{1cm}

\begingroup \Large
**$$\text{\blue{Game Theory}}$$**
\endgroup
\vspace{1cm}

**Instructor**: Dr. GP Saggese - `gsaggese@umd.edu`

**References**:

- AIMA 5: Adversarial search and game theory
- AIMA 18: Multiagent decision making

# Game theory

* Normal Form Games
- Representation of games using a payoff matrix
- Players choose strategies simultaneously
- Used to study strategic interactions
- Example: Prisoner’s Dilemma

* Extensive Form Games
- Game represented as a tree with sequential moves
- Captures order of play, decisions, and information
- Includes concepts like subgames and information sets
- Used in modeling turn-based interactions (e.g., poker)

* Pure and Mixed Strategies
- Pure strategy: deterministic choice
- Mixed strategy: probability distribution over actions
- Mixed strategies allow randomization and increase flexibility
- Mixed strategies are crucial in achieving equilibrium in some games

* Nash Equilibrium
- A set of strategies where no player has an incentive to deviate
- Can be in pure or mixed strategies
- Existence guaranteed (in mixed strategies) by Nash's theorem
- Central concept in game theory

* Dominant and Dominated Strategies
- A strategy dominates another if it always yields better payoff
- Dominated strategies are never rational to play
- Iterated elimination of dominated strategies simplifies games

* Best Response and Reaction Functions
- Best response: strategy that maximizes a player’s payoff given others’ strategies
- Nash equilibrium occurs where all players play best responses
- Used to derive and analyze equilibria

* Zero-Sum Games
- One player’s gain is another player’s loss
- Payoffs satisfy $u_1 = -u_2$
- Solvable using minimax theorem
- Important in adversarial ML (e.g., GANs)

* Minimax Theorem
- In zero-sum games: $\min_{\pi_1} \max_{\pi_2} u = \max_{\pi_2} \min_{\pi_1} u$
- Players choose strategies to minimize their maximum possible loss
- Foundation for robust optimization and adversarial training

* Correlated Equilibrium
- Players coordinate using a shared signal
- Generalization of Nash equilibrium
- Can lead to better outcomes than Nash equilibrium
- Enables learning equilibria via no-regret algorithms

* Bayesian Games
- Games with incomplete information
- Players have private types and beliefs
- Strategies depend on beliefs about others
- Relevant to modeling uncertainty in ML

* Evolutionary Game Theory
- Studies dynamics of strategy changes in populations
- Focuses on replicator dynamics and evolutionarily stable strategies (ESS)
- Used in multi-agent learning and biology-inspired algorithms

* Repeated Games
- Same game played multiple times
- History of play influences future actions
- Cooperation can emerge (e.g., tit-for-tat)
- Important for modeling long-term interaction

* Stochastic Games
- Generalization of repeated games with state transitions
- Combines game theory with Markov decision processes (MDPs)
- Used in reinforcement learning and dynamic competition

* Mechanism Design
- Inverse game theory: design rules to achieve desired outcomes
- Ensures incentive compatibility and individual rationality
- Applied in auctions, resource allocation, and blockchain systems

* Auction Theory
- Study of bidding strategies and auction formats
- Types: first-price, second-price (Vickrey), all-pay, etc.
- Truthful bidding is optimal in second-price auctions
- Used in online ad auctions and marketplaces

* Potential Games
- Games with a potential function aligning with player incentives
- Any change in individual utility reflects a global change
- Facilitates convergence to equilibrium via learning

* Learning in Games
- Fictitious play, regret minimization, Q-learning in multi-agent settings
- Focus on convergence to equilibrium through repeated interaction
- No-regret algorithms converge to correlated equilibria

* Multi-Agent Reinforcement Learning (MARL)
- Agents learn by interacting with other learning agents
- Combines RL with game-theoretic reasoning
- Challenges: non-stationarity, exploration, coordination

* Cooperative Game Theory
- Focuses on group outcomes and coalition formation
- Concepts: core, Shapley value, bargaining
- Useful in team-based ML and federated learning

* Social Choice and Voting
- Aggregation of individual preferences into a collective decision
- Arrow’s impossibility theorem: no perfect voting system exists
- Relevant in ensemble methods and preference aggregation

## Connections between Machine Learning and Game Theory
