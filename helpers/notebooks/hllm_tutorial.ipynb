{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTENTS:\n",
    "- [Description](#description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='description'></a>\n",
    "# Description\n",
    "\n",
    "This notebook examines ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo /bin/bash -c \"(source /venv/bin/activate; pip install --quiet jupyterlab-vim)\"\n",
    "#!jupyter labextension enable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T18:11:14.828251Z",
     "start_time": "2021-04-02T18:11:14.514771Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "\n",
    "import helpers.hdbg as hdbg\n",
    "import helpers.henv as henv\n",
    "import helpers.hprint as hprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T18:11:24.635995Z",
     "start_time": "2021-04-02T18:11:18.239237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# System signature\n",
      "  # Container version\n",
      "    container_version='1.2.0'\n",
      "    changelog_version='2.0.0'\n",
      "  # Git info\n",
      "    branch_name='CmampTask11862_Allow_dind_unit_tests_to_run_on_server_and_CI'\n",
      "    hash='0ca93d8c'\n",
      "    # Last commits:\n",
      "      *   0ca93d8c GP Saggese Merge                                                             ( 5 minutes ago) Fri May 9 22:09:03 2025  (HEAD -> CmampTask11862_Allow_dind_unit_tests_to_run_on_server_and_CI, origin/CmampTask11862_Allow_dind_unit_tests_to_run_on_server_and_CI)\n",
      "      |\\  \n",
      "      * | 99cbbf22 GP Saggese Lint                                                              ( 6 minutes ago) Fri May 9 22:08:07 2025           \n",
      "      | * 27b38c48 GP Saggese CmampTask12067_Read_docs_about_DataPull_4 (#698)                  ( 8 minutes ago) Fri May 9 22:06:25 2025  (origin/master, origin/HEAD, master)\n",
      "  # Platform info\n",
      "    system=Linux\n",
      "    node name=0f79e8b845ee\n",
      "    release=6.10.14-linuxkit\n",
      "    version=#1 SMP Thu Mar 20 16:32:56 UTC 2025\n",
      "    machine=aarch64\n",
      "    processor=aarch64\n",
      "  # psutils info\n",
      "    cpu count=8\n",
      "    cpu freq=None\n",
      "    memory=svmem(total=16749285376, available=14575529984, percent=13.0, used=1910644736, free=9673363456, active=2843516928, inactive=3252117504, buffers=490647552, cached=4674629632, shared=1093632, slab=694362112)\n",
      "    disk usage=sdiskusage(total=270233210880, used=102272610304, free=154199986176, percent=39.9)\n",
      "  # Docker info\n",
      "    has_docker=True\n",
      "    docker_version='28.0.4'\n",
      "    docker_needs_sudo=False\n",
      "    has_privileged_mode=True\n",
      "    is_inside_docker=True\n",
      "    has_docker_sibling_containers_support=True\n",
      "    has_docker_children_containers_support=True\n",
      "  # Packages\n",
      "    python: 3.12.3\n",
      "    cvxopt: ?\n",
      "    cvxpy: ?\n",
      "    gluonnlp: ?\n",
      "    gluonts: ?\n",
      "    joblib: 1.4.2\n",
      "    mxnet: ?\n",
      "    numpy: 2.2.3\n",
      "    pandas: 2.2.3\n",
      "    pyarrow: 19.0.1\n",
      "    scipy: 1.15.2\n",
      "    seaborn: 0.13.2\n",
      "    sklearn: 1.6.1\n",
      "    statsmodels: 0.14.4\n"
     ]
    }
   ],
   "source": [
    "print(henv.get_system_signature()[0])\n",
    "\n",
    "hprint.config_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T18:11:24.668793Z",
     "start_time": "2021-04-02T18:11:24.638503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mWARNING: Running in Jupyter\n",
      "INFO  > cmd='/venv/lib/python3.12/site-packages/ipykernel_launcher.py -f /home/.local/share/jupyter/runtime/kernel-0f2f4a10-7f18-4858-af02-b60808101345.json'\n"
     ]
    }
   ],
   "source": [
    "# hdbg.init_logger(verbosity=logging.DEBUG)\n",
    "hdbg.init_logger(verbosity=logging.INFO)\n",
    "# hdbg.test_logger()\n",
    "_LOG = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo /bin/bash -c \"(source /venv/bin/activate; pip install --quiet openai requests)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers.hllm as hllm\n",
    "import helpers.hpandas as hpandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = hllm.get_model_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'architecture': {'input_modalities': ['text', 'image'],\n",
      "                  'instruct_type': None,\n",
      "                  'modality': 'text+image->text',\n",
      "                  'output_modalities': ['text'],\n",
      "                  'tokenizer': 'Mistral'},\n",
      " 'context_length': 131072,\n",
      " 'created': 1746627341,\n",
      " 'description': 'Mistral Medium 3 is a high-performance enterprise-grade '\n",
      "                'language model designed to deliver frontier-level '\n",
      "                'capabilities at significantly reduced operational cost. It '\n",
      "                'balances state-of-the-art reasoning and multimodal '\n",
      "                'performance with 8× lower cost compared to traditional large '\n",
      "                'models, making it suitable for scalable deployments across '\n",
      "                'professional and industrial use cases.\\n'\n",
      "                '\\n'\n",
      "                'The model excels in domains such as coding, STEM reasoning, '\n",
      "                'and enterprise adaptation. It supports hybrid, on-prem, and '\n",
      "                'in-VPC deployments and is optimized for integration into '\n",
      "                'custom workflows. Mistral Medium 3 offers competitive '\n",
      "                'accuracy relative to larger models like Claude Sonnet '\n",
      "                '3.5/3.7, Llama 4 Maverick, and Command R+, while maintaining '\n",
      "                'broad compatibility across cloud environments.',\n",
      " 'id': 'mistralai/mistral-medium-3',\n",
      " 'name': 'Mistral: Mistral Medium 3',\n",
      " 'per_request_limits': None,\n",
      " 'pricing': {'completion': '0.000002',\n",
      "             'image': '0',\n",
      "             'internal_reasoning': '0',\n",
      "             'prompt': '0.0000004',\n",
      "             'request': '0',\n",
      "             'web_search': '0'},\n",
      " 'supported_parameters': ['tools',\n",
      "                          'tool_choice',\n",
      "                          'max_tokens',\n",
      "                          'temperature',\n",
      "                          'top_p',\n",
      "                          'stop',\n",
      "                          'frequency_penalty',\n",
      "                          'presence_penalty',\n",
      "                          'response_format',\n",
      "                          'structured_outputs',\n",
      "                          'seed'],\n",
      " 'top_provider': {'context_length': 131072,\n",
      "                  'is_moderated': False,\n",
      "                  'max_completion_tokens': None}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>context_length</th>\n",
       "      <th>per_request_limits</th>\n",
       "      <th>supported_parameters</th>\n",
       "      <th>architecture_modality</th>\n",
       "      <th>architecture_input_modalities</th>\n",
       "      <th>architecture_output_modalities</th>\n",
       "      <th>architecture_tokenizer</th>\n",
       "      <th>architecture_instruct_type</th>\n",
       "      <th>pricing_prompt</th>\n",
       "      <th>pricing_completion</th>\n",
       "      <th>pricing_request</th>\n",
       "      <th>pricing_image</th>\n",
       "      <th>pricing_web_search</th>\n",
       "      <th>pricing_internal_reasoning</th>\n",
       "      <th>top_provider_context_length</th>\n",
       "      <th>top_provider_max_completion_tokens</th>\n",
       "      <th>top_provider_is_moderated</th>\n",
       "      <th>pricing_input_cache_read</th>\n",
       "      <th>pricing_input_cache_write</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistralai/mistral-medium-3</td>\n",
       "      <td>Mistral: Mistral Medium 3</td>\n",
       "      <td>1746627341</td>\n",
       "      <td>Mistral Medium 3 is a high-performance enterpr...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google/gemini-2.5-pro-preview</td>\n",
       "      <td>Google: Gemini 2.5 Pro Preview</td>\n",
       "      <td>1746578513</td>\n",
       "      <td>Gemini 2.5 Pro is Google’s state-of-the-art AI...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, tools, tool_c...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000125</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00000031</td>\n",
       "      <td>0.000001625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arcee-ai/caller-large</td>\n",
       "      <td>Arcee AI: Caller Large</td>\n",
       "      <td>1746487869</td>\n",
       "      <td>Caller Large is Arcee's specialist \"function‑c...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000055</td>\n",
       "      <td>0.00000085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arcee-ai/spotlight</td>\n",
       "      <td>Arcee AI: Spotlight</td>\n",
       "      <td>1746481552</td>\n",
       "      <td>Spotlight is a 7‑billion‑parameter vision‑lang...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000018</td>\n",
       "      <td>0.00000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>65537.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arcee-ai/maestro-reasoning</td>\n",
       "      <td>Arcee AI: Maestro Reasoning</td>\n",
       "      <td>1746481269</td>\n",
       "      <td>Maestro Reasoning is Arcee's flagship analysis...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0.0000033</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arcee-ai/virtuoso-large</td>\n",
       "      <td>Arcee AI: Virtuoso Large</td>\n",
       "      <td>1746478885</td>\n",
       "      <td>Virtuoso‑Large is Arcee's top‑tier general‑pur...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000075</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arcee-ai/coder-large</td>\n",
       "      <td>Arcee AI: Coder Large</td>\n",
       "      <td>1746478663</td>\n",
       "      <td>Coder‑Large is a 32 B‑parameter offspring of Q...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arcee-ai/virtuoso-medium-v2</td>\n",
       "      <td>Arcee AI: Virtuoso Medium V2</td>\n",
       "      <td>1746478434</td>\n",
       "      <td>Virtuoso‑Medium‑v2 is a 32 B model distilled f...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arcee-ai/arcee-blitz</td>\n",
       "      <td>Arcee AI: Arcee Blitz</td>\n",
       "      <td>1746470100</td>\n",
       "      <td>Arcee Blitz is a 24 B‑parameter dense model di...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000045</td>\n",
       "      <td>0.00000075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>microsoft/phi-4-reasoning-plus:free</td>\n",
       "      <td>Microsoft: Phi 4 Reasoning Plus (free)</td>\n",
       "      <td>1746130961</td>\n",
       "      <td>Phi-4-reasoning-plus is an enhanced 14B parame...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>microsoft/phi-4-reasoning-plus</td>\n",
       "      <td>Microsoft: Phi 4 Reasoning Plus</td>\n",
       "      <td>1746130961</td>\n",
       "      <td>Phi-4-reasoning-plus is an enhanced 14B parame...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000007</td>\n",
       "      <td>0.00000035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>microsoft/phi-4-reasoning:free</td>\n",
       "      <td>Microsoft: Phi 4 Reasoning (free)</td>\n",
       "      <td>1746121275</td>\n",
       "      <td>Phi-4-reasoning is a 14B parameter dense decod...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>qwen/qwen3-0.6b-04-28:free</td>\n",
       "      <td>Qwen: Qwen3 0.6B (free)</td>\n",
       "      <td>1746043526</td>\n",
       "      <td>Qwen3-0.6B is a lightweight, 0.6 billion param...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>inception/mercury-coder-small-beta</td>\n",
       "      <td>Inception: Mercury Coder Small Beta</td>\n",
       "      <td>1746033880</td>\n",
       "      <td>Mercury Coder Small is the first diffusion lar...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, frequency_penalty, presence_penal...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qwen/qwen3-1.7b:free</td>\n",
       "      <td>Qwen: Qwen3 1.7B (free)</td>\n",
       "      <td>1746031388</td>\n",
       "      <td>Qwen3-1.7B is a compact, 1.7 billion parameter...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>qwen/qwen3-4b:free</td>\n",
       "      <td>Qwen: Qwen3 4B (free)</td>\n",
       "      <td>1746031104</td>\n",
       "      <td>Qwen3-4B is a 4 billion parameter dense langua...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>opengvlab/internvl3-14b:free</td>\n",
       "      <td>OpenGVLab: InternVL3 14B (free)</td>\n",
       "      <td>1746021355</td>\n",
       "      <td>The 14b version of the InternVL3 series. An ad...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p]</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>opengvlab/internvl3-2b:free</td>\n",
       "      <td>OpenGVLab: InternVL3 2B (free)</td>\n",
       "      <td>1746019807</td>\n",
       "      <td>The 2b version of the InternVL3 series, for an...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p]</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deepseek/deepseek-prover-v2:free</td>\n",
       "      <td>DeepSeek: DeepSeek Prover V2 (free)</td>\n",
       "      <td>1746013094</td>\n",
       "      <td>DeepSeek Prover V2 is a 671B parameter model, ...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>deepseek/deepseek-prover-v2</td>\n",
       "      <td>DeepSeek: DeepSeek Prover V2</td>\n",
       "      <td>1746013094</td>\n",
       "      <td>DeepSeek Prover V2 is a 671B parameter model, ...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.00000218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>meta-llama/llama-guard-4-12b</td>\n",
       "      <td>Meta: Llama Guard 4 12B</td>\n",
       "      <td>1745975193</td>\n",
       "      <td>Llama Guard 4 is a Llama 4 Scout-derived multi...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qwen/qwen3-30b-a3b:free</td>\n",
       "      <td>Qwen: Qwen3 30B A3B (free)</td>\n",
       "      <td>1745878604</td>\n",
       "      <td>Qwen3, the latest generation in the Qwen large...</td>\n",
       "      <td>40960</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qwen/qwen3-30b-a3b</td>\n",
       "      <td>Qwen: Qwen3 30B A3B</td>\n",
       "      <td>1745878604</td>\n",
       "      <td>Qwen3, the latest generation in the Qwen large...</td>\n",
       "      <td>40960</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qwen/qwen3-8b:free</td>\n",
       "      <td>Qwen: Qwen3 8B (free)</td>\n",
       "      <td>1745876632</td>\n",
       "      <td>Qwen3-8B is a dense 8.2B parameter causal lang...</td>\n",
       "      <td>40960</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qwen/qwen3-8b</td>\n",
       "      <td>Qwen: Qwen3 8B</td>\n",
       "      <td>1745876632</td>\n",
       "      <td>Qwen3-8B is a dense 8.2B parameter causal lang...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000035</td>\n",
       "      <td>0.000000138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qwen/qwen3-14b:free</td>\n",
       "      <td>Qwen: Qwen3 14B (free)</td>\n",
       "      <td>1745876478</td>\n",
       "      <td>Qwen3-14B is a dense 14.8B parameter causal la...</td>\n",
       "      <td>40960</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>qwen/qwen3-14b</td>\n",
       "      <td>Qwen: Qwen3 14B</td>\n",
       "      <td>1745876478</td>\n",
       "      <td>Qwen3-14B is a dense 14.8B parameter causal la...</td>\n",
       "      <td>40960</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000007</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>qwen/qwen3-32b:free</td>\n",
       "      <td>Qwen: Qwen3 32B (free)</td>\n",
       "      <td>1745875945</td>\n",
       "      <td>Qwen3-32B is a dense 32.8B parameter causal la...</td>\n",
       "      <td>40960</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>Qwen: Qwen3 32B</td>\n",
       "      <td>1745875945</td>\n",
       "      <td>Qwen3-32B is a dense 32.8B parameter causal la...</td>\n",
       "      <td>40960</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>qwen/qwen3-235b-a22b:free</td>\n",
       "      <td>Qwen: Qwen3 235B A22B (free)</td>\n",
       "      <td>1745875757</td>\n",
       "      <td>Qwen3-235B-A22B is a 235B parameter mixture-of...</td>\n",
       "      <td>40960</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>qwen/qwen3-235b-a22b</td>\n",
       "      <td>Qwen: Qwen3 235B A22B</td>\n",
       "      <td>1745875757</td>\n",
       "      <td>Qwen3-235B-A22B is a 235B parameter mixture-of...</td>\n",
       "      <td>40960</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000014</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tngtech/deepseek-r1t-chimera:free</td>\n",
       "      <td>TNG: DeepSeek R1T Chimera (free)</td>\n",
       "      <td>1745760875</td>\n",
       "      <td>DeepSeek-R1T-Chimera is created by merging Dee...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>thudm/glm-z1-rumination-32b</td>\n",
       "      <td>THUDM: GLM Z1 Rumination 32B</td>\n",
       "      <td>1745601495</td>\n",
       "      <td>THUDM: GLM Z1 Rumination 32B is a 32B-paramete...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>thudm/glm-z1-9b:free</td>\n",
       "      <td>THUDM: GLM Z1 9B (free)</td>\n",
       "      <td>1745601140</td>\n",
       "      <td>GLM-Z1-9B-0414 is a 9B-parameter language mode...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>thudm/glm-4-9b:free</td>\n",
       "      <td>THUDM: GLM 4 9B (free)</td>\n",
       "      <td>1745601023</td>\n",
       "      <td>GLM-4-9B-0414 is a 9 billion parameter languag...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>microsoft/mai-ds-r1:free</td>\n",
       "      <td>Microsoft: MAI DS R1 (free)</td>\n",
       "      <td>1745194100</td>\n",
       "      <td>MAI-DS-R1 is a post-trained variant of DeepSee...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>thudm/glm-z1-32b:free</td>\n",
       "      <td>THUDM: GLM Z1 32B (free)</td>\n",
       "      <td>1744924148</td>\n",
       "      <td>GLM-Z1-32B-0414 is an enhanced reasoning varia...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>thudm/glm-z1-32b</td>\n",
       "      <td>THUDM: GLM Z1 32B</td>\n",
       "      <td>1744924148</td>\n",
       "      <td>GLM-Z1-32B-0414 is an enhanced reasoning varia...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>thudm/glm-4-32b:free</td>\n",
       "      <td>THUDM: GLM 4 32B (free)</td>\n",
       "      <td>1744920915</td>\n",
       "      <td>GLM-4-32B-0414 is a 32B bilingual (Chinese-Eng...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>thudm/glm-4-32b</td>\n",
       "      <td>THUDM: GLM 4 32B</td>\n",
       "      <td>1744920915</td>\n",
       "      <td>GLM-4-32B-0414 is a 32B bilingual (Chinese-Eng...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>google/gemini-2.5-flash-preview</td>\n",
       "      <td>Google: Gemini 2.5 Flash Preview</td>\n",
       "      <td>1744914667</td>\n",
       "      <td>Gemini 2.5 Flash is Google's state-of-the-art ...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, tools, tool_c...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0006192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000000375</td>\n",
       "      <td>0.0000002333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>google/gemini-2.5-flash-preview:thinking</td>\n",
       "      <td>Google: Gemini 2.5 Flash Preview (thinking)</td>\n",
       "      <td>1744914667</td>\n",
       "      <td>Gemini 2.5 Flash is Google's state-of-the-art ...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, tools, tool_c...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0006192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000000375</td>\n",
       "      <td>0.0000002333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>openai/o4-mini-high</td>\n",
       "      <td>OpenAI: o4 Mini High</td>\n",
       "      <td>1744824212</td>\n",
       "      <td>OpenAI o4-mini-high is the same model as [o4-m...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, seed, max_tokens, respons...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0008415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000275</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>openai/o3</td>\n",
       "      <td>OpenAI: o3</td>\n",
       "      <td>1744823457</td>\n",
       "      <td>o3 is a well-rounded and powerful model across...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, seed, max_tokens, respons...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>OpenAI: o4 Mini</td>\n",
       "      <td>1744820942</td>\n",
       "      <td>OpenAI o4-mini is a compact reasoning model in...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, seed, max_tokens, respons...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0008415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000275</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>shisa-ai/shisa-v2-llama3.3-70b:free</td>\n",
       "      <td>Shisa AI: Shisa V2 Llama 3.3 70B  (free)</td>\n",
       "      <td>1744754858</td>\n",
       "      <td>Shisa V2 Llama 3.3 70B is a bilingual Japanese...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>qwen/qwen2.5-coder-7b-instruct</td>\n",
       "      <td>Qwen: Qwen2.5 Coder 7B Instruct</td>\n",
       "      <td>1744734887</td>\n",
       "      <td>Qwen2.5-Coder-7B-Instruct is a 7B parameter in...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000001</td>\n",
       "      <td>0.00000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>openai/gpt-4.1</td>\n",
       "      <td>OpenAI: GPT-4.1</td>\n",
       "      <td>1744651385</td>\n",
       "      <td>GPT-4.1 is a flagship large language model opt...</td>\n",
       "      <td>1047576</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1047576.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>openai/gpt-4.1-mini</td>\n",
       "      <td>OpenAI: GPT-4.1 Mini</td>\n",
       "      <td>1744651381</td>\n",
       "      <td>GPT-4.1 Mini is a mid-sized model delivering p...</td>\n",
       "      <td>1047576</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0.0000016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1047576.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>openai/gpt-4.1-nano</td>\n",
       "      <td>OpenAI: GPT-4.1 Nano</td>\n",
       "      <td>1744651369</td>\n",
       "      <td>For tasks that demand low latency, GPT‑4.1 nan...</td>\n",
       "      <td>1047576</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1047576.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>eleutherai/llemma_7b</td>\n",
       "      <td>EleutherAI: Llemma 7b</td>\n",
       "      <td>1744643225</td>\n",
       "      <td>Llemma 7B is a language model for mathematics....</td>\n",
       "      <td>4096</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>code-llama</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>alfredpros/codellama-7b-instruct-solidity</td>\n",
       "      <td>AlfredPros: CodeLLaMa 7B Instruct Solidity</td>\n",
       "      <td>1744641874</td>\n",
       "      <td>A finetuned 7 billion parameters Code LLaMA - ...</td>\n",
       "      <td>4096</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>alpaca</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>arliai/qwq-32b-arliai-rpr-v1:free</td>\n",
       "      <td>ArliAI: QwQ 32B RpR v1 (free)</td>\n",
       "      <td>1744555982</td>\n",
       "      <td>QwQ-32B-ArliAI-RpR-v1 is a 32B parameter model...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>agentica-org/deepcoder-14b-preview:free</td>\n",
       "      <td>Agentica: Deepcoder 14B Preview (free)</td>\n",
       "      <td>1744555395</td>\n",
       "      <td>DeepCoder-14B-Preview is a 14B parameter code ...</td>\n",
       "      <td>96000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>moonshotai/kimi-vl-a3b-thinking:free</td>\n",
       "      <td>Moonshot AI: Kimi VL A3B Thinking (free)</td>\n",
       "      <td>1744304841</td>\n",
       "      <td>Kimi-VL is a lightweight Mixture-of-Experts vi...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[image, text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>xAI: Grok 3 Mini Beta</td>\n",
       "      <td>1744240195</td>\n",
       "      <td>Grok 3 Mini is a lightweight, smaller thinking...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Grok</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>x-ai/grok-3-beta</td>\n",
       "      <td>xAI: Grok 3 Beta</td>\n",
       "      <td>1744240068</td>\n",
       "      <td>Grok 3 is the latest model from xAI. It's thei...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Grok</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>nvidia/llama-3.3-nemotron-super-49b-v1:free</td>\n",
       "      <td>NVIDIA: Llama 3.3 Nemotron Super 49B v1 (free)</td>\n",
       "      <td>1744119494</td>\n",
       "      <td>Llama-3.3-Nemotron-Super-49B-v1 is a large lan...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>nvidia/llama-3.3-nemotron-super-49b-v1</td>\n",
       "      <td>NVIDIA: Llama 3.3 Nemotron Super 49B v1</td>\n",
       "      <td>1744119494</td>\n",
       "      <td>Llama-3.3-Nemotron-Super-49B-v1 is a large lan...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000013</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>nvidia/llama-3.1-nemotron-ultra-253b-v1:free</td>\n",
       "      <td>NVIDIA: Llama 3.1 Nemotron Ultra 253B v1 (free)</td>\n",
       "      <td>1744115059</td>\n",
       "      <td>Llama-3.1-Nemotron-Ultra-253B-v1 is a large la...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>meta-llama/llama-4-maverick:free</td>\n",
       "      <td>Meta: Llama 4 Maverick (free)</td>\n",
       "      <td>1743881822</td>\n",
       "      <td>Llama 4 Maverick 17B Instruct (128E) is a high...</td>\n",
       "      <td>256000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, structured_ou...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>meta-llama/llama-4-maverick</td>\n",
       "      <td>Meta: Llama 4 Maverick</td>\n",
       "      <td>1743881822</td>\n",
       "      <td>Llama 4 Maverick 17B Instruct (128E) is a high...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000017</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0006684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>meta-llama/llama-4-scout:free</td>\n",
       "      <td>Meta: Llama 4 Scout (free)</td>\n",
       "      <td>1743881519</td>\n",
       "      <td>Llama 4 Scout 17B Instruct (16E) is a mixture-...</td>\n",
       "      <td>512000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, structured_ou...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>meta-llama/llama-4-scout</td>\n",
       "      <td>Meta: Llama 4 Scout</td>\n",
       "      <td>1743881519</td>\n",
       "      <td>Llama 4 Scout 17B Instruct (16E) is a mixture-...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, presence_pena...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000008</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>all-hands/openhands-lm-32b-v0.1</td>\n",
       "      <td>OpenHands LM 32B V0.1</td>\n",
       "      <td>1743613013</td>\n",
       "      <td>OpenHands LM v0.1 is a 32B open-source coding ...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000026</td>\n",
       "      <td>0.0000034</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>mistral/ministral-8b</td>\n",
       "      <td>Mistral: Ministral 8B</td>\n",
       "      <td>1743430021</td>\n",
       "      <td>Ministral 8B is a state-of-the-art language mo...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>deepseek/deepseek-v3-base:free</td>\n",
       "      <td>DeepSeek: DeepSeek V3 Base (free)</td>\n",
       "      <td>1743272023</td>\n",
       "      <td>Note that this is a base model mostly meant fo...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>scb10x/llama3.1-typhoon2-8b-instruct</td>\n",
       "      <td>Typhoon2 8B Instruct</td>\n",
       "      <td>1743196511</td>\n",
       "      <td>Llama3.1-Typhoon2-8B-Instruct is a Thai-Englis...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000018</td>\n",
       "      <td>0.00000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>scb10x/llama3.1-typhoon2-70b-instruct</td>\n",
       "      <td>Typhoon2 70B Instruct</td>\n",
       "      <td>1743196170</td>\n",
       "      <td>Llama3.1-Typhoon2-70B-Instruct is a Thai-Engli...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000088</td>\n",
       "      <td>0.00000088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>allenai/molmo-7b-d:free</td>\n",
       "      <td>AllenAI: Molmo 7B D (free)</td>\n",
       "      <td>1743023247</td>\n",
       "      <td>Molmo is a family of open vision-language mode...</td>\n",
       "      <td>4096</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>bytedance-research/ui-tars-72b:free</td>\n",
       "      <td>Bytedance: UI-TARS 72B  (free)</td>\n",
       "      <td>1743020065</td>\n",
       "      <td>UI-TARS 72B is an open-source multimodal AI mo...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>qwen/qwen2.5-vl-3b-instruct:free</td>\n",
       "      <td>Qwen: Qwen2.5 VL 3B Instruct (free)</td>\n",
       "      <td>1743014573</td>\n",
       "      <td>Qwen2.5 VL 3B is a multimodal LLM from the Qwe...</td>\n",
       "      <td>64000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>google/gemini-2.5-pro-exp-03-25</td>\n",
       "      <td>Google: Gemini 2.5 Pro Experimental</td>\n",
       "      <td>1742922099</td>\n",
       "      <td>Gemini 2.5 Pro is Google’s state-of-the-art AI...</td>\n",
       "      <td>1000000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, tools, tool_c...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>qwen/qwen2.5-vl-32b-instruct:free</td>\n",
       "      <td>Qwen: Qwen2.5 VL 32B Instruct (free)</td>\n",
       "      <td>1742839838</td>\n",
       "      <td>Qwen2.5-VL-32B is a multimodal vision-language...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, seed, respons...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>qwen/qwen2.5-vl-32b-instruct</td>\n",
       "      <td>Qwen: Qwen2.5 VL 32B Instruct</td>\n",
       "      <td>1742839838</td>\n",
       "      <td>Qwen2.5-VL-32B is a multimodal vision-language...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324:free</td>\n",
       "      <td>DeepSeek: DeepSeek V3 0324 (free)</td>\n",
       "      <td>1742824755</td>\n",
       "      <td>DeepSeek V3, a 685B-parameter, mixture-of-expe...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324</td>\n",
       "      <td>DeepSeek: DeepSeek V3 0324</td>\n",
       "      <td>1742824755</td>\n",
       "      <td>DeepSeek V3, a 685B-parameter, mixture-of-expe...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, presence_pena...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.00000088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>featherless/qwerky-72b:free</td>\n",
       "      <td>Qwerky 72B (free)</td>\n",
       "      <td>1742481597</td>\n",
       "      <td>Qwerky-72B is a linear-attention RWKV variant ...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>openai/o1-pro</td>\n",
       "      <td>OpenAI: o1-pro</td>\n",
       "      <td>1742423211</td>\n",
       "      <td>The o1 series of models are trained with reinf...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>mistralai/mistral-small-3.1-24b-instruct:free</td>\n",
       "      <td>Mistral: Mistral Small 3.1 24B (free)</td>\n",
       "      <td>1742238937</td>\n",
       "      <td>Mistral Small 3.1 24B Instruct is an upgraded ...</td>\n",
       "      <td>96000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>mistralai/mistral-small-3.1-24b-instruct</td>\n",
       "      <td>Mistral: Mistral Small 3.1 24B</td>\n",
       "      <td>1742238937</td>\n",
       "      <td>Mistral Small 3.1 24B Instruct is an upgraded ...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, presence_pena...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>open-r1/olympiccoder-32b:free</td>\n",
       "      <td>OlympicCoder 32B (free)</td>\n",
       "      <td>1742077228</td>\n",
       "      <td>OlympicCoder-32B is a high-performing open-sou...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>google/gemma-3-1b-it:free</td>\n",
       "      <td>Google: Gemma 3 1B (free)</td>\n",
       "      <td>1741963556</td>\n",
       "      <td>Gemma 3 1B is the smallest of the new Gemma 3 ...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>google/gemma-3-4b-it:free</td>\n",
       "      <td>Google: Gemma 3 4B (free)</td>\n",
       "      <td>1741905510</td>\n",
       "      <td>Gemma 3 introduces multimodality, supporting v...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>google/gemma-3-4b-it</td>\n",
       "      <td>Google: Gemma 3 4B</td>\n",
       "      <td>1741905510</td>\n",
       "      <td>Gemma 3 introduces multimodality, supporting v...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemma</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>ai21/jamba-1.6-large</td>\n",
       "      <td>AI21: Jamba 1.6 Large</td>\n",
       "      <td>1741905173</td>\n",
       "      <td>AI21 Jamba Large 1.6 is a high-performance hyb...</td>\n",
       "      <td>256000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ai21/jamba-1.6-mini</td>\n",
       "      <td>AI21: Jamba Mini 1.6</td>\n",
       "      <td>1741905171</td>\n",
       "      <td>AI21 Jamba Mini 1.6 is a hybrid foundation mod...</td>\n",
       "      <td>256000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>google/gemma-3-12b-it:free</td>\n",
       "      <td>Google: Gemma 3 12B (free)</td>\n",
       "      <td>1741902625</td>\n",
       "      <td>Gemma 3 introduces multimodality, supporting v...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>google/gemma-3-12b-it</td>\n",
       "      <td>Google: Gemma 3 12B</td>\n",
       "      <td>1741902625</td>\n",
       "      <td>Gemma 3 introduces multimodality, supporting v...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemma</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>cohere/command-a</td>\n",
       "      <td>Cohere: Command A</td>\n",
       "      <td>1741894342</td>\n",
       "      <td>Command A is an open-weights 111B parameter mo...</td>\n",
       "      <td>256000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>openai/gpt-4o-mini-search-preview</td>\n",
       "      <td>OpenAI: GPT-4o-mini Search Preview</td>\n",
       "      <td>1741818122</td>\n",
       "      <td>GPT-4o mini Search Preview is a specialized mo...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[web_search_options, max_tokens, response_form...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>openai/gpt-4o-search-preview</td>\n",
       "      <td>OpenAI: GPT-4o Search Preview</td>\n",
       "      <td>1741817949</td>\n",
       "      <td>GPT-4o Search Previewis a specialized model fo...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[web_search_options, max_tokens, response_form...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>rekaai/reka-flash-3:free</td>\n",
       "      <td>Reka: Flash 3 (free)</td>\n",
       "      <td>1741812813</td>\n",
       "      <td>Reka Flash 3 is a general-purpose, instruction...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>google/gemma-3-27b-it:free</td>\n",
       "      <td>Google: Gemma 3 27B (free)</td>\n",
       "      <td>1741756359</td>\n",
       "      <td>Gemma 3 introduces multimodality, supporting v...</td>\n",
       "      <td>96000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>google/gemma-3-27b-it</td>\n",
       "      <td>Google: Gemma 3 27B</td>\n",
       "      <td>1741756359</td>\n",
       "      <td>Gemma 3 introduces multimodality, supporting v...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemma</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>thedrummer/anubis-pro-105b-v1</td>\n",
       "      <td>TheDrummer: Anubis Pro 105B V1</td>\n",
       "      <td>1741642290</td>\n",
       "      <td>Anubis Pro 105B v1 is an expanded and refined ...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, presence_pena...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>thedrummer/skyfall-36b-v2</td>\n",
       "      <td>TheDrummer: Skyfall 36B V2</td>\n",
       "      <td>1741636566</td>\n",
       "      <td>Skyfall 36B v2 is an enhanced iteration of Mis...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, presence_pena...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>microsoft/phi-4-multimodal-instruct</td>\n",
       "      <td>Microsoft: Phi 4 Multimodal Instruct</td>\n",
       "      <td>1741396284</td>\n",
       "      <td>Phi-4 Multimodal Instruct is a versatile 5.6B ...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00017685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>perplexity/sonar-reasoning-pro</td>\n",
       "      <td>Perplexity: Sonar Reasoning Pro</td>\n",
       "      <td>1741313308</td>\n",
       "      <td>Note: Sonar Pro pricing includes Perplexity se...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>perplexity/sonar-pro</td>\n",
       "      <td>Perplexity: Sonar Pro</td>\n",
       "      <td>1741312423</td>\n",
       "      <td>Note: Sonar Pro pricing includes Perplexity se...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, web_search_op...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>perplexity/sonar-deep-research</td>\n",
       "      <td>Perplexity: Sonar Deep Research</td>\n",
       "      <td>1741311246</td>\n",
       "      <td>Sonar Deep Research is a research-focused mode...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>deepseek/deepseek-r1-zero:free</td>\n",
       "      <td>DeepSeek: DeepSeek R1 Zero (free)</td>\n",
       "      <td>1741297434</td>\n",
       "      <td>DeepSeek-R1-Zero is a model trained via large-...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>qwen/qwq-32b:free</td>\n",
       "      <td>Qwen: QwQ 32B (free)</td>\n",
       "      <td>1741208814</td>\n",
       "      <td>QwQ is the reasoning model of the Qwen series....</td>\n",
       "      <td>40000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>qwq</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>qwen/qwq-32b</td>\n",
       "      <td>Qwen: QwQ 32B</td>\n",
       "      <td>1741208814</td>\n",
       "      <td>QwQ is the reasoning model of the Qwen series....</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>qwq</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>moonshotai/moonlight-16b-a3b-instruct:free</td>\n",
       "      <td>Moonshot AI: Moonlight 16B A3B Instruct (free)</td>\n",
       "      <td>1740719801</td>\n",
       "      <td>Moonlight-16B-A3B-Instruct is a 16B-parameter ...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>nousresearch/deephermes-3-llama-3-8b-preview:free</td>\n",
       "      <td>Nous: DeepHermes 3 Llama 3 8B Preview (free)</td>\n",
       "      <td>1740719372</td>\n",
       "      <td>DeepHermes 3 Preview is the latest version of ...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>openai/gpt-4.5-preview</td>\n",
       "      <td>OpenAI: GPT-4.5 (Preview)</td>\n",
       "      <td>1740687810</td>\n",
       "      <td>GPT-4.5 (Preview) is a research preview of Ope...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>google/gemini-2.0-flash-lite-001</td>\n",
       "      <td>Google: Gemini 2.0 Flash Lite</td>\n",
       "      <td>1740506212</td>\n",
       "      <td>Gemini 2.0 Flash Lite offers a significantly f...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000075</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>anthropic/claude-3.7-sonnet</td>\n",
       "      <td>Anthropic: Claude 3.7 Sonnet</td>\n",
       "      <td>1740422110</td>\n",
       "      <td>Claude 3.7 Sonnet is an advanced large languag...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.00000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>Anthropic: Claude 3.7 Sonnet (thinking)</td>\n",
       "      <td>1740422110</td>\n",
       "      <td>Claude 3.7 Sonnet is an advanced large languag...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.00000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:beta</td>\n",
       "      <td>Anthropic: Claude 3.7 Sonnet (self-moderated)</td>\n",
       "      <td>1740422110</td>\n",
       "      <td>Claude 3.7 Sonnet is an advanced large languag...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, stop, reasoning, inc...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.00000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>perplexity/r1-1776</td>\n",
       "      <td>Perplexity: R1 1776</td>\n",
       "      <td>1740004929</td>\n",
       "      <td>R1 1776 is a version of DeepSeek-R1 that has b...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>mistralai/mistral-saba</td>\n",
       "      <td>Mistral: Saba</td>\n",
       "      <td>1739803239</td>\n",
       "      <td>Mistral Saba is a 24B-parameter language model...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>cognitivecomputations/dolphin3.0-r1-mistral-24...</td>\n",
       "      <td>Dolphin3.0 R1 Mistral 24B (free)</td>\n",
       "      <td>1739462498</td>\n",
       "      <td>Dolphin 3.0 R1 is the next generation of the D...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>cognitivecomputations/dolphin3.0-mistral-24b:free</td>\n",
       "      <td>Dolphin3.0 Mistral 24B (free)</td>\n",
       "      <td>1739462019</td>\n",
       "      <td>Dolphin 3.0 is the next generation of the Dolp...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>meta-llama/llama-guard-3-8b</td>\n",
       "      <td>Llama Guard 3 8B</td>\n",
       "      <td>1739401318</td>\n",
       "      <td>Llama Guard 3 is a Llama-3.1-8B pretrained mod...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>none</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>openai/o3-mini-high</td>\n",
       "      <td>OpenAI: o3 Mini High</td>\n",
       "      <td>1739372611</td>\n",
       "      <td>OpenAI o3-mini-high is the same model as [o3-m...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, seed, max_tokens, respons...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000055</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>deepseek/deepseek-r1-distill-llama-8b</td>\n",
       "      <td>DeepSeek: R1 Distill Llama 8B</td>\n",
       "      <td>1738937718</td>\n",
       "      <td>DeepSeek R1 Distill Llama 8B is a distilled la...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.00000004</td>\n",
       "      <td>0.00000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>google/gemini-2.0-flash-001</td>\n",
       "      <td>Google: Gemini 2.0 Flash</td>\n",
       "      <td>1738769413</td>\n",
       "      <td>Gemini Flash 2.0 offers a significantly faster...</td>\n",
       "      <td>1000000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000025</td>\n",
       "      <td>0.0000001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>qwen/qwen-vl-plus</td>\n",
       "      <td>Qwen: Qwen VL Plus</td>\n",
       "      <td>1738731255</td>\n",
       "      <td>Qwen's Enhanced Large Visual Language Model. S...</td>\n",
       "      <td>7500</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, seed, respons...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000021</td>\n",
       "      <td>0.00000063</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>aion-labs/aion-1.0</td>\n",
       "      <td>AionLabs: Aion-1.0</td>\n",
       "      <td>1738697557</td>\n",
       "      <td>Aion-1.0 is a multi-model system designed for ...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>aion-labs/aion-1.0-mini</td>\n",
       "      <td>AionLabs: Aion-1.0-Mini</td>\n",
       "      <td>1738697107</td>\n",
       "      <td>Aion-1.0-Mini 32B parameter model is a distill...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000007</td>\n",
       "      <td>0.0000014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>aion-labs/aion-rp-llama-3.1-8b</td>\n",
       "      <td>AionLabs: Aion-RP 1.0 (8B)</td>\n",
       "      <td>1738696718</td>\n",
       "      <td>Aion-RP-Llama-3.1-8B ranks the highest in the ...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>qwen/qwen-vl-max</td>\n",
       "      <td>Qwen: Qwen VL Max</td>\n",
       "      <td>1738434304</td>\n",
       "      <td>Qwen VL Max is a visual understanding model wi...</td>\n",
       "      <td>7500</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, seed, respons...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000032</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>qwen/qwen-turbo</td>\n",
       "      <td>Qwen: Qwen-Turbo</td>\n",
       "      <td>1738410974</td>\n",
       "      <td>Qwen-Turbo, based on Qwen2.5, is a 1M context ...</td>\n",
       "      <td>1000000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>qwen/qwen2.5-vl-72b-instruct:free</td>\n",
       "      <td>Qwen: Qwen2.5 VL 72B Instruct (free)</td>\n",
       "      <td>1738410311</td>\n",
       "      <td>Qwen2.5-VL is proficient in recognizing common...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, seed, respons...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>qwen/qwen2.5-vl-72b-instruct</td>\n",
       "      <td>Qwen: Qwen2.5 VL 72B Instruct</td>\n",
       "      <td>1738410311</td>\n",
       "      <td>Qwen2.5-VL is proficient in recognizing common...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.00000075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>qwen/qwen-plus</td>\n",
       "      <td>Qwen: Qwen-Plus</td>\n",
       "      <td>1738409840</td>\n",
       "      <td>Qwen-Plus, based on the Qwen2.5 foundation mod...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>qwen/qwen-max</td>\n",
       "      <td>Qwen: Qwen-Max</td>\n",
       "      <td>1738402289</td>\n",
       "      <td>Qwen-Max, based on Qwen2.5, provides the best ...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000016</td>\n",
       "      <td>0.0000064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>openai/o3-mini</td>\n",
       "      <td>OpenAI: o3 Mini</td>\n",
       "      <td>1738351721</td>\n",
       "      <td>OpenAI o3-mini is a cost-efficient language mo...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, seed, max_tokens, respons...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000055</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>deepseek/deepseek-r1-distill-qwen-1.5b</td>\n",
       "      <td>DeepSeek: R1 Distill Qwen 1.5B</td>\n",
       "      <td>1738328067</td>\n",
       "      <td>DeepSeek R1 Distill Qwen 1.5B is a distilled l...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.00000018</td>\n",
       "      <td>0.00000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>mistralai/mistral-small-24b-instruct-2501:free</td>\n",
       "      <td>Mistral: Mistral Small 3 (free)</td>\n",
       "      <td>1738255409</td>\n",
       "      <td>Mistral Small 3 is a 24B-parameter language mo...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>mistralai/mistral-small-24b-instruct-2501</td>\n",
       "      <td>Mistral: Mistral Small 3</td>\n",
       "      <td>1738255409</td>\n",
       "      <td>Mistral Small 3 is a 24B-parameter language mo...</td>\n",
       "      <td>28000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000006</td>\n",
       "      <td>0.00000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>deepseek/deepseek-r1-distill-qwen-32b:free</td>\n",
       "      <td>DeepSeek: R1 Distill Qwen 32B (free)</td>\n",
       "      <td>1738194830</td>\n",
       "      <td>DeepSeek R1 Distill Qwen 32B is a distilled la...</td>\n",
       "      <td>16000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>deepseek/deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>DeepSeek: R1 Distill Qwen 32B</td>\n",
       "      <td>1738194830</td>\n",
       "      <td>DeepSeek R1 Distill Qwen 32B is a distilled la...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.00000012</td>\n",
       "      <td>0.00000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>deepseek/deepseek-r1-distill-qwen-14b:free</td>\n",
       "      <td>DeepSeek: R1 Distill Qwen 14B (free)</td>\n",
       "      <td>1738193940</td>\n",
       "      <td>DeepSeek R1 Distill Qwen 14B is a distilled la...</td>\n",
       "      <td>64000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>deepseek/deepseek-r1-distill-qwen-14b</td>\n",
       "      <td>DeepSeek: R1 Distill Qwen 14B</td>\n",
       "      <td>1738193940</td>\n",
       "      <td>DeepSeek R1 Distill Qwen 14B is a distilled la...</td>\n",
       "      <td>64000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>perplexity/sonar-reasoning</td>\n",
       "      <td>Perplexity: Sonar Reasoning</td>\n",
       "      <td>1738131107</td>\n",
       "      <td>Sonar Reasoning is a reasoning model provided ...</td>\n",
       "      <td>127000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>perplexity/sonar</td>\n",
       "      <td>Perplexity: Sonar</td>\n",
       "      <td>1738013808</td>\n",
       "      <td>Sonar is lightweight, affordable, fast, and si...</td>\n",
       "      <td>127072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, web_search_op...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>liquid/lfm-7b</td>\n",
       "      <td>Liquid: LFM 7B</td>\n",
       "      <td>1737806883</td>\n",
       "      <td>LFM-7B, a new best-in-class language model. LF...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.00000001</td>\n",
       "      <td>0.00000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>liquid/lfm-3b</td>\n",
       "      <td>Liquid: LFM 3B</td>\n",
       "      <td>1737806501</td>\n",
       "      <td>Liquid's LFM 3B delivers incredible performanc...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>deepseek/deepseek-r1-distill-llama-70b:free</td>\n",
       "      <td>DeepSeek: R1 Distill Llama 70B (free)</td>\n",
       "      <td>1737663169</td>\n",
       "      <td>DeepSeek R1 Distill Llama 70B is a distilled l...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>deepseek/deepseek-r1-distill-llama-70b</td>\n",
       "      <td>DeepSeek: R1 Distill Llama 70B</td>\n",
       "      <td>1737663169</td>\n",
       "      <td>DeepSeek R1 Distill Llama 70B is a distilled l...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>deepseek/deepseek-r1:free</td>\n",
       "      <td>DeepSeek: R1 (free)</td>\n",
       "      <td>1737381095</td>\n",
       "      <td>DeepSeek R1 is here: Performance on par with [...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, reasoning, include_reasoning, tem...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>deepseek/deepseek-r1</td>\n",
       "      <td>DeepSeek: R1</td>\n",
       "      <td>1737381095</td>\n",
       "      <td>DeepSeek R1 is here: Performance on par with [...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, reasoning, in...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.00000218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>minimax/minimax-01</td>\n",
       "      <td>MiniMax: MiniMax-01</td>\n",
       "      <td>1736915462</td>\n",
       "      <td>MiniMax-01 is a combines MiniMax-Text-01 for t...</td>\n",
       "      <td>1000192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p]</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000192.0</td>\n",
       "      <td>1000192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>mistralai/codestral-2501</td>\n",
       "      <td>Mistral: Codestral 2501</td>\n",
       "      <td>1736895522</td>\n",
       "      <td>[Mistral](/mistralai)'s cutting-edge language ...</td>\n",
       "      <td>262144</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>microsoft/phi-4</td>\n",
       "      <td>Microsoft: Phi 4</td>\n",
       "      <td>1736489872</td>\n",
       "      <td>[Microsoft Research](/microsoft) Phi-4 is desi...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000007</td>\n",
       "      <td>0.00000014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>deepseek/deepseek-chat:free</td>\n",
       "      <td>DeepSeek: DeepSeek V3 (free)</td>\n",
       "      <td>1735241320</td>\n",
       "      <td>DeepSeek-V3 is the latest model from the DeepS...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>deepseek/deepseek-chat</td>\n",
       "      <td>DeepSeek: DeepSeek V3</td>\n",
       "      <td>1735241320</td>\n",
       "      <td>DeepSeek-V3 is the latest model from the DeepS...</td>\n",
       "      <td>163840</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000038</td>\n",
       "      <td>0.00000089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>163840.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>sao10k/l3.3-euryale-70b</td>\n",
       "      <td>Sao10K: Llama 3.3 Euryale 70B</td>\n",
       "      <td>1734535928</td>\n",
       "      <td>Euryale L3.3 70B is a model focused on creativ...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.0000007</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>openai/o1</td>\n",
       "      <td>OpenAI: o1</td>\n",
       "      <td>1734459999</td>\n",
       "      <td>The latest and strongest model family from Ope...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, seed, max_tokens, respons...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>eva-unit-01/eva-llama-3.33-70b</td>\n",
       "      <td>EVA Llama 3.33 70B</td>\n",
       "      <td>1734377303</td>\n",
       "      <td>EVA Llama 3.33 70b is a roleplay and storywrit...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>x-ai/grok-2-vision-1212</td>\n",
       "      <td>xAI: Grok 2 Vision 1212</td>\n",
       "      <td>1734237338</td>\n",
       "      <td>Grok 2 Vision 1212 advances image-based AI wit...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Grok</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>x-ai/grok-2-1212</td>\n",
       "      <td>xAI: Grok 2 1212</td>\n",
       "      <td>1734232814</td>\n",
       "      <td>Grok 2 1212 introduces significant enhancement...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Grok</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>cohere/command-r7b-12-2024</td>\n",
       "      <td>Cohere: Command R7B (12-2024)</td>\n",
       "      <td>1734158152</td>\n",
       "      <td>Command R7B (12-2024) is a small, fast update ...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000000375</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>google/gemini-2.0-flash-exp:free</td>\n",
       "      <td>Google: Gemini 2.0 Flash Experimental (free)</td>\n",
       "      <td>1733937523</td>\n",
       "      <td>Gemini Flash 2.0 offers a significantly faster...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop]</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>meta-llama/llama-3.3-70b-instruct:free</td>\n",
       "      <td>Meta: Llama 3.3 70B Instruct (free)</td>\n",
       "      <td>1733506137</td>\n",
       "      <td>The Meta Llama 3.3 multilingual large language...</td>\n",
       "      <td>8000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>meta-llama/llama-3.3-70b-instruct</td>\n",
       "      <td>Meta: Llama 3.3 70B Instruct</td>\n",
       "      <td>1733506137</td>\n",
       "      <td>The Meta Llama 3.3 multilingual large language...</td>\n",
       "      <td>131000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000009</td>\n",
       "      <td>0.00000035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131000.0</td>\n",
       "      <td>131000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>amazon/nova-lite-v1</td>\n",
       "      <td>Amazon: Nova Lite 1.0</td>\n",
       "      <td>1733437363</td>\n",
       "      <td>Amazon Nova Lite 1.0 is a very low-cost multim...</td>\n",
       "      <td>300000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, max_tokens, temperature, top_p, top_k,...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Nova</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000006</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>amazon/nova-micro-v1</td>\n",
       "      <td>Amazon: Nova Micro 1.0</td>\n",
       "      <td>1733437237</td>\n",
       "      <td>Amazon Nova Micro 1.0 is a text-only model tha...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, max_tokens, temperature, top_p, top_k,...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Nova</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000035</td>\n",
       "      <td>0.00000014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>amazon/nova-pro-v1</td>\n",
       "      <td>Amazon: Nova Pro 1.0</td>\n",
       "      <td>1733436303</td>\n",
       "      <td>Amazon Nova Pro 1.0 is a capable multimodal mo...</td>\n",
       "      <td>300000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, max_tokens, temperature, top_p, top_k,...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Nova</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000032</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>qwen/qwq-32b-preview:free</td>\n",
       "      <td>Qwen: QwQ 32B Preview (free)</td>\n",
       "      <td>1732754541</td>\n",
       "      <td>QwQ-32B-Preview is an experimental research mo...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>qwen/qwq-32b-preview</td>\n",
       "      <td>Qwen: QwQ 32B Preview</td>\n",
       "      <td>1732754541</td>\n",
       "      <td>QwQ-32B-Preview is an experimental research mo...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>deepseek-r1</td>\n",
       "      <td>0.00000009</td>\n",
       "      <td>0.00000027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>google/learnlm-1.5-pro-experimental:free</td>\n",
       "      <td>Google: LearnLM 1.5 Pro Experimental (free)</td>\n",
       "      <td>1732216551</td>\n",
       "      <td>An experimental version of [Gemini 1.5 Pro](/g...</td>\n",
       "      <td>40960</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40960.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>eva-unit-01/eva-qwen-2.5-72b</td>\n",
       "      <td>EVA Qwen2.5 72B</td>\n",
       "      <td>1732210606</td>\n",
       "      <td>EVA Qwen2.5 72B is a roleplay and storywriting...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>openai/gpt-4o-2024-11-20</td>\n",
       "      <td>OpenAI: GPT-4o (2024-11-20)</td>\n",
       "      <td>1732127594</td>\n",
       "      <td>The 2024-11-20 version of GPT-4o offers a leve...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>mistralai/mistral-large-2411</td>\n",
       "      <td>Mistral Large 2411</td>\n",
       "      <td>1731978685</td>\n",
       "      <td>Mistral Large 2 2411 is an update of [Mistral ...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>mistralai/mistral-large-2407</td>\n",
       "      <td>Mistral Large 2407</td>\n",
       "      <td>1731978415</td>\n",
       "      <td>This is Mistral AI's flagship model, Mistral L...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>mistralai/pixtral-large-2411</td>\n",
       "      <td>Mistral: Pixtral Large 2411</td>\n",
       "      <td>1731977388</td>\n",
       "      <td>Pixtral Large is a 124B parameter, open-weight...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>x-ai/grok-vision-beta</td>\n",
       "      <td>xAI: Grok Vision Beta</td>\n",
       "      <td>1731976624</td>\n",
       "      <td>Grok Vision Beta is xAI's experimental languag...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Grok</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>infermatic/mn-inferor-12b</td>\n",
       "      <td>Infermatic: Mistral Nemo Inferor 12B</td>\n",
       "      <td>1731464428</td>\n",
       "      <td>Inferor 12B is a merge of top roleplay models,...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>mistral</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>qwen/qwen-2.5-coder-32b-instruct:free</td>\n",
       "      <td>Qwen2.5 Coder 32B Instruct (free)</td>\n",
       "      <td>1731368400</td>\n",
       "      <td>Qwen2.5-Coder is the latest series of Code-Spe...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>qwen/qwen-2.5-coder-32b-instruct</td>\n",
       "      <td>Qwen2.5 Coder 32B Instruct</td>\n",
       "      <td>1731368400</td>\n",
       "      <td>Qwen2.5-Coder is the latest series of Code-Spe...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.00000006</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>raifle/sorcererlm-8x22b</td>\n",
       "      <td>SorcererLM 8x22B</td>\n",
       "      <td>1731105083</td>\n",
       "      <td>SorcererLM is an advanced RP and storytelling ...</td>\n",
       "      <td>16000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>vicuna</td>\n",
       "      <td>0.0000045</td>\n",
       "      <td>0.0000045</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>eva-unit-01/eva-qwen-2.5-32b</td>\n",
       "      <td>EVA Qwen2.5 32B</td>\n",
       "      <td>1731104847</td>\n",
       "      <td>EVA Qwen2.5 32B is a roleplaying/storywriting ...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.0000026</td>\n",
       "      <td>0.0000034</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>thedrummer/unslopnemo-12b</td>\n",
       "      <td>Unslopnemo 12B</td>\n",
       "      <td>1731103448</td>\n",
       "      <td>UnslopNemo v4.1 is the latest addition from th...</td>\n",
       "      <td>32000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>mistral</td>\n",
       "      <td>0.00000045</td>\n",
       "      <td>0.00000045</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>anthropic/claude-3.5-haiku:beta</td>\n",
       "      <td>Anthropic: Claude 3.5 Haiku (self-moderated)</td>\n",
       "      <td>1730678400</td>\n",
       "      <td>Claude 3.5 Haiku features offers enhanced capa...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00000008</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>anthropic/claude-3.5-haiku</td>\n",
       "      <td>Anthropic: Claude 3.5 Haiku</td>\n",
       "      <td>1730678400</td>\n",
       "      <td>Claude 3.5 Haiku features offers enhanced capa...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000008</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>anthropic/claude-3.5-haiku-20241022:beta</td>\n",
       "      <td>Anthropic: Claude 3.5 Haiku (2024-10-22) (self...</td>\n",
       "      <td>1730678400</td>\n",
       "      <td>Claude 3.5 Haiku features enhancements across ...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00000008</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>anthropic/claude-3.5-haiku-20241022</td>\n",
       "      <td>Anthropic: Claude 3.5 Haiku (2024-10-22)</td>\n",
       "      <td>1730678400</td>\n",
       "      <td>Claude 3.5 Haiku features enhancements across ...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000008</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>neversleep/llama-3.1-lumimaid-70b</td>\n",
       "      <td>NeverSleep: Lumimaid v0.2 70B</td>\n",
       "      <td>1729555200</td>\n",
       "      <td>Lumimaid v0.2 70B is a finetune of [Llama 3.1 ...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0.00000225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>anthracite-org/magnum-v4-72b</td>\n",
       "      <td>Magnum v4 72B</td>\n",
       "      <td>1729555200</td>\n",
       "      <td>This is a series of models designed to replica...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0.00000225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>anthropic/claude-3.5-sonnet:beta</td>\n",
       "      <td>Anthropic: Claude 3.5 Sonnet (self-moderated)</td>\n",
       "      <td>1729555200</td>\n",
       "      <td>New Claude 3.5 Sonnet delivers better-than-Opu...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.00000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>anthropic/claude-3.5-sonnet</td>\n",
       "      <td>Anthropic: Claude 3.5 Sonnet</td>\n",
       "      <td>1729555200</td>\n",
       "      <td>New Claude 3.5 Sonnet delivers better-than-Opu...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.00000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>x-ai/grok-beta</td>\n",
       "      <td>xAI: Grok Beta</td>\n",
       "      <td>1729382400</td>\n",
       "      <td>Grok Beta is xAI's experimental language model...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Grok</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>mistralai/ministral-8b</td>\n",
       "      <td>Mistral: Ministral 8B</td>\n",
       "      <td>1729123200</td>\n",
       "      <td>Ministral 8B is an 8B parameter model featurin...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>mistralai/ministral-3b</td>\n",
       "      <td>Mistral: Ministral 3B</td>\n",
       "      <td>1729123200</td>\n",
       "      <td>Ministral 3B is a 3B parameter model optimized...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000004</td>\n",
       "      <td>0.00000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>qwen/qwen-2.5-7b-instruct:free</td>\n",
       "      <td>Qwen2.5 7B Instruct (free)</td>\n",
       "      <td>1729036800</td>\n",
       "      <td>Qwen2.5 7B is the latest series of Qwen large ...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>qwen/qwen-2.5-7b-instruct</td>\n",
       "      <td>Qwen2.5 7B Instruct</td>\n",
       "      <td>1729036800</td>\n",
       "      <td>Qwen2.5 7B is the latest series of Qwen large ...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>nvidia/llama-3.1-nemotron-70b-instruct</td>\n",
       "      <td>NVIDIA: Llama 3.1 Nemotron 70B Instruct</td>\n",
       "      <td>1728950400</td>\n",
       "      <td>NVIDIA's Llama 3.1 Nemotron 70B is a language ...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000012</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>inflection/inflection-3-productivity</td>\n",
       "      <td>Inflection: Inflection 3 Productivity</td>\n",
       "      <td>1728604800</td>\n",
       "      <td>Inflection 3 Productivity is optimized for fol...</td>\n",
       "      <td>8000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>inflection/inflection-3-pi</td>\n",
       "      <td>Inflection: Inflection 3 Pi</td>\n",
       "      <td>1728604800</td>\n",
       "      <td>Inflection 3 Pi powers Inflection's [Pi](https...</td>\n",
       "      <td>8000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>google/gemini-flash-1.5-8b</td>\n",
       "      <td>Google: Gemini 1.5 Flash 8B</td>\n",
       "      <td>1727913600</td>\n",
       "      <td>Gemini Flash 1.5 8B is optimized for speed and...</td>\n",
       "      <td>1000000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000000375</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00000001</td>\n",
       "      <td>0.0000000583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>thedrummer/rocinante-12b</td>\n",
       "      <td>Rocinante 12B</td>\n",
       "      <td>1727654400</td>\n",
       "      <td>Rocinante 12B is designed for engaging storyte...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>anthracite-org/magnum-v2-72b</td>\n",
       "      <td>Magnum v2 72B</td>\n",
       "      <td>1727654400</td>\n",
       "      <td>From the maker of [Goliath](https://openrouter...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>liquid/lfm-40b</td>\n",
       "      <td>Liquid: LFM 40B MoE</td>\n",
       "      <td>1727654400</td>\n",
       "      <td>Liquid's 40.3B Mixture of Experts (MoE) model....</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>meta-llama/llama-3.2-3b-instruct:free</td>\n",
       "      <td>Meta: Llama 3.2 3B Instruct (free)</td>\n",
       "      <td>1727222400</td>\n",
       "      <td>Llama 3.2 3B is a 3-billion-parameter multilin...</td>\n",
       "      <td>20000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>meta-llama/llama-3.2-3b-instruct</td>\n",
       "      <td>Meta: Llama 3.2 3B Instruct</td>\n",
       "      <td>1727222400</td>\n",
       "      <td>Llama 3.2 3B is a 3-billion-parameter multilin...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000001</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>meta-llama/llama-3.2-1b-instruct:free</td>\n",
       "      <td>Meta: Llama 3.2 1B Instruct (free)</td>\n",
       "      <td>1727222400</td>\n",
       "      <td>Llama 3.2 1B is a 1-billion-parameter language...</td>\n",
       "      <td>131000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>meta-llama/llama-3.2-1b-instruct</td>\n",
       "      <td>Meta: Llama 3.2 1B Instruct</td>\n",
       "      <td>1727222400</td>\n",
       "      <td>Llama 3.2 1B is a 1-billion-parameter language...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, top_k, stop, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.000000005</td>\n",
       "      <td>0.00000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>meta-llama/llama-3.2-90b-vision-instruct</td>\n",
       "      <td>Meta: Llama 3.2 90B Vision Instruct</td>\n",
       "      <td>1727222400</td>\n",
       "      <td>The Llama 90B Vision model is a top-tier, 90-b...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>meta-llama/llama-3.2-11b-vision-instruct:free</td>\n",
       "      <td>Meta: Llama 3.2 11B Vision Instruct (free)</td>\n",
       "      <td>1727222400</td>\n",
       "      <td>Llama 3.2 11B Vision is a multimodal model wit...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>meta-llama/llama-3.2-11b-vision-instruct</td>\n",
       "      <td>Meta: Llama 3.2 11B Vision Instruct</td>\n",
       "      <td>1727222400</td>\n",
       "      <td>Llama 3.2 11B Vision is a multimodal model wit...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.000000049</td>\n",
       "      <td>0.000000049</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00007948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>qwen/qwen-2.5-72b-instruct:free</td>\n",
       "      <td>Qwen2.5 72B Instruct (free)</td>\n",
       "      <td>1726704000</td>\n",
       "      <td>Qwen2.5 72B is the latest series of Qwen large...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>qwen/qwen-2.5-72b-instruct</td>\n",
       "      <td>Qwen2.5 72B Instruct</td>\n",
       "      <td>1726704000</td>\n",
       "      <td>Qwen2.5 72B is the latest series of Qwen large...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.00000012</td>\n",
       "      <td>0.00000039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>qwen/qwen-2.5-vl-72b-instruct</td>\n",
       "      <td>Qwen: Qwen2.5-VL 72B Instruct</td>\n",
       "      <td>1726617600</td>\n",
       "      <td>Qwen2.5 VL 72B is a multimodal LLM from the Qw...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>neversleep/llama-3.1-lumimaid-8b</td>\n",
       "      <td>NeverSleep: Lumimaid v0.2 8B</td>\n",
       "      <td>1726358400</td>\n",
       "      <td>Lumimaid v0.2 8B is a finetune of [Llama 3.1 8...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000009375</td>\n",
       "      <td>0.00000075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>openai/o1-preview</td>\n",
       "      <td>OpenAI: o1-preview</td>\n",
       "      <td>1726099200</td>\n",
       "      <td>The latest and strongest model family from Ope...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[seed, max_tokens]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>openai/o1-preview-2024-09-12</td>\n",
       "      <td>OpenAI: o1-preview (2024-09-12)</td>\n",
       "      <td>1726099200</td>\n",
       "      <td>The latest and strongest model family from Ope...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[seed, max_tokens]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>openai/o1-mini</td>\n",
       "      <td>OpenAI: o1-mini</td>\n",
       "      <td>1726099200</td>\n",
       "      <td>The latest and strongest model family from Ope...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[seed, max_tokens]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000055</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>openai/o1-mini-2024-09-12</td>\n",
       "      <td>OpenAI: o1-mini (2024-09-12)</td>\n",
       "      <td>1726099200</td>\n",
       "      <td>The latest and strongest model family from Ope...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[seed, max_tokens]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000055</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>mistralai/pixtral-12b</td>\n",
       "      <td>Mistral: Pixtral 12B</td>\n",
       "      <td>1725926400</td>\n",
       "      <td>The first multi-modal, text+image-to-text mode...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>cohere/command-r-plus-08-2024</td>\n",
       "      <td>Cohere: Command R+ (08-2024)</td>\n",
       "      <td>1724976000</td>\n",
       "      <td>command-r-plus-08-2024 is an update of the [Co...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, max_tokens, temperature, top_p, stop, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>cohere/command-r-08-2024</td>\n",
       "      <td>Cohere: Command R (08-2024)</td>\n",
       "      <td>1724976000</td>\n",
       "      <td>command-r-08-2024 is an update of the [Command...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, max_tokens, temperature, top_p, stop, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>qwen/qwen-2.5-vl-7b-instruct:free</td>\n",
       "      <td>Qwen: Qwen2.5-VL 7B Instruct (free)</td>\n",
       "      <td>1724803200</td>\n",
       "      <td>Qwen2.5 VL 7B is a multimodal LLM from the Qwe...</td>\n",
       "      <td>64000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>qwen/qwen-2.5-vl-7b-instruct</td>\n",
       "      <td>Qwen: Qwen2.5-VL 7B Instruct</td>\n",
       "      <td>1724803200</td>\n",
       "      <td>Qwen2.5 VL 7B is a multimodal LLM from the Qwe...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>sao10k/l3.1-euryale-70b</td>\n",
       "      <td>Sao10K: Llama 3.1 Euryale 70B v2.2</td>\n",
       "      <td>1724803200</td>\n",
       "      <td>Euryale L3.1 70B v2.2 is a model focused on cr...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.0000007</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>google/gemini-flash-1.5-8b-exp</td>\n",
       "      <td>Google: Gemini 1.5 Flash 8B Experimental</td>\n",
       "      <td>1724803200</td>\n",
       "      <td>Gemini Flash 1.5 8B Experimental is an experim...</td>\n",
       "      <td>1000000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>microsoft/phi-3.5-mini-128k-instruct</td>\n",
       "      <td>Microsoft: Phi-3.5 Mini 128K Instruct</td>\n",
       "      <td>1724198400</td>\n",
       "      <td>Phi-3.5 models are lightweight, state-of-the-a...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>phi3</td>\n",
       "      <td>0.00000003</td>\n",
       "      <td>0.00000009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-70b</td>\n",
       "      <td>Nous: Hermes 3 70B Instruct</td>\n",
       "      <td>1723939200</td>\n",
       "      <td>Hermes 3 is a generalist language model with m...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.00000012</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-405b</td>\n",
       "      <td>Nous: Hermes 3 405B Instruct</td>\n",
       "      <td>1723766400</td>\n",
       "      <td>Hermes 3 is a generalist language model with m...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>openai/chatgpt-4o-latest</td>\n",
       "      <td>OpenAI: ChatGPT-4o</td>\n",
       "      <td>1723593600</td>\n",
       "      <td>OpenAI ChatGPT 4o is continually updated by Op...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>sao10k/l3-lunaris-8b</td>\n",
       "      <td>Sao10K: Llama 3 8B Lunaris</td>\n",
       "      <td>1723507200</td>\n",
       "      <td>Lunaris 8B is a versatile generalist and rolep...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>aetherwiing/mn-starcannon-12b</td>\n",
       "      <td>Aetherwiing: Starcannon 12B</td>\n",
       "      <td>1723507200</td>\n",
       "      <td>Starcannon 12B v2 is a creative roleplay and s...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>openai/gpt-4o-2024-08-06</td>\n",
       "      <td>OpenAI: GPT-4o (2024-08-06)</td>\n",
       "      <td>1722902400</td>\n",
       "      <td>The 2024-08-06 version of GPT-4o offers improv...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>meta-llama/llama-3.1-405b:free</td>\n",
       "      <td>Meta: Llama 3.1 405B (base) (free)</td>\n",
       "      <td>1722556800</td>\n",
       "      <td>Meta's latest class of model (Llama 3.1) launc...</td>\n",
       "      <td>64000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>meta-llama/llama-3.1-405b</td>\n",
       "      <td>Meta: Llama 3.1 405B (base)</td>\n",
       "      <td>1722556800</td>\n",
       "      <td>Meta's latest class of model (Llama 3.1) launc...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>nothingiisreal/mn-celeste-12b</td>\n",
       "      <td>Mistral Nemo 12B Celeste</td>\n",
       "      <td>1722556800</td>\n",
       "      <td>A specialized story writing and roleplaying mo...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>perplexity/llama-3.1-sonar-small-128k-online</td>\n",
       "      <td>Perplexity: Llama 3.1 Sonar 8B Online</td>\n",
       "      <td>1722470400</td>\n",
       "      <td>Llama 3.1 Sonar is Perplexity's latest model f...</td>\n",
       "      <td>127072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, top_k, freque...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>perplexity/llama-3.1-sonar-large-128k-online</td>\n",
       "      <td>Perplexity: Llama 3.1 Sonar 70B Online</td>\n",
       "      <td>1722470400</td>\n",
       "      <td>Llama 3.1 Sonar is Perplexity's latest model f...</td>\n",
       "      <td>127072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, top_k, freque...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>meta-llama/llama-3.1-8b-instruct:free</td>\n",
       "      <td>Meta: Llama 3.1 8B Instruct (free)</td>\n",
       "      <td>1721692800</td>\n",
       "      <td>Meta's latest class of model (Llama 3.1) launc...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>meta-llama/llama-3.1-8b-instruct</td>\n",
       "      <td>Meta: Llama 3.1 8B Instruct</td>\n",
       "      <td>1721692800</td>\n",
       "      <td>Meta's latest class of model (Llama 3.1) launc...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>meta-llama/llama-3.1-405b-instruct</td>\n",
       "      <td>Meta: Llama 3.1 405B Instruct</td>\n",
       "      <td>1721692800</td>\n",
       "      <td>The highly anticipated 400B class of Llama3 is...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>meta-llama/llama-3.1-70b-instruct</td>\n",
       "      <td>Meta: Llama 3.1 70B Instruct</td>\n",
       "      <td>1721692800</td>\n",
       "      <td>Meta's latest class of model (Llama 3.1) launc...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.00000028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>mistralai/codestral-mamba</td>\n",
       "      <td>Mistral: Codestral Mamba</td>\n",
       "      <td>1721347200</td>\n",
       "      <td>A 7.3B parameter Mamba-based model designed fo...</td>\n",
       "      <td>262144</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>mistralai/mistral-nemo:free</td>\n",
       "      <td>Mistral: Mistral Nemo (free)</td>\n",
       "      <td>1721347200</td>\n",
       "      <td>A 12B parameter model with a 128k token contex...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>mistral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>mistralai/mistral-nemo</td>\n",
       "      <td>Mistral: Mistral Nemo</td>\n",
       "      <td>1721347200</td>\n",
       "      <td>A 12B parameter model with a 128k token contex...</td>\n",
       "      <td>98304</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>mistral</td>\n",
       "      <td>0.00000003</td>\n",
       "      <td>0.00000007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98304.0</td>\n",
       "      <td>49152.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>openai/gpt-4o-mini</td>\n",
       "      <td>OpenAI: GPT-4o-mini</td>\n",
       "      <td>1721260800</td>\n",
       "      <td>GPT-4o mini is OpenAI's newest model after [GP...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>openai/gpt-4o-mini-2024-07-18</td>\n",
       "      <td>OpenAI: GPT-4o-mini (2024-07-18)</td>\n",
       "      <td>1721260800</td>\n",
       "      <td>GPT-4o mini is OpenAI's newest model after [GP...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>google/gemma-2-27b-it</td>\n",
       "      <td>Google: Gemma 2 27B</td>\n",
       "      <td>1720828800</td>\n",
       "      <td>Gemma 2 27B by Google is an open model built f...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemma</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>alpindale/magnum-72b</td>\n",
       "      <td>Magnum 72B</td>\n",
       "      <td>1720656000</td>\n",
       "      <td>From the maker of [Goliath](https://openrouter...</td>\n",
       "      <td>16384</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>google/gemma-2-9b-it:free</td>\n",
       "      <td>Google: Gemma 2 9B (free)</td>\n",
       "      <td>1719532800</td>\n",
       "      <td>Gemma 2 9B by Google is an advanced, open-sour...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>Google: Gemma 2 9B</td>\n",
       "      <td>1719532800</td>\n",
       "      <td>Gemma 2 9B by Google is an advanced, open-sour...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemma</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>01-ai/yi-large</td>\n",
       "      <td>01.AI: Yi Large</td>\n",
       "      <td>1719273600</td>\n",
       "      <td>The Yi Large model was designed by 01.AI with ...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Yi</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>ai21/jamba-instruct</td>\n",
       "      <td>AI21: Jamba Instruct</td>\n",
       "      <td>1719273600</td>\n",
       "      <td>The Jamba-Instruct model, introduced by AI21 L...</td>\n",
       "      <td>256000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>anthropic/claude-3.5-sonnet-20240620:beta</td>\n",
       "      <td>Anthropic: Claude 3.5 Sonnet (2024-06-20) (sel...</td>\n",
       "      <td>1718841600</td>\n",
       "      <td>Claude 3.5 Sonnet delivers better-than-Opus ca...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.00000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>anthropic/claude-3.5-sonnet-20240620</td>\n",
       "      <td>Anthropic: Claude 3.5 Sonnet (2024-06-20)</td>\n",
       "      <td>1718841600</td>\n",
       "      <td>Claude 3.5 Sonnet delivers better-than-Opus ca...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.00000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>sao10k/l3-euryale-70b</td>\n",
       "      <td>Sao10k: Llama 3 Euryale 70B v2.1</td>\n",
       "      <td>1718668800</td>\n",
       "      <td>Euryale 70B v2.1 is a model focused on creativ...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000148</td>\n",
       "      <td>0.00000148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>cognitivecomputations/dolphin-mixtral-8x22b</td>\n",
       "      <td>Dolphin 2.9.2 Mixtral 8x22B 🐬</td>\n",
       "      <td>1717804800</td>\n",
       "      <td>Dolphin 2.9 is designed for instruction follow...</td>\n",
       "      <td>16000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>qwen/qwen-2-72b-instruct</td>\n",
       "      <td>Qwen 2 72B Instruct</td>\n",
       "      <td>1717718400</td>\n",
       "      <td>Qwen2 72B is a transformer-based model that ex...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Qwen</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>mistralai/mistral-7b-instruct:free</td>\n",
       "      <td>Mistral: Mistral 7B Instruct (free)</td>\n",
       "      <td>1716768000</td>\n",
       "      <td>A high-performing, industry-standard 7.3B para...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>mistral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>mistralai/mistral-7b-instruct</td>\n",
       "      <td>Mistral: Mistral 7B Instruct</td>\n",
       "      <td>1716768000</td>\n",
       "      <td>A high-performing, industry-standard 7.3B para...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>mistral</td>\n",
       "      <td>0.000000028</td>\n",
       "      <td>0.000000054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>nousresearch/hermes-2-pro-llama-3-8b</td>\n",
       "      <td>NousResearch: Hermes 2 Pro - Llama-3 8B</td>\n",
       "      <td>1716768000</td>\n",
       "      <td>Hermes 2 Pro is an upgraded, retrained version...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.000000025</td>\n",
       "      <td>0.00000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>mistralai/mistral-7b-instruct-v0.3</td>\n",
       "      <td>Mistral: Mistral 7B Instruct v0.3</td>\n",
       "      <td>1716768000</td>\n",
       "      <td>A high-performing, industry-standard 7.3B para...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>mistral</td>\n",
       "      <td>0.000000028</td>\n",
       "      <td>0.000000054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>microsoft/phi-3-mini-128k-instruct</td>\n",
       "      <td>Microsoft: Phi-3 Mini 128K Instruct</td>\n",
       "      <td>1716681600</td>\n",
       "      <td>Phi-3 Mini is a powerful 3.8B parameter model ...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>phi3</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>microsoft/phi-3-medium-128k-instruct</td>\n",
       "      <td>Microsoft: Phi-3 Medium 128K Instruct</td>\n",
       "      <td>1716508800</td>\n",
       "      <td>Phi-3 128K Medium is a powerful 14-billion par...</td>\n",
       "      <td>131072</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>phi3</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>neversleep/llama-3-lumimaid-70b</td>\n",
       "      <td>NeverSleep: Llama 3 Lumimaid 70B</td>\n",
       "      <td>1715817600</td>\n",
       "      <td>The NeverSleep team is back, with a Llama 3 70...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>deepseek/deepseek-coder</td>\n",
       "      <td>DeepSeek-Coder-V2</td>\n",
       "      <td>1715644800</td>\n",
       "      <td>DeepSeek-Coder-V2, an open-source Mixture-of-E...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000004</td>\n",
       "      <td>0.00000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>google/gemini-flash-1.5</td>\n",
       "      <td>Google: Gemini 1.5 Flash</td>\n",
       "      <td>1715644800</td>\n",
       "      <td>Gemini 1.5 Flash is a foundation model that pe...</td>\n",
       "      <td>1000000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000075</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00000001875</td>\n",
       "      <td>0.0000001583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>openai/gpt-4o</td>\n",
       "      <td>OpenAI: GPT-4o</td>\n",
       "      <td>1715558400</td>\n",
       "      <td>GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI ...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>openai/gpt-4o:extended</td>\n",
       "      <td>OpenAI: GPT-4o (extended)</td>\n",
       "      <td>1715558400</td>\n",
       "      <td>GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI ...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>meta-llama/llama-guard-2-8b</td>\n",
       "      <td>Meta: LlamaGuard 2 8B</td>\n",
       "      <td>1715558400</td>\n",
       "      <td>This safeguard model has 8B parameters and is ...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>openai/gpt-4o-2024-05-13</td>\n",
       "      <td>OpenAI: GPT-4o (2024-05-13)</td>\n",
       "      <td>1715558400</td>\n",
       "      <td>GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI ...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image, file]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>allenai/olmo-7b-instruct</td>\n",
       "      <td>OLMo 7B Instruct</td>\n",
       "      <td>1715299200</td>\n",
       "      <td>OLMo 7B Instruct by the Allen Institute for AI...</td>\n",
       "      <td>2048</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Other</td>\n",
       "      <td>zephyr</td>\n",
       "      <td>0.00000008</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>neversleep/llama-3-lumimaid-8b:extended</td>\n",
       "      <td>NeverSleep: Llama 3 Lumimaid 8B (extended)</td>\n",
       "      <td>1714780800</td>\n",
       "      <td>The NeverSleep team is back, with a Llama 3 8B...</td>\n",
       "      <td>24576</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000009375</td>\n",
       "      <td>0.00000075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24576.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>neversleep/llama-3-lumimaid-8b</td>\n",
       "      <td>NeverSleep: Llama 3 Lumimaid 8B</td>\n",
       "      <td>1714780800</td>\n",
       "      <td>The NeverSleep team is back, with a Llama 3 8B...</td>\n",
       "      <td>24576</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000009375</td>\n",
       "      <td>0.00000075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24576.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>sao10k/fimbulvetr-11b-v2</td>\n",
       "      <td>Fimbulvetr 11B v2</td>\n",
       "      <td>1713657600</td>\n",
       "      <td>Creative writing model, routed with permission...</td>\n",
       "      <td>4096</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama2</td>\n",
       "      <td>alpaca</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>meta-llama/llama-3-8b-instruct</td>\n",
       "      <td>Meta: Llama 3 8B Instruct</td>\n",
       "      <td>1713398400</td>\n",
       "      <td>Meta's latest class of model (Llama 3) launche...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, top_k, seed, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.00000003</td>\n",
       "      <td>0.00000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>meta-llama/llama-3-70b-instruct</td>\n",
       "      <td>Meta: Llama 3 70B Instruct</td>\n",
       "      <td>1713398400</td>\n",
       "      <td>Meta's latest class of model (Llama 3) launche...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama3</td>\n",
       "      <td>llama3</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>mistralai/mixtral-8x22b-instruct</td>\n",
       "      <td>Mistral: Mixtral 8x22B Instruct</td>\n",
       "      <td>1713312000</td>\n",
       "      <td>Mistral's official instruct fine-tuned version...</td>\n",
       "      <td>65536</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>mistral</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>microsoft/wizardlm-2-8x22b</td>\n",
       "      <td>WizardLM-2 8x22B</td>\n",
       "      <td>1713225600</td>\n",
       "      <td>WizardLM-2 8x22B is Microsoft AI's most advanc...</td>\n",
       "      <td>65536</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, presence_pena...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>vicuna</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>google/gemini-pro-1.5</td>\n",
       "      <td>Google: Gemini 1.5 Pro</td>\n",
       "      <td>1712620800</td>\n",
       "      <td>Google's latest multimodal model, supports ima...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000125</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0006575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>openai/gpt-4-turbo</td>\n",
       "      <td>OpenAI: GPT-4 Turbo</td>\n",
       "      <td>1712620800</td>\n",
       "      <td>The latest GPT-4 Turbo model with vision capab...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>cohere/command-r-plus</td>\n",
       "      <td>Cohere: Command R+</td>\n",
       "      <td>1712188800</td>\n",
       "      <td>Command R+ is a new, 104B-parameter LLM from C...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, max_tokens, temperature, top_p, stop, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>cohere/command-r-plus-04-2024</td>\n",
       "      <td>Cohere: Command R+ (04-2024)</td>\n",
       "      <td>1712016000</td>\n",
       "      <td>Command R+ is a new, 104B-parameter LLM from C...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, max_tokens, temperature, top_p, stop, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>sophosympatheia/midnight-rose-70b</td>\n",
       "      <td>Midnight Rose 70B</td>\n",
       "      <td>1711065600</td>\n",
       "      <td>A merge with a complex family tree, this model...</td>\n",
       "      <td>4096</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama2</td>\n",
       "      <td>airoboros</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>cohere/command</td>\n",
       "      <td>Cohere: Command</td>\n",
       "      <td>1710374400</td>\n",
       "      <td>Command is an instruction-following conversati...</td>\n",
       "      <td>4096</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>cohere/command-r</td>\n",
       "      <td>Cohere: Command R</td>\n",
       "      <td>1710374400</td>\n",
       "      <td>Command-R is a 35B parameter model that perfor...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, max_tokens, temperature, top_p, stop, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>anthropic/claude-3-haiku:beta</td>\n",
       "      <td>Anthropic: Claude 3 Haiku (self-moderated)</td>\n",
       "      <td>1710288000</td>\n",
       "      <td>Claude 3 Haiku is Anthropic's fastest and most...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.00000125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00000003</td>\n",
       "      <td>0.0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>anthropic/claude-3-haiku</td>\n",
       "      <td>Anthropic: Claude 3 Haiku</td>\n",
       "      <td>1710288000</td>\n",
       "      <td>Claude 3 Haiku is Anthropic's fastest and most...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.00000125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000003</td>\n",
       "      <td>0.0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>anthropic/claude-3-opus:beta</td>\n",
       "      <td>Anthropic: Claude 3 Opus (self-moderated)</td>\n",
       "      <td>1709596800</td>\n",
       "      <td>Claude 3 Opus is Anthropic's most powerful mod...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0.00001875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>anthropic/claude-3-opus</td>\n",
       "      <td>Anthropic: Claude 3 Opus</td>\n",
       "      <td>1709596800</td>\n",
       "      <td>Claude 3 Opus is Anthropic's most powerful mod...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0.00001875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>anthropic/claude-3-sonnet:beta</td>\n",
       "      <td>Anthropic: Claude 3 Sonnet (self-moderated)</td>\n",
       "      <td>1709596800</td>\n",
       "      <td>Claude 3 Sonnet is an ideal balance of intelli...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.00000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>anthropic/claude-3-sonnet</td>\n",
       "      <td>Anthropic: Claude 3 Sonnet</td>\n",
       "      <td>1709596800</td>\n",
       "      <td>Claude 3 Sonnet is an ideal balance of intelli...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text+image-&gt;text</td>\n",
       "      <td>[text, image]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.00000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>cohere/command-r-03-2024</td>\n",
       "      <td>Cohere: Command R (03-2024)</td>\n",
       "      <td>1709341200</td>\n",
       "      <td>Command-R is a 35B parameter model that perfor...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, max_tokens, temperature, top_p, stop, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>mistralai/mistral-large</td>\n",
       "      <td>Mistral Large</td>\n",
       "      <td>1708905600</td>\n",
       "      <td>This is Mistral AI's flagship model, Mistral L...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>openai/gpt-3.5-turbo-0613</td>\n",
       "      <td>OpenAI: GPT-3.5 Turbo (older v0613)</td>\n",
       "      <td>1706140800</td>\n",
       "      <td>GPT-3.5 Turbo is OpenAI's fastest model. It ca...</td>\n",
       "      <td>4095</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>openai/gpt-4-turbo-preview</td>\n",
       "      <td>OpenAI: GPT-4 Turbo Preview</td>\n",
       "      <td>1706140800</td>\n",
       "      <td>The preview GPT-4 model with improved instruct...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>nousresearch/nous-hermes-2-mixtral-8x7b-dpo</td>\n",
       "      <td>Nous: Hermes 2 Mixtral 8x7B DPO</td>\n",
       "      <td>1705363200</td>\n",
       "      <td>Nous Hermes 2 Mixtral 8x7B DPO is the new flag...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>mistralai/mistral-medium</td>\n",
       "      <td>Mistral Medium</td>\n",
       "      <td>1704844800</td>\n",
       "      <td>This is Mistral AI's closed-source, medium-sid...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000275</td>\n",
       "      <td>0.0000081</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>mistralai/mistral-small</td>\n",
       "      <td>Mistral Small</td>\n",
       "      <td>1704844800</td>\n",
       "      <td>With 22 billion parameters, Mistral Small v24....</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>mistralai/mistral-tiny</td>\n",
       "      <td>Mistral Tiny</td>\n",
       "      <td>1704844800</td>\n",
       "      <td>Note: This model is being deprecated. Recommen...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>mistralai/mistral-7b-instruct-v0.2</td>\n",
       "      <td>Mistral: Mistral 7B Instruct v0.2</td>\n",
       "      <td>1703721600</td>\n",
       "      <td>A high-performing, industry-standard 7.3B para...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>mistral</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>mistralai/mixtral-8x7b-instruct</td>\n",
       "      <td>Mistral: Mixtral 8x7B Instruct</td>\n",
       "      <td>1702166400</td>\n",
       "      <td>Mixtral 8x7B Instruct is a pretrained generati...</td>\n",
       "      <td>32768</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>mistral</td>\n",
       "      <td>0.00000008</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>neversleep/noromaid-20b</td>\n",
       "      <td>Noromaid 20B</td>\n",
       "      <td>1700956800</td>\n",
       "      <td>A collab between IkariDev and Undi. This merge...</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama2</td>\n",
       "      <td>alpaca</td>\n",
       "      <td>0.00000075</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>anthropic/claude-2.1:beta</td>\n",
       "      <td>Anthropic: Claude v2.1 (self-moderated)</td>\n",
       "      <td>1700611200</td>\n",
       "      <td>Claude 2 delivers advancements in key capabili...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, top_k, stop]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>anthropic/claude-2.1</td>\n",
       "      <td>Anthropic: Claude v2.1</td>\n",
       "      <td>1700611200</td>\n",
       "      <td>Claude 2 delivers advancements in key capabili...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, top_k, stop]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>anthropic/claude-2:beta</td>\n",
       "      <td>Anthropic: Claude v2 (self-moderated)</td>\n",
       "      <td>1700611200</td>\n",
       "      <td>Claude 2 delivers advancements in key capabili...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, top_k, stop]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>anthropic/claude-2</td>\n",
       "      <td>Anthropic: Claude v2</td>\n",
       "      <td>1700611200</td>\n",
       "      <td>Claude 2 delivers advancements in key capabili...</td>\n",
       "      <td>200000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, top_k, stop]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>undi95/toppy-m-7b</td>\n",
       "      <td>Toppy M 7B</td>\n",
       "      <td>1699574400</td>\n",
       "      <td>A wild 7B parameter model that merges several ...</td>\n",
       "      <td>4096</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>alpaca</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>alpindale/goliath-120b</td>\n",
       "      <td>Goliath 120B</td>\n",
       "      <td>1699574400</td>\n",
       "      <td>A large LLM created by combining two fine-tune...</td>\n",
       "      <td>6144</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama2</td>\n",
       "      <td>airoboros</td>\n",
       "      <td>0.0000065625</td>\n",
       "      <td>0.000009375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>openrouter/auto</td>\n",
       "      <td>Auto Router</td>\n",
       "      <td>1699401600</td>\n",
       "      <td>Your prompt will be processed by a meta-model ...</td>\n",
       "      <td>2000000</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Router</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>openai/gpt-3.5-turbo-1106</td>\n",
       "      <td>OpenAI: GPT-3.5 Turbo 16k (older v1106)</td>\n",
       "      <td>1699228800</td>\n",
       "      <td>An older GPT-3.5 Turbo model with improved ins...</td>\n",
       "      <td>16385</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16385.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>openai/gpt-4-1106-preview</td>\n",
       "      <td>OpenAI: GPT-4 Turbo (older v1106)</td>\n",
       "      <td>1699228800</td>\n",
       "      <td>The latest GPT-4 Turbo model with vision capab...</td>\n",
       "      <td>128000</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>jondurbin/airoboros-l2-70b</td>\n",
       "      <td>Airoboros 70B</td>\n",
       "      <td>1698537600</td>\n",
       "      <td>A Llama 2 70B fine-tune using synthetic data (...</td>\n",
       "      <td>4096</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama2</td>\n",
       "      <td>airoboros</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>openai/gpt-3.5-turbo-instruct</td>\n",
       "      <td>OpenAI: GPT-3.5 Turbo Instruct</td>\n",
       "      <td>1695859200</td>\n",
       "      <td>This model is a variant of GPT-3.5 Turbo tuned...</td>\n",
       "      <td>4095</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>chatml</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>mistralai/mistral-7b-instruct-v0.1</td>\n",
       "      <td>Mistral: Mistral 7B Instruct v0.1</td>\n",
       "      <td>1695859200</td>\n",
       "      <td>A 7.3B parameter model that outperforms Llama ...</td>\n",
       "      <td>2824</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>mistral</td>\n",
       "      <td>0.00000011</td>\n",
       "      <td>0.00000019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2824.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>pygmalionai/mythalion-13b</td>\n",
       "      <td>Pygmalion: Mythalion 13B</td>\n",
       "      <td>1693612800</td>\n",
       "      <td>A blend of the new Pygmalion-13b and MythoMax....</td>\n",
       "      <td>8192</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama2</td>\n",
       "      <td>alpaca</td>\n",
       "      <td>0.0000005625</td>\n",
       "      <td>0.000001125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>openai/gpt-3.5-turbo-16k</td>\n",
       "      <td>OpenAI: GPT-3.5 Turbo 16k</td>\n",
       "      <td>1693180800</td>\n",
       "      <td>This model offers four times the context lengt...</td>\n",
       "      <td>16385</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16385.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>openai/gpt-4-32k</td>\n",
       "      <td>OpenAI: GPT-4 32k</td>\n",
       "      <td>1693180800</td>\n",
       "      <td>GPT-4-32k is an extended version of GPT-4, wit...</td>\n",
       "      <td>32767</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32767.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>openai/gpt-4-32k-0314</td>\n",
       "      <td>OpenAI: GPT-4 32k (older v0314)</td>\n",
       "      <td>1693180800</td>\n",
       "      <td>GPT-4-32k is an extended version of GPT-4, wit...</td>\n",
       "      <td>32767</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32767.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>mancer/weaver</td>\n",
       "      <td>Mancer: Weaver (alpha)</td>\n",
       "      <td>1690934400</td>\n",
       "      <td>An attempt to recreate Claude-style verbosity,...</td>\n",
       "      <td>8000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama2</td>\n",
       "      <td>alpaca</td>\n",
       "      <td>0.000001125</td>\n",
       "      <td>0.000001125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>anthropic/claude-2.0:beta</td>\n",
       "      <td>Anthropic: Claude v2.0 (self-moderated)</td>\n",
       "      <td>1690502400</td>\n",
       "      <td>Anthropic's flagship model. Superior performan...</td>\n",
       "      <td>100000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, top_k, stop]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>anthropic/claude-2.0</td>\n",
       "      <td>Anthropic: Claude v2.0</td>\n",
       "      <td>1690502400</td>\n",
       "      <td>Anthropic's flagship model. Superior performan...</td>\n",
       "      <td>100000</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, top_k, stop]</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Claude</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>undi95/remm-slerp-l2-13b</td>\n",
       "      <td>ReMM SLERP 13B</td>\n",
       "      <td>1689984000</td>\n",
       "      <td>A recreation trial of the original MythoMax-L2...</td>\n",
       "      <td>6144</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama2</td>\n",
       "      <td>alpaca</td>\n",
       "      <td>0.0000005625</td>\n",
       "      <td>0.000001125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>gryphe/mythomax-l2-13b</td>\n",
       "      <td>MythoMax 13B</td>\n",
       "      <td>1688256000</td>\n",
       "      <td>One of the highest performing and most popular...</td>\n",
       "      <td>4096</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama2</td>\n",
       "      <td>alpaca</td>\n",
       "      <td>0.000000065</td>\n",
       "      <td>0.000000065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>meta-llama/llama-2-70b-chat</td>\n",
       "      <td>Meta: Llama 2 70B Chat</td>\n",
       "      <td>1687219200</td>\n",
       "      <td>The flagship, 70 billion parameter language mo...</td>\n",
       "      <td>4096</td>\n",
       "      <td>None</td>\n",
       "      <td>[max_tokens, temperature, top_p, stop, frequen...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>Llama2</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>openai/gpt-3.5-turbo</td>\n",
       "      <td>OpenAI: GPT-3.5 Turbo</td>\n",
       "      <td>1685232000</td>\n",
       "      <td>GPT-3.5 Turbo is OpenAI's fastest model. It ca...</td>\n",
       "      <td>16385</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16385.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>openai/gpt-3.5-turbo-0125</td>\n",
       "      <td>OpenAI: GPT-3.5 Turbo 16k</td>\n",
       "      <td>1685232000</td>\n",
       "      <td>The latest GPT-3.5 Turbo model with improved i...</td>\n",
       "      <td>16385</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16385.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>openai/gpt-4</td>\n",
       "      <td>OpenAI: GPT-4</td>\n",
       "      <td>1685232000</td>\n",
       "      <td>OpenAI's flagship model, GPT-4 is a large-scal...</td>\n",
       "      <td>8191</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8191.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>openai/gpt-4-0314</td>\n",
       "      <td>OpenAI: GPT-4 (older v0314)</td>\n",
       "      <td>1685232000</td>\n",
       "      <td>GPT-4-0314 is the first version of GPT-4 relea...</td>\n",
       "      <td>8191</td>\n",
       "      <td>None</td>\n",
       "      <td>[tools, tool_choice, max_tokens, temperature, ...</td>\n",
       "      <td>text-&gt;text</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>GPT</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8191.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id                                               name     created                                        description  context_length per_request_limits                               supported_parameters architecture_modality architecture_input_modalities architecture_output_modalities architecture_tokenizer architecture_instruct_type pricing_prompt pricing_completion pricing_request pricing_image pricing_web_search pricing_internal_reasoning  top_provider_context_length  top_provider_max_completion_tokens  top_provider_is_moderated pricing_input_cache_read pricing_input_cache_write\n",
       "0                           mistralai/mistral-medium-3                          Mistral: Mistral Medium 3  1746627341  Mistral Medium 3 is a high-performance enterpr...          131072               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                Mistral                       None      0.0000004           0.000002               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "1                        google/gemini-2.5-pro-preview                     Google: Gemini 2.5 Pro Preview  1746578513  Gemini 2.5 Pro is Google’s state-of-the-art AI...         1048576               None  [max_tokens, temperature, top_p, tools, tool_c...      text+image->text           [text, image, file]                         [text]                 Gemini                       None     0.00000125            0.00001               0       0.00516                  0                          0                    1048576.0                             65535.0                      False               0.00000031               0.000001625\n",
       "2                                arcee-ai/caller-large                             Arcee AI: Caller Large  1746487869  Caller Large is Arcee's specialist \"function‑c...           32768               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                  Other                       None     0.00000055         0.00000085               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "3                                   arcee-ai/spotlight                                Arcee AI: Spotlight  1746481552  Spotlight is a 7‑billion‑parameter vision‑lang...          131072               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [image, text]                         [text]                  Other                       None     0.00000018         0.00000018               0             0                  0                          0                     131072.0                             65537.0                      False                      NaN                       NaN\n",
       "4                           arcee-ai/maestro-reasoning                        Arcee AI: Maestro Reasoning  1746481269  Maestro Reasoning is Arcee's flagship analysis...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None      0.0000009          0.0000033               0             0                  0                          0                     131072.0                             32000.0                      False                      NaN                       NaN\n",
       "5                              arcee-ai/virtuoso-large                           Arcee AI: Virtuoso Large  1746478885  Virtuoso‑Large is Arcee's top‑tier general‑pur...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None     0.00000075          0.0000012               0             0                  0                          0                     131072.0                             64000.0                      False                      NaN                       NaN\n",
       "6                                 arcee-ai/coder-large                              Arcee AI: Coder Large  1746478663  Coder‑Large is a 32 B‑parameter offspring of Q...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None      0.0000005          0.0000008               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "7                          arcee-ai/virtuoso-medium-v2                       Arcee AI: Virtuoso Medium V2  1746478434  Virtuoso‑Medium‑v2 is a 32 B model distilled f...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None      0.0000005          0.0000008               0             0                  0                          0                     131072.0                             32768.0                      False                      NaN                       NaN\n",
       "8                                 arcee-ai/arcee-blitz                              Arcee AI: Arcee Blitz  1746470100  Arcee Blitz is a 24 B‑parameter dense model di...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None     0.00000045         0.00000075               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "9                  microsoft/phi-4-reasoning-plus:free             Microsoft: Phi 4 Reasoning Plus (free)  1746130961  Phi-4-reasoning-plus is an enhanced 14B parame...           32768               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "10                      microsoft/phi-4-reasoning-plus                    Microsoft: Phi 4 Reasoning Plus  1746130961  Phi-4-reasoning-plus is an enhanced 14B parame...           32768               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                       None     0.00000007         0.00000035               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "11                      microsoft/phi-4-reasoning:free                  Microsoft: Phi 4 Reasoning (free)  1746121275  Phi-4-reasoning is a 14B parameter dense decod...           32768               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "12                          qwen/qwen3-0.6b-04-28:free                            Qwen: Qwen3 0.6B (free)  1746043526  Qwen3-0.6B is a lightweight, 0.6 billion param...           32000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None              0                  0               0             0                  0                          0                      32000.0                                 NaN                      False                      NaN                       NaN\n",
       "13                  inception/mercury-coder-small-beta                Inception: Mercury Coder Small Beta  1746033880  Mercury Coder Small is the first diffusion lar...           32000               None  [max_tokens, frequency_penalty, presence_penal...            text->text                        [text]                         [text]                  Other                       None     0.00000025           0.000001               0             0                  0                          0                      32000.0                                 NaN                      False                      NaN                       NaN\n",
       "14                                qwen/qwen3-1.7b:free                            Qwen: Qwen3 1.7B (free)  1746031388  Qwen3-1.7B is a compact, 1.7 billion parameter...           32000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None              0                  0               0             0                  0                          0                      32000.0                                 NaN                      False                      NaN                       NaN\n",
       "15                                  qwen/qwen3-4b:free                              Qwen: Qwen3 4B (free)  1746031104  Qwen3-4B is a 4 billion parameter dense langua...          128000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None              0                  0               0             0                  0                          0                     128000.0                                 NaN                      False                      NaN                       NaN\n",
       "16                        opengvlab/internvl3-14b:free                    OpenGVLab: InternVL3 14B (free)  1746021355  The 14b version of the InternVL3 series. An ad...           32000               None                   [max_tokens, temperature, top_p]      text+image->text                 [image, text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                      32000.0                                 NaN                      False                      NaN                       NaN\n",
       "17                         opengvlab/internvl3-2b:free                     OpenGVLab: InternVL3 2B (free)  1746019807  The 2b version of the InternVL3 series, for an...           32000               None                   [max_tokens, temperature, top_p]      text+image->text                 [image, text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                      32000.0                                 NaN                      False                      NaN                       NaN\n",
       "18                    deepseek/deepseek-prover-v2:free                DeepSeek: DeepSeek Prover V2 (free)  1746013094  DeepSeek Prover V2 is a 671B parameter model, ...          163840               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]               DeepSeek                       None              0                  0               0             0                  0                          0                     163840.0                                 NaN                      False                      NaN                       NaN\n",
       "19                         deepseek/deepseek-prover-v2                       DeepSeek: DeepSeek Prover V2  1746013094  DeepSeek Prover V2 is a 671B parameter model, ...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]               DeepSeek                       None      0.0000005         0.00000218               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "20                        meta-llama/llama-guard-4-12b                            Meta: Llama Guard 4 12B  1745975193  Llama Guard 4 is a Llama 4 Scout-derived multi...          163840               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [image, text]                         [text]                  Other                       None     0.00000005         0.00000005               0             0                  0                          0                     163840.0                                 NaN                      False                      NaN                       NaN\n",
       "21                             qwen/qwen3-30b-a3b:free                         Qwen: Qwen3 30B A3B (free)  1745878604  Qwen3, the latest generation in the Qwen large...           40960               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None              0                  0               0             0                  0                          0                      40960.0                                 NaN                      False                      NaN                       NaN\n",
       "22                                  qwen/qwen3-30b-a3b                                Qwen: Qwen3 30B A3B  1745878604  Qwen3, the latest generation in the Qwen large...           40960               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                  Qwen3                       None      0.0000001          0.0000003               0             0                  0                          0                      40960.0                             40960.0                      False                      NaN                       NaN\n",
       "23                                  qwen/qwen3-8b:free                              Qwen: Qwen3 8B (free)  1745876632  Qwen3-8B is a dense 8.2B parameter causal lang...           40960               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None              0                  0               0             0                  0                          0                      40960.0                             40960.0                      False                      NaN                       NaN\n",
       "24                                       qwen/qwen3-8b                                     Qwen: Qwen3 8B  1745876632  Qwen3-8B is a dense 8.2B parameter causal lang...          128000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None    0.000000035        0.000000138               0             0                  0                          0                     128000.0                                 NaN                      False                      NaN                       NaN\n",
       "25                                 qwen/qwen3-14b:free                             Qwen: Qwen3 14B (free)  1745876478  Qwen3-14B is a dense 14.8B parameter causal la...           40960               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None              0                  0               0             0                  0                          0                      40960.0                                 NaN                      False                      NaN                       NaN\n",
       "26                                      qwen/qwen3-14b                                    Qwen: Qwen3 14B  1745876478  Qwen3-14B is a dense 14.8B parameter causal la...           40960               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None     0.00000007         0.00000024               0             0                  0                          0                      40960.0                             40960.0                      False                      NaN                       NaN\n",
       "27                                 qwen/qwen3-32b:free                             Qwen: Qwen3 32B (free)  1745875945  Qwen3-32B is a dense 32.8B parameter causal la...           40960               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None              0                  0               0             0                  0                          0                      40960.0                                 NaN                      False                      NaN                       NaN\n",
       "28                                      qwen/qwen3-32b                                    Qwen: Qwen3 32B  1745875945  Qwen3-32B is a dense 32.8B parameter causal la...           40960               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None      0.0000001          0.0000003               0             0                  0                          0                      40960.0                                 NaN                      False                      NaN                       NaN\n",
       "29                           qwen/qwen3-235b-a22b:free                       Qwen: Qwen3 235B A22B (free)  1745875757  Qwen3-235B-A22B is a 235B parameter mixture-of...           40960               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None              0                  0               0             0                  0                          0                      40960.0                                 NaN                      False                      NaN                       NaN\n",
       "30                                qwen/qwen3-235b-a22b                              Qwen: Qwen3 235B A22B  1745875757  Qwen3-235B-A22B is a 235B parameter mixture-of...           40960               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Qwen3                       None     0.00000014           0.000002               0             0                  0                          0                      40960.0                             40960.0                      False                      NaN                       NaN\n",
       "31                   tngtech/deepseek-r1t-chimera:free                   TNG: DeepSeek R1T Chimera (free)  1745760875  DeepSeek-R1T-Chimera is created by merging Dee...          163840               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]               DeepSeek                deepseek-r1              0                  0               0             0                  0                          0                     163840.0                                 NaN                      False                      NaN                       NaN\n",
       "32                         thudm/glm-z1-rumination-32b                      THUDM: GLM Z1 Rumination 32B   1745601495  THUDM: GLM Z1 Rumination 32B is a 32B-paramete...           32000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1     0.00000024         0.00000024               0             0                  0                          0                      32000.0                                 NaN                      False                      NaN                       NaN\n",
       "33                                thudm/glm-z1-9b:free                            THUDM: GLM Z1 9B (free)  1745601140  GLM-Z1-9B-0414 is a 9B-parameter language mode...           32000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1              0                  0               0             0                  0                          0                      32000.0                                 NaN                      False                      NaN                       NaN\n",
       "34                                 thudm/glm-4-9b:free                             THUDM: GLM 4 9B (free)  1745601023  GLM-4-9B-0414 is a 9 billion parameter languag...           32000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                      32000.0                                 NaN                      False                      NaN                       NaN\n",
       "35                            microsoft/mai-ds-r1:free                        Microsoft: MAI DS R1 (free)  1745194100  MAI-DS-R1 is a post-trained variant of DeepSee...          163840               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]               DeepSeek                deepseek-r1              0                  0               0             0                  0                          0                     163840.0                                 NaN                      False                      NaN                       NaN\n",
       "36                               thudm/glm-z1-32b:free                           THUDM: GLM Z1 32B (free)  1744924148  GLM-Z1-32B-0414 is an enhanced reasoning varia...           32768               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "37                                    thudm/glm-z1-32b                                  THUDM: GLM Z1 32B  1744924148  GLM-Z1-32B-0414 is an enhanced reasoning varia...           32000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1     0.00000024         0.00000024               0             0                  0                          0                      32000.0                                 NaN                      False                      NaN                       NaN\n",
       "38                                thudm/glm-4-32b:free                            THUDM: GLM 4 32B (free)  1744920915  GLM-4-32B-0414 is a 32B bilingual (Chinese-Eng...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "39                                     thudm/glm-4-32b                                   THUDM: GLM 4 32B  1744920915  GLM-4-32B-0414 is a 32B bilingual (Chinese-Eng...           32000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None     0.00000024         0.00000024               0             0                  0                          0                      32000.0                                 NaN                      False                      NaN                       NaN\n",
       "40                     google/gemini-2.5-flash-preview                   Google: Gemini 2.5 Flash Preview  1744914667  Gemini 2.5 Flash is Google's state-of-the-art ...         1048576               None  [max_tokens, temperature, top_p, tools, tool_c...      text+image->text           [image, text, file]                         [text]                 Gemini                       None     0.00000015          0.0000006               0     0.0006192                  0                          0                    1048576.0                             65535.0                      False             0.0000000375              0.0000002333\n",
       "41            google/gemini-2.5-flash-preview:thinking        Google: Gemini 2.5 Flash Preview (thinking)  1744914667  Gemini 2.5 Flash is Google's state-of-the-art ...         1048576               None  [max_tokens, temperature, top_p, tools, tool_c...      text+image->text           [image, text, file]                         [text]                 Gemini                       None     0.00000015          0.0000035               0     0.0006192                  0                          0                    1048576.0                             65535.0                      False             0.0000000375              0.0000002333\n",
       "42                                 openai/o4-mini-high                               OpenAI: o4 Mini High  1744824212  OpenAI o4-mini-high is the same model as [o4-m...          200000               None  [tools, tool_choice, seed, max_tokens, respons...      text+image->text           [image, text, file]                         [text]                  Other                       None      0.0000011          0.0000044               0     0.0008415                  0                          0                     200000.0                            100000.0                       True              0.000000275                       NaN\n",
       "43                                           openai/o3                                         OpenAI: o3  1744823457  o3 is a well-rounded and powerful model across...          200000               None  [tools, tool_choice, seed, max_tokens, respons...      text+image->text           [image, text, file]                         [text]                  Other                       None        0.00001            0.00004               0       0.00765                  0                          0                     200000.0                            100000.0                       True                0.0000025                       NaN\n",
       "44                                      openai/o4-mini                                    OpenAI: o4 Mini  1744820942  OpenAI o4-mini is a compact reasoning model in...          200000               None  [tools, tool_choice, seed, max_tokens, respons...      text+image->text                 [image, text]                         [text]                  Other                       None      0.0000011          0.0000044               0     0.0008415                  0                          0                     200000.0                            100000.0                       True              0.000000275                       NaN\n",
       "45                 shisa-ai/shisa-v2-llama3.3-70b:free           Shisa AI: Shisa V2 Llama 3.3 70B  (free)  1744754858  Shisa V2 Llama 3.3 70B is a bilingual Japanese...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                       None              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "46                      qwen/qwen2.5-coder-7b-instruct                    Qwen: Qwen2.5 Coder 7B Instruct  1744734887  Qwen2.5-Coder-7B-Instruct is a 7B parameter in...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                       None     0.00000001         0.00000003               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "47                                      openai/gpt-4.1                                    OpenAI: GPT-4.1  1744651385  GPT-4.1 is a flagship large language model opt...         1047576               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [image, text]                         [text]                    GPT                       None       0.000002           0.000008               0             0                  0                          0                    1047576.0                             32768.0                       True                0.0000005                       NaN\n",
       "48                                 openai/gpt-4.1-mini                               OpenAI: GPT-4.1 Mini  1744651381  GPT-4.1 Mini is a mid-sized model delivering p...         1047576               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [image, text]                         [text]                    GPT                       None      0.0000004          0.0000016               0             0                  0                          0                    1047576.0                             32768.0                       True                0.0000001                       NaN\n",
       "49                                 openai/gpt-4.1-nano                               OpenAI: GPT-4.1 Nano  1744651369  For tasks that demand low latency, GPT‑4.1 nan...         1047576               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [image, text]                         [text]                    GPT                       None      0.0000001          0.0000004               0             0                  0                          0                    1047576.0                             32768.0                       True              0.000000025                       NaN\n",
       "50                                eleutherai/llemma_7b                              EleutherAI: Llemma 7b  1744643225  Llemma 7B is a language model for mathematics....            4096               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                 code-llama      0.0000008          0.0000012               0             0                  0                          0                       4096.0                              4096.0                      False                      NaN                       NaN\n",
       "51           alfredpros/codellama-7b-instruct-solidity         AlfredPros: CodeLLaMa 7B Instruct Solidity  1744641874  A finetuned 7 billion parameters Code LLaMA - ...            4096               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                     alpaca      0.0000008          0.0000012               0             0                  0                          0                       4096.0                              4096.0                      False                      NaN                       NaN\n",
       "52                   arliai/qwq-32b-arliai-rpr-v1:free                      ArliAI: QwQ 32B RpR v1 (free)  1744555982  QwQ-32B-ArliAI-RpR-v1 is a 32B parameter model...           32768               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "53             agentica-org/deepcoder-14b-preview:free             Agentica: Deepcoder 14B Preview (free)  1744555395  DeepCoder-14B-Preview is a 14B parameter code ...           96000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1              0                  0               0             0                  0                          0                      96000.0                                 NaN                      False                      NaN                       NaN\n",
       "54                moonshotai/kimi-vl-a3b-thinking:free           Moonshot AI: Kimi VL A3B Thinking (free)  1744304841  Kimi-VL is a lightweight Mixture-of-Experts vi...          131072               None  [max_tokens, temperature, top_p, reasoning, in...      text+image->text                 [image, text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "55                               x-ai/grok-3-mini-beta                              xAI: Grok 3 Mini Beta  1744240195  Grok 3 Mini is a lightweight, smaller thinking...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                   Grok                       None      0.0000003          0.0000005               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "56                                    x-ai/grok-3-beta                                   xAI: Grok 3 Beta  1744240068  Grok 3 is the latest model from xAI. It's thei...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                   Grok                       None       0.000003           0.000015               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "57         nvidia/llama-3.3-nemotron-super-49b-v1:free     NVIDIA: Llama 3.3 Nemotron Super 49B v1 (free)  1744119494  Llama-3.3-Nemotron-Super-49B-v1 is a large lan...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "58              nvidia/llama-3.3-nemotron-super-49b-v1            NVIDIA: Llama 3.3 Nemotron Super 49B v1  1744119494  Llama-3.3-Nemotron-Super-49B-v1 is a large lan...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None     0.00000013          0.0000004               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "59        nvidia/llama-3.1-nemotron-ultra-253b-v1:free    NVIDIA: Llama 3.1 Nemotron Ultra 253B v1 (free)  1744115059  Llama-3.1-Nemotron-Ultra-253B-v1 is a large la...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                       None              0                  0               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "60                    meta-llama/llama-4-maverick:free                      Meta: Llama 4 Maverick (free)  1743881822  Llama 4 Maverick 17B Instruct (128E) is a high...          256000               None  [max_tokens, temperature, top_p, structured_ou...      text+image->text                 [text, image]                         [text]                  Other                       None              0                  0               0             0                  0                          0                     256000.0                                 NaN                      False                      NaN                       NaN\n",
       "61                         meta-llama/llama-4-maverick                             Meta: Llama 4 Maverick  1743881822  Llama 4 Maverick 17B Instruct (128E) is a high...         1048576               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                  Other                       None     0.00000017          0.0000006               0     0.0006684                  0                          0                    1048576.0                             16384.0                      False                      NaN                       NaN\n",
       "62                       meta-llama/llama-4-scout:free                         Meta: Llama 4 Scout (free)  1743881519  Llama 4 Scout 17B Instruct (16E) is a mixture-...          512000               None  [max_tokens, temperature, top_p, structured_ou...      text+image->text                 [text, image]                         [text]                  Other                       None              0                  0               0             0                  0                          0                     512000.0                                 NaN                      False                      NaN                       NaN\n",
       "63                            meta-llama/llama-4-scout                                Meta: Llama 4 Scout  1743881519  Llama 4 Scout 17B Instruct (16E) is a mixture-...         1048576               None  [max_tokens, temperature, top_p, presence_pena...      text+image->text                 [text, image]                         [text]                  Other                       None     0.00000008          0.0000003               0             0                  0                          0                    1048576.0                           1048576.0                      False                      NaN                       NaN\n",
       "64                     all-hands/openhands-lm-32b-v0.1                              OpenHands LM 32B V0.1  1743613013  OpenHands LM v0.1 is a 32B open-source coding ...           16384               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                  Other                       None      0.0000026          0.0000034               0             0                  0                          0                      16384.0                              4096.0                      False                      NaN                       NaN\n",
       "65                                mistral/ministral-8b                              Mistral: Ministral 8B  1743430021  Ministral 8B is a state-of-the-art language mo...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None      0.0000001          0.0000001               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "66                      deepseek/deepseek-v3-base:free                  DeepSeek: DeepSeek V3 Base (free)  1743272023  Note that this is a base model mostly meant fo...          163840               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]               DeepSeek                       None              0                  0               0             0                  0                          0                     163840.0                                 NaN                      False                      NaN                       NaN\n",
       "67                scb10x/llama3.1-typhoon2-8b-instruct                               Typhoon2 8B Instruct  1743196511  Llama3.1-Typhoon2-8B-Instruct is a Thai-Englis...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3     0.00000018         0.00000018               0             0                  0                          0                       8192.0                                 NaN                      False                      NaN                       NaN\n",
       "68               scb10x/llama3.1-typhoon2-70b-instruct                              Typhoon2 70B Instruct  1743196170  Llama3.1-Typhoon2-70B-Instruct is a Thai-Engli...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3     0.00000088         0.00000088               0             0                  0                          0                       8192.0                                 NaN                      False                      NaN                       NaN\n",
       "69                             allenai/molmo-7b-d:free                         AllenAI: Molmo 7B D (free)  1743023247  Molmo is a family of open vision-language mode...            4096               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                  Other                       None              0                  0               0             0                  0                          0                       4096.0                                 NaN                      False                      NaN                       NaN\n",
       "70                 bytedance-research/ui-tars-72b:free                     Bytedance: UI-TARS 72B  (free)  1743020065  UI-TARS 72B is an open-source multimodal AI mo...           32768               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                  Other                       None              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "71                    qwen/qwen2.5-vl-3b-instruct:free                Qwen: Qwen2.5 VL 3B Instruct (free)  1743014573  Qwen2.5 VL 3B is a multimodal LLM from the Qwe...           64000               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                   Qwen                       None              0                  0               0             0                  0                          0                      64000.0                                 NaN                      False                      NaN                       NaN\n",
       "72                     google/gemini-2.5-pro-exp-03-25                Google: Gemini 2.5 Pro Experimental  1742922099  Gemini 2.5 Pro is Google’s state-of-the-art AI...         1000000               None  [max_tokens, temperature, top_p, tools, tool_c...      text+image->text           [text, image, file]                         [text]                 Gemini                       None              0                  0               0             0                  0                          0                    1000000.0                             65535.0                      False                      NaN                       NaN\n",
       "73                   qwen/qwen2.5-vl-32b-instruct:free               Qwen: Qwen2.5 VL 32B Instruct (free)  1742839838  Qwen2.5-VL-32B is a multimodal vision-language...            8192               None  [max_tokens, temperature, top_p, seed, respons...      text+image->text                 [text, image]                         [text]                   Qwen                       None              0                  0               0             0                  0                          0                       8192.0                                 NaN                      False                      NaN                       NaN\n",
       "74                        qwen/qwen2.5-vl-32b-instruct                      Qwen: Qwen2.5 VL 32B Instruct  1742839838  Qwen2.5-VL-32B is a multimodal vision-language...          128000               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                   Qwen                       None      0.0000009          0.0000009               0             0                  0                          0                     128000.0                                 NaN                      False                      NaN                       NaN\n",
       "75                 deepseek/deepseek-chat-v3-0324:free                  DeepSeek: DeepSeek V3 0324 (free)  1742824755  DeepSeek V3, a 685B-parameter, mixture-of-expe...          163840               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]               DeepSeek                       None              0                  0               0             0                  0                          0                     163840.0                                 NaN                      False                      NaN                       NaN\n",
       "76                      deepseek/deepseek-chat-v3-0324                         DeepSeek: DeepSeek V3 0324  1742824755  DeepSeek V3, a 685B-parameter, mixture-of-expe...          163840               None  [max_tokens, temperature, top_p, presence_pena...            text->text                        [text]                         [text]               DeepSeek                       None      0.0000003         0.00000088               0             0                  0                          0                     163840.0                                 NaN                      False                      NaN                       NaN\n",
       "77                         featherless/qwerky-72b:free                                  Qwerky 72B (free)  1742481597  Qwerky-72B is a linear-attention RWKV variant ...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                      32768.0                              4096.0                      False                      NaN                       NaN\n",
       "78                                       openai/o1-pro                                     OpenAI: o1-pro  1742423211  The o1 series of models are trained with reinf...          200000               None  [max_tokens, temperature, top_p, reasoning, in...      text+image->text                 [text, image]                         [text]                    GPT                       None        0.00015             0.0006               0       0.21675                  0                          0                     200000.0                            100000.0                       True                      NaN                       NaN\n",
       "79       mistralai/mistral-small-3.1-24b-instruct:free              Mistral: Mistral Small 3.1 24B (free)  1742238937  Mistral Small 3.1 24B Instruct is an upgraded ...           96000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                Mistral                       None              0                  0               0             0                  0                          0                      96000.0                             96000.0                      False                      NaN                       NaN\n",
       "80            mistralai/mistral-small-3.1-24b-instruct                     Mistral: Mistral Small 3.1 24B  1742238937  Mistral Small 3.1 24B Instruct is an upgraded ...          131072               None  [max_tokens, temperature, top_p, presence_pena...      text+image->text                 [text, image]                         [text]                Mistral                       None     0.00000005         0.00000015               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "81                       open-r1/olympiccoder-32b:free                            OlympicCoder 32B (free)  1742077228  OlympicCoder-32B is a high-performing open-sou...           32768               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "82                           google/gemma-3-1b-it:free                          Google: Gemma 3 1B (free)  1741963556  Gemma 3 1B is the smallest of the new Gemma 3 ...           32768               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Gemini                      gemma              0                  0               0             0                  0                          0                      32768.0                              8192.0                      False                      NaN                       NaN\n",
       "83                           google/gemma-3-4b-it:free                          Google: Gemma 3 4B (free)  1741905510  Gemma 3 introduces multimodality, supporting v...          131072               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Gemini                      gemma              0                  0               0             0                  0                          0                     131072.0                              8192.0                      False                      NaN                       NaN\n",
       "84                                google/gemma-3-4b-it                                 Google: Gemma 3 4B  1741905510  Gemma 3 introduces multimodality, supporting v...          131072               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Gemini                      gemma     0.00000002         0.00000004               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "85                                ai21/jamba-1.6-large                              AI21: Jamba 1.6 Large  1741905173  AI21 Jamba Large 1.6 is a high-performance hyb...          256000               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                  Other                       None       0.000002           0.000008               0             0                  0                          0                     256000.0                              4096.0                      False                      NaN                       NaN\n",
       "86                                 ai21/jamba-1.6-mini                               AI21: Jamba Mini 1.6  1741905171  AI21 Jamba Mini 1.6 is a hybrid foundation mod...          256000               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                  Other                       None      0.0000002          0.0000004               0             0                  0                          0                     256000.0                              4096.0                      False                      NaN                       NaN\n",
       "87                          google/gemma-3-12b-it:free                         Google: Gemma 3 12B (free)  1741902625  Gemma 3 introduces multimodality, supporting v...          131072               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Gemini                      gemma              0                  0               0             0                  0                          0                     131072.0                              8192.0                      False                      NaN                       NaN\n",
       "88                               google/gemma-3-12b-it                                Google: Gemma 3 12B  1741902625  Gemma 3 introduces multimodality, supporting v...          131072               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Gemini                      gemma     0.00000005          0.0000001               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "89                                    cohere/command-a                                  Cohere: Command A  1741894342  Command A is an open-weights 111B parameter mo...          256000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None      0.0000025            0.00001               0             0                  0                          0                     256000.0                              8192.0                      False                      NaN                       NaN\n",
       "90                   openai/gpt-4o-mini-search-preview                 OpenAI: GPT-4o-mini Search Preview  1741818122  GPT-4o mini Search Preview is a specialized mo...          128000               None  [web_search_options, max_tokens, response_form...            text->text                        [text]                         [text]                    GPT                       None     0.00000015          0.0000006          0.0275      0.000217                  0                          0                     128000.0                             16384.0                       True                      NaN                       NaN\n",
       "91                        openai/gpt-4o-search-preview                      OpenAI: GPT-4o Search Preview  1741817949  GPT-4o Search Previewis a specialized model fo...          128000               None  [web_search_options, max_tokens, response_form...            text->text                        [text]                         [text]                    GPT                       None      0.0000025            0.00001           0.035      0.003613                  0                          0                     128000.0                             16384.0                       True                      NaN                       NaN\n",
       "92                            rekaai/reka-flash-3:free                               Reka: Flash 3 (free)  1741812813  Reka Flash 3 is a general-purpose, instruction...           32768               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "93                          google/gemma-3-27b-it:free                         Google: Gemma 3 27B (free)  1741756359  Gemma 3 introduces multimodality, supporting v...           96000               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Gemini                      gemma              0                  0               0             0                  0                          0                      96000.0                              8192.0                      False                      NaN                       NaN\n",
       "94                               google/gemma-3-27b-it                                Google: Gemma 3 27B  1741756359  Gemma 3 introduces multimodality, supporting v...          131072               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Gemini                      gemma      0.0000001          0.0000002               0     0.0000256                  0                          0                     131072.0                             16384.0                      False                      NaN                       NaN\n",
       "95                       thedrummer/anubis-pro-105b-v1                     TheDrummer: Anubis Pro 105B V1  1741642290  Anubis Pro 105B v1 is an expanded and refined ...          131072               None  [max_tokens, temperature, top_p, presence_pena...            text->text                        [text]                         [text]                  Other                       None      0.0000008           0.000001               0             0                  0                          0                     131072.0                            131072.0                      False                      NaN                       NaN\n",
       "96                           thedrummer/skyfall-36b-v2                         TheDrummer: Skyfall 36B V2  1741636566  Skyfall 36B v2 is an enhanced iteration of Mis...           32768               None  [max_tokens, temperature, top_p, presence_pena...            text->text                        [text]                         [text]                  Other                       None      0.0000005          0.0000008               0             0                  0                          0                      32768.0                             32768.0                      False                      NaN                       NaN\n",
       "97                 microsoft/phi-4-multimodal-instruct               Microsoft: Phi 4 Multimodal Instruct  1741396284  Phi-4 Multimodal Instruct is a versatile 5.6B ...          131072               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                  Other                       None     0.00000005          0.0000001               0    0.00017685                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "98                      perplexity/sonar-reasoning-pro                    Perplexity: Sonar Reasoning Pro  1741313308  Note: Sonar Pro pricing includes Perplexity se...          128000               None  [max_tokens, temperature, top_p, reasoning, in...      text+image->text                 [text, image]                         [text]                  Other                deepseek-r1       0.000002           0.000008               0             0              0.005                          0                     128000.0                                 NaN                      False                      NaN                       NaN\n",
       "99                                perplexity/sonar-pro                              Perplexity: Sonar Pro  1741312423  Note: Sonar Pro pricing includes Perplexity se...          200000               None  [max_tokens, temperature, top_p, web_search_op...      text+image->text                 [text, image]                         [text]                  Other                       None       0.000003           0.000015               0             0              0.005                          0                     200000.0                              8000.0                      False                      NaN                       NaN\n",
       "100                     perplexity/sonar-deep-research                    Perplexity: Sonar Deep Research  1741311246  Sonar Deep Research is a research-focused mode...          128000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1       0.000002           0.000008               0             0              0.005                   0.000003                     128000.0                                 NaN                      False                      NaN                       NaN\n",
       "101                     deepseek/deepseek-r1-zero:free                  DeepSeek: DeepSeek R1 Zero (free)  1741297434  DeepSeek-R1-Zero is a model trained via large-...          163840               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1              0                  0               0             0                  0                          0                     163840.0                                 NaN                      False                      NaN                       NaN\n",
       "102                                  qwen/qwq-32b:free                               Qwen: QwQ 32B (free)  1741208814  QwQ is the reasoning model of the Qwen series....           40000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                   Qwen                        qwq              0                  0               0             0                  0                          0                      40000.0                             40000.0                      False                      NaN                       NaN\n",
       "103                                       qwen/qwq-32b                                      Qwen: QwQ 32B  1741208814  QwQ is the reasoning model of the Qwen series....          131072               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                   Qwen                        qwq     0.00000015          0.0000002               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "104         moonshotai/moonlight-16b-a3b-instruct:free     Moonshot AI: Moonlight 16B A3B Instruct (free)  1740719801  Moonlight-16B-A3B-Instruct is a 16B-parameter ...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                       8192.0                                 NaN                      False                      NaN                       NaN\n",
       "105  nousresearch/deephermes-3-llama-3-8b-preview:free       Nous: DeepHermes 3 Llama 3 8B Preview (free)  1740719372  DeepHermes 3 Preview is the latest version of ...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "106                             openai/gpt-4.5-preview                          OpenAI: GPT-4.5 (Preview)  1740687810  GPT-4.5 (Preview) is a research preview of Ope...          128000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                    GPT                       None       0.000075            0.00015               0      0.108375                  0                          0                     128000.0                             16384.0                       True                0.0000375                       NaN\n",
       "107                   google/gemini-2.0-flash-lite-001                      Google: Gemini 2.0 Flash Lite  1740506212  Gemini 2.0 Flash Lite offers a significantly f...         1048576               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text           [text, image, file]                         [text]                 Gemini                       None    0.000000075          0.0000003               0             0                  0                          0                    1048576.0                              8192.0                      False                      NaN                       NaN\n",
       "108                        anthropic/claude-3.7-sonnet                       Anthropic: Claude 3.7 Sonnet  1740422110  Claude 3.7 Sonnet is an advanced large languag...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None       0.000003           0.000015               0        0.0048                  0                          0                     200000.0                             64000.0                      False                0.0000003                0.00000375\n",
       "109               anthropic/claude-3.7-sonnet:thinking            Anthropic: Claude 3.7 Sonnet (thinking)  1740422110  Claude 3.7 Sonnet is an advanced large languag...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None       0.000003           0.000015               0        0.0048                  0                          0                     200000.0                             64000.0                      False                0.0000003                0.00000375\n",
       "110                   anthropic/claude-3.7-sonnet:beta      Anthropic: Claude 3.7 Sonnet (self-moderated)  1740422110  Claude 3.7 Sonnet is an advanced large languag...          200000               None  [max_tokens, temperature, stop, reasoning, inc...      text+image->text                 [text, image]                         [text]                 Claude                       None       0.000003           0.000015               0        0.0048                  0                          0                     200000.0                            128000.0                      False                0.0000003                0.00000375\n",
       "111                                 perplexity/r1-1776                                Perplexity: R1 1776  1740004929  R1 1776 is a version of DeepSeek-R1 that has b...          128000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]               DeepSeek                deepseek-r1       0.000002           0.000008               0             0                  0                          0                     128000.0                                 NaN                      False                      NaN                       NaN\n",
       "112                             mistralai/mistral-saba                                      Mistral: Saba  1739803239  Mistral Saba is a 24B-parameter language model...           32768               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None      0.0000002          0.0000006               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "113  cognitivecomputations/dolphin3.0-r1-mistral-24...                   Dolphin3.0 R1 Mistral 24B (free)  1739462498  Dolphin 3.0 R1 is the next generation of the D...           32768               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "114  cognitivecomputations/dolphin3.0-mistral-24b:free                      Dolphin3.0 Mistral 24B (free)  1739462019  Dolphin 3.0 is the next generation of the Dolp...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "115                        meta-llama/llama-guard-3-8b                                   Llama Guard 3 8B  1739401318  Llama Guard 3 is a Llama-3.1-8B pretrained mod...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                       none     0.00000002         0.00000006               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "116                                openai/o3-mini-high                               OpenAI: o3 Mini High  1739372611  OpenAI o3-mini-high is the same model as [o3-m...          200000               None  [tools, tool_choice, seed, max_tokens, respons...            text->text                        [text]                         [text]                  Other                       None      0.0000011          0.0000044               0             0                  0                          0                     200000.0                            100000.0                       True               0.00000055                       NaN\n",
       "117              deepseek/deepseek-r1-distill-llama-8b                      DeepSeek: R1 Distill Llama 8B  1738937718  DeepSeek R1 Distill Llama 8B is a distilled la...           32000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                 Llama3                deepseek-r1     0.00000004         0.00000004               0             0                  0                          0                      32000.0                             32000.0                      False                      NaN                       NaN\n",
       "118                        google/gemini-2.0-flash-001                           Google: Gemini 2.0 Flash  1738769413  Gemini Flash 2.0 offers a significantly faster...         1000000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text           [text, image, file]                         [text]                 Gemini                       None      0.0000001          0.0000004               0     0.0000258                  0                          0                    1000000.0                              8192.0                      False              0.000000025              0.0000001833\n",
       "119                                  qwen/qwen-vl-plus                                 Qwen: Qwen VL Plus  1738731255  Qwen's Enhanced Large Visual Language Model. S...            7500               None  [max_tokens, temperature, top_p, seed, respons...      text+image->text                 [text, image]                         [text]                   Qwen                       None     0.00000021         0.00000063               0     0.0002688                  0                          0                       7500.0                              1500.0                      False                      NaN                       NaN\n",
       "120                                 aion-labs/aion-1.0                                 AionLabs: Aion-1.0  1738697557  Aion-1.0 is a multi-model system designed for ...          131072               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                       None       0.000004           0.000008               0             0                  0                          0                     131072.0                             32768.0                      False                      NaN                       NaN\n",
       "121                            aion-labs/aion-1.0-mini                            AionLabs: Aion-1.0-Mini  1738697107  Aion-1.0-Mini 32B parameter model is a distill...          131072               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                       None      0.0000007          0.0000014               0             0                  0                          0                     131072.0                             32768.0                      False                      NaN                       NaN\n",
       "122                     aion-labs/aion-rp-llama-3.1-8b                         AionLabs: Aion-RP 1.0 (8B)  1738696718  Aion-RP-Llama-3.1-8B ranks the highest in the ...           32768               None                   [max_tokens, temperature, top_p]            text->text                        [text]                         [text]                  Other                       None      0.0000002          0.0000002               0             0                  0                          0                      32768.0                             32768.0                      False                      NaN                       NaN\n",
       "123                                   qwen/qwen-vl-max                                  Qwen: Qwen VL Max  1738434304  Qwen VL Max is a visual understanding model wi...            7500               None  [max_tokens, temperature, top_p, seed, respons...      text+image->text                 [text, image]                         [text]                   Qwen                       None      0.0000008          0.0000032               0      0.001024                  0                          0                       7500.0                              1500.0                      False                      NaN                       NaN\n",
       "124                                    qwen/qwen-turbo                                   Qwen: Qwen-Turbo  1738410974  Qwen-Turbo, based on Qwen2.5, is a 1M context ...         1000000               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                   Qwen                       None     0.00000005          0.0000002               0             0                  0                          0                    1000000.0                              8192.0                      False                      NaN                       NaN\n",
       "125                  qwen/qwen2.5-vl-72b-instruct:free               Qwen: Qwen2.5 VL 72B Instruct (free)  1738410311  Qwen2.5-VL is proficient in recognizing common...          131072               None  [max_tokens, temperature, top_p, seed, respons...      text+image->text                 [text, image]                         [text]                   Qwen                       None              0                  0               0             0                  0                          0                     131072.0                              2048.0                      False                      NaN                       NaN\n",
       "126                       qwen/qwen2.5-vl-72b-instruct                      Qwen: Qwen2.5 VL 72B Instruct  1738410311  Qwen2.5-VL is proficient in recognizing common...           32000               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                   Qwen                       None     0.00000025         0.00000075               0             0                  0                          0                      32000.0                                 NaN                      False                      NaN                       NaN\n",
       "127                                     qwen/qwen-plus                                    Qwen: Qwen-Plus  1738409840  Qwen-Plus, based on the Qwen2.5 foundation mod...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                   Qwen                       None      0.0000004          0.0000012               0             0                  0                          0                     131072.0                              8192.0                      False                      NaN                       NaN\n",
       "128                                      qwen/qwen-max                                    Qwen: Qwen-Max   1738402289  Qwen-Max, based on Qwen2.5, provides the best ...           32768               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                   Qwen                       None      0.0000016          0.0000064               0             0                  0                          0                      32768.0                              8192.0                      False                      NaN                       NaN\n",
       "129                                     openai/o3-mini                                    OpenAI: o3 Mini  1738351721  OpenAI o3-mini is a cost-efficient language mo...          200000               None  [tools, tool_choice, seed, max_tokens, respons...            text->text                        [text]                         [text]                  Other                       None      0.0000011          0.0000044               0             0                  0                          0                     200000.0                            100000.0                       True               0.00000055                       NaN\n",
       "130             deepseek/deepseek-r1-distill-qwen-1.5b                     DeepSeek: R1 Distill Qwen 1.5B  1738328067  DeepSeek R1 Distill Qwen 1.5B is a distilled l...          131072               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1     0.00000018         0.00000018               0             0                  0                          0                     131072.0                             32768.0                      False                      NaN                       NaN\n",
       "131     mistralai/mistral-small-24b-instruct-2501:free                    Mistral: Mistral Small 3 (free)  1738255409  Mistral Small 3 is a 24B-parameter language mo...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                       None              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "132          mistralai/mistral-small-24b-instruct-2501                           Mistral: Mistral Small 3  1738255409  Mistral Small 3 is a 24B-parameter language mo...           28000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                       None     0.00000006         0.00000012               0             0                  0                          0                      28000.0                             14000.0                      False                      NaN                       NaN\n",
       "133         deepseek/deepseek-r1-distill-qwen-32b:free               DeepSeek: R1 Distill Qwen 32B (free)  1738194830  DeepSeek R1 Distill Qwen 32B is a distilled la...           16000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                   Qwen                deepseek-r1              0                  0               0             0                  0                          0                      16000.0                             16000.0                      False                      NaN                       NaN\n",
       "134              deepseek/deepseek-r1-distill-qwen-32b                      DeepSeek: R1 Distill Qwen 32B  1738194830  DeepSeek R1 Distill Qwen 32B is a distilled la...          131072               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                   Qwen                deepseek-r1     0.00000012         0.00000018               0             0                  0                          0                     131072.0                             16384.0                      False                      NaN                       NaN\n",
       "135         deepseek/deepseek-r1-distill-qwen-14b:free               DeepSeek: R1 Distill Qwen 14B (free)  1738193940  DeepSeek R1 Distill Qwen 14B is a distilled la...           64000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                   Qwen                deepseek-r1              0                  0               0             0                  0                          0                      64000.0                                 NaN                      False                      NaN                       NaN\n",
       "136              deepseek/deepseek-r1-distill-qwen-14b                      DeepSeek: R1 Distill Qwen 14B  1738193940  DeepSeek R1 Distill Qwen 14B is a distilled la...           64000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                   Qwen                deepseek-r1     0.00000015         0.00000015               0             0                  0                          0                      64000.0                             64000.0                      False                      NaN                       NaN\n",
       "137                         perplexity/sonar-reasoning                        Perplexity: Sonar Reasoning  1738131107  Sonar Reasoning is a reasoning model provided ...          127000               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                  Other                deepseek-r1       0.000001           0.000005           0.005             0                  0                          0                     127000.0                                 NaN                      False                      NaN                       NaN\n",
       "138                                   perplexity/sonar                                  Perplexity: Sonar  1738013808  Sonar is lightweight, affordable, fast, and si...          127072               None  [max_tokens, temperature, top_p, web_search_op...      text+image->text                 [text, image]                         [text]                  Other                       None       0.000001           0.000001           0.005             0                  0                          0                     127072.0                                 NaN                      False                      NaN                       NaN\n",
       "139                                      liquid/lfm-7b                                     Liquid: LFM 7B  1737806883  LFM-7B, a new best-in-class language model. LF...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                     chatml     0.00000001         0.00000001               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "140                                      liquid/lfm-3b                                     Liquid: LFM 3B  1737806501  Liquid's LFM 3B delivers incredible performanc...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                     chatml     0.00000002         0.00000002               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "141        deepseek/deepseek-r1-distill-llama-70b:free              DeepSeek: R1 Distill Llama 70B (free)  1737663169  DeepSeek R1 Distill Llama 70B is a distilled l...            8192               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                 Llama3                deepseek-r1              0                  0               0             0                  0                          0                       8192.0                              4096.0                      False                      NaN                       NaN\n",
       "142             deepseek/deepseek-r1-distill-llama-70b                     DeepSeek: R1 Distill Llama 70B  1737663169  DeepSeek R1 Distill Llama 70B is a distilled l...          131072               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]                 Llama3                deepseek-r1      0.0000001          0.0000004               0             0                  0                          0                     131072.0                             16384.0                      False                      NaN                       NaN\n",
       "143                          deepseek/deepseek-r1:free                                DeepSeek: R1 (free)  1737381095  DeepSeek R1 is here: Performance on par with [...          163840               None  [max_tokens, reasoning, include_reasoning, tem...            text->text                        [text]                         [text]               DeepSeek                deepseek-r1              0                  0               0             0                  0                          0                     163840.0                                 NaN                      False                      NaN                       NaN\n",
       "144                               deepseek/deepseek-r1                                       DeepSeek: R1  1737381095  DeepSeek R1 is here: Performance on par with [...          163840               None  [max_tokens, temperature, top_p, reasoning, in...            text->text                        [text]                         [text]               DeepSeek                deepseek-r1      0.0000005         0.00000218               0             0                  0                          0                     163840.0                            163840.0                      False                      NaN                       NaN\n",
       "145                                 minimax/minimax-01                                MiniMax: MiniMax-01  1736915462  MiniMax-01 is a combines MiniMax-Text-01 for t...         1000192               None                   [max_tokens, temperature, top_p]      text+image->text                 [text, image]                         [text]                  Other                       None      0.0000002          0.0000011               0             0                  0                          0                    1000192.0                           1000192.0                      False                      NaN                       NaN\n",
       "146                           mistralai/codestral-2501                            Mistral: Codestral 2501  1736895522  [Mistral](/mistralai)'s cutting-edge language ...          262144               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None      0.0000003          0.0000009               0             0                  0                          0                     262144.0                                 NaN                      False                      NaN                       NaN\n",
       "147                                    microsoft/phi-4                                   Microsoft: Phi 4  1736489872  [Microsoft Research](/microsoft) Phi-4 is desi...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None     0.00000007         0.00000014               0             0                  0                          0                      16384.0                             16384.0                      False                      NaN                       NaN\n",
       "148                        deepseek/deepseek-chat:free                       DeepSeek: DeepSeek V3 (free)  1735241320  DeepSeek-V3 is the latest model from the DeepS...          163840               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]               DeepSeek                       None              0                  0               0             0                  0                          0                     163840.0                                 NaN                      False                      NaN                       NaN\n",
       "149                             deepseek/deepseek-chat                              DeepSeek: DeepSeek V3  1735241320  DeepSeek-V3 is the latest model from the DeepS...          163840               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]               DeepSeek                       None     0.00000038         0.00000089               0             0                  0                          0                     163840.0                            163840.0                      False                      NaN                       NaN\n",
       "150                            sao10k/l3.3-euryale-70b                      Sao10K: Llama 3.3 Euryale 70B  1734535928  Euryale L3.3 70B is a model focused on creativ...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3      0.0000007          0.0000008               0             0                  0                          0                     131072.0                             16384.0                      False                      NaN                       NaN\n",
       "151                                          openai/o1                                         OpenAI: o1  1734459999  The latest and strongest model family from Ope...          200000               None  [tools, tool_choice, seed, max_tokens, respons...      text+image->text                 [text, image]                         [text]                    GPT                       None       0.000015            0.00006               0      0.021675                  0                          0                     200000.0                            100000.0                       True                0.0000075                       NaN\n",
       "152                     eva-unit-01/eva-llama-3.33-70b                                 EVA Llama 3.33 70B  1734377303  EVA Llama 3.33 70b is a roleplay and storywrit...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3       0.000004           0.000006               0             0                  0                          0                      16384.0                              4096.0                      False                      NaN                       NaN\n",
       "153                            x-ai/grok-2-vision-1212                            xAI: Grok 2 Vision 1212  1734237338  Grok 2 Vision 1212 advances image-based AI wit...           32768               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                   Grok                       None       0.000002            0.00001               0        0.0036                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "154                                   x-ai/grok-2-1212                                   xAI: Grok 2 1212  1734232814  Grok 2 1212 introduces significant enhancement...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                   Grok                       None       0.000002            0.00001               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "155                         cohere/command-r7b-12-2024                      Cohere: Command R7B (12-2024)  1734158152  Command R7B (12-2024) is a small, fast update ...          128000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Cohere                       None   0.0000000375         0.00000015               0             0                  0                          0                     128000.0                              4000.0                      False                      NaN                       NaN\n",
       "156                   google/gemini-2.0-flash-exp:free       Google: Gemini 2.0 Flash Experimental (free)  1733937523  Gemini Flash 2.0 offers a significantly faster...         1048576               None             [max_tokens, temperature, top_p, stop]      text+image->text                 [text, image]                         [text]                 Gemini                       None              0                  0               0             0                  0                          0                    1048576.0                              8192.0                      False                      NaN                       NaN\n",
       "157             meta-llama/llama-3.3-70b-instruct:free                Meta: Llama 3.3 70B Instruct (free)  1733506137  The Meta Llama 3.3 multilingual large language...            8000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3              0                  0               0             0                  0                          0                       8000.0                              8000.0                      False                      NaN                       NaN\n",
       "158                  meta-llama/llama-3.3-70b-instruct                       Meta: Llama 3.3 70B Instruct  1733506137  The Meta Llama 3.3 multilingual large language...          131000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3     0.00000009         0.00000035               0             0                  0                          0                     131000.0                            131000.0                      False                      NaN                       NaN\n",
       "159                                amazon/nova-lite-v1                              Amazon: Nova Lite 1.0  1733437363  Amazon Nova Lite 1.0 is a very low-cost multim...          300000               None  [tools, max_tokens, temperature, top_p, top_k,...      text+image->text                 [text, image]                         [text]                   Nova                       None     0.00000006         0.00000024               0       0.00009                  0                          0                     300000.0                              5120.0                       True                      NaN                       NaN\n",
       "160                               amazon/nova-micro-v1                             Amazon: Nova Micro 1.0  1733437237  Amazon Nova Micro 1.0 is a text-only model tha...          128000               None  [tools, max_tokens, temperature, top_p, top_k,...            text->text                        [text]                         [text]                   Nova                       None    0.000000035         0.00000014               0             0                  0                          0                     128000.0                              5120.0                       True                      NaN                       NaN\n",
       "161                                 amazon/nova-pro-v1                               Amazon: Nova Pro 1.0  1733436303  Amazon Nova Pro 1.0 is a capable multimodal mo...          300000               None  [tools, max_tokens, temperature, top_p, top_k,...      text+image->text                 [text, image]                         [text]                   Nova                       None      0.0000008          0.0000032               0        0.0012                  0                          0                     300000.0                              5120.0                       True                      NaN                       NaN\n",
       "162                          qwen/qwq-32b-preview:free                       Qwen: QwQ 32B Preview (free)  1732754541  QwQ-32B-Preview is an experimental research mo...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                deepseek-r1              0                  0               0             0                  0                          0                      16384.0                                 NaN                      False                      NaN                       NaN\n",
       "163                               qwen/qwq-32b-preview                              Qwen: QwQ 32B Preview  1732754541  QwQ-32B-Preview is an experimental research mo...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                deepseek-r1     0.00000009         0.00000027               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "164           google/learnlm-1.5-pro-experimental:free        Google: LearnLM 1.5 Pro Experimental (free)  1732216551  An experimental version of [Gemini 1.5 Pro](/g...           40960               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Gemini                       None              0                  0               0             0                  0                          0                      40960.0                              8192.0                      False                      NaN                       NaN\n",
       "165                       eva-unit-01/eva-qwen-2.5-72b                                    EVA Qwen2.5 72B  1732210606  EVA Qwen2.5 72B is a roleplay and storywriting...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml       0.000004           0.000006               0             0                  0                          0                      16384.0                              4096.0                      False                      NaN                       NaN\n",
       "166                           openai/gpt-4o-2024-11-20                        OpenAI: GPT-4o (2024-11-20)  1732127594  The 2024-11-20 version of GPT-4o offers a leve...          128000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text           [text, image, file]                         [text]                    GPT                       None      0.0000025            0.00001               0      0.003613                  0                          0                     128000.0                             16384.0                       True               0.00000125                       NaN\n",
       "167                       mistralai/mistral-large-2411                                 Mistral Large 2411  1731978685  Mistral Large 2 2411 is an update of [Mistral ...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None       0.000002           0.000006               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "168                       mistralai/mistral-large-2407                                 Mistral Large 2407  1731978415  This is Mistral AI's flagship model, Mistral L...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None       0.000002           0.000006               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "169                       mistralai/pixtral-large-2411                        Mistral: Pixtral Large 2411  1731977388  Pixtral Large is a 124B parameter, open-weight...          131072               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                Mistral                       None       0.000002           0.000006               0      0.002888                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "170                              x-ai/grok-vision-beta                              xAI: Grok Vision Beta  1731976624  Grok Vision Beta is xAI's experimental languag...            8192               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                   Grok                       None       0.000005           0.000015               0         0.009                  0                          0                       8192.0                                 NaN                      False                      NaN                       NaN\n",
       "171                          infermatic/mn-inferor-12b               Infermatic: Mistral Nemo Inferor 12B  1731464428  Inferor 12B is a merge of top roleplay models,...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                    mistral      0.0000008          0.0000012               0             0                  0                          0                      16384.0                              4096.0                      False                      NaN                       NaN\n",
       "172              qwen/qwen-2.5-coder-32b-instruct:free                  Qwen2.5 Coder 32B Instruct (free)  1731368400  Qwen2.5-Coder is the latest series of Code-Spe...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "173                   qwen/qwen-2.5-coder-32b-instruct                         Qwen2.5 Coder 32B Instruct  1731368400  Qwen2.5-Coder is the latest series of Code-Spe...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml     0.00000006         0.00000015               0             0                  0                          0                      32768.0                             16384.0                      False                      NaN                       NaN\n",
       "174                            raifle/sorcererlm-8x22b                                   SorcererLM 8x22B  1731105083  SorcererLM is an advanced RP and storytelling ...           16000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                     vicuna      0.0000045          0.0000045               0             0                  0                          0                      16000.0                                 NaN                      False                      NaN                       NaN\n",
       "175                       eva-unit-01/eva-qwen-2.5-32b                                    EVA Qwen2.5 32B  1731104847  EVA Qwen2.5 32B is a roleplaying/storywriting ...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml      0.0000026          0.0000034               0             0                  0                          0                      16384.0                              4096.0                      False                      NaN                       NaN\n",
       "176                          thedrummer/unslopnemo-12b                                     Unslopnemo 12B  1731103448  UnslopNemo v4.1 is the latest addition from th...           32000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                    mistral     0.00000045         0.00000045               0             0                  0                          0                      32000.0                             16000.0                      False                      NaN                       NaN\n",
       "177                    anthropic/claude-3.5-haiku:beta       Anthropic: Claude 3.5 Haiku (self-moderated)  1730678400  Claude 3.5 Haiku features offers enhanced capa...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None      0.0000008           0.000004               0             0                  0                          0                     200000.0                              8192.0                      False               0.00000008                  0.000001\n",
       "178                         anthropic/claude-3.5-haiku                        Anthropic: Claude 3.5 Haiku  1730678400  Claude 3.5 Haiku features offers enhanced capa...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None      0.0000008           0.000004               0             0                  0                          0                     200000.0                              8192.0                       True               0.00000008                  0.000001\n",
       "179           anthropic/claude-3.5-haiku-20241022:beta  Anthropic: Claude 3.5 Haiku (2024-10-22) (self...  1730678400  Claude 3.5 Haiku features enhancements across ...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None      0.0000008           0.000004               0             0                  0                          0                     200000.0                              8192.0                      False               0.00000008                  0.000001\n",
       "180                anthropic/claude-3.5-haiku-20241022           Anthropic: Claude 3.5 Haiku (2024-10-22)  1730678400  Claude 3.5 Haiku features enhancements across ...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None      0.0000008           0.000004               0             0                  0                          0                     200000.0                              8192.0                       True               0.00000008                  0.000001\n",
       "181                  neversleep/llama-3.1-lumimaid-70b                      NeverSleep: Lumimaid v0.2 70B  1729555200  Lumimaid v0.2 70B is a finetune of [Llama 3.1 ...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3      0.0000015         0.00000225               0             0                  0                          0                      16384.0                              2048.0                      False                      NaN                       NaN\n",
       "182                       anthracite-org/magnum-v4-72b                                      Magnum v4 72B  1729555200  This is a series of models designed to replica...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml      0.0000015         0.00000225               0             0                  0                          0                      16384.0                              1024.0                      False                      NaN                       NaN\n",
       "183                   anthropic/claude-3.5-sonnet:beta      Anthropic: Claude 3.5 Sonnet (self-moderated)  1729555200  New Claude 3.5 Sonnet delivers better-than-Opu...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None       0.000003           0.000015               0        0.0048                  0                          0                     200000.0                              8192.0                      False                0.0000003                0.00000375\n",
       "184                        anthropic/claude-3.5-sonnet                       Anthropic: Claude 3.5 Sonnet  1729555200  New Claude 3.5 Sonnet delivers better-than-Opu...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None       0.000003           0.000015               0        0.0048                  0                          0                     200000.0                              8192.0                       True                0.0000003                0.00000375\n",
       "185                                     x-ai/grok-beta                                     xAI: Grok Beta  1729382400  Grok Beta is xAI's experimental language model...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                   Grok                       None       0.000005           0.000015               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "186                             mistralai/ministral-8b                              Mistral: Ministral 8B  1729123200  Ministral 8B is an 8B parameter model featurin...          128000               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None      0.0000001          0.0000001               0             0                  0                          0                     128000.0                                 NaN                      False                      NaN                       NaN\n",
       "187                             mistralai/ministral-3b                              Mistral: Ministral 3B  1729123200  Ministral 3B is a 3B parameter model optimized...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None     0.00000004         0.00000004               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "188                     qwen/qwen-2.5-7b-instruct:free                         Qwen2.5 7B Instruct (free)  1729036800  Qwen2.5 7B is the latest series of Qwen large ...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml              0                  0               0             0                  0                          0                      32768.0                             32768.0                      False                      NaN                       NaN\n",
       "189                          qwen/qwen-2.5-7b-instruct                                Qwen2.5 7B Instruct  1729036800  Qwen2.5 7B is the latest series of Qwen large ...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml     0.00000005          0.0000001               0             0                  0                          0                      32768.0                             16384.0                      False                      NaN                       NaN\n",
       "190             nvidia/llama-3.1-nemotron-70b-instruct            NVIDIA: Llama 3.1 Nemotron 70B Instruct  1728950400  NVIDIA's Llama 3.1 Nemotron 70B is a language ...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3     0.00000012          0.0000003               0             0                  0                          0                     131072.0                            131072.0                      False                      NaN                       NaN\n",
       "191               inflection/inflection-3-productivity              Inflection: Inflection 3 Productivity  1728604800  Inflection 3 Productivity is optimized for fol...            8000               None             [max_tokens, temperature, top_p, stop]            text->text                        [text]                         [text]                  Other                       None      0.0000025            0.00001               0             0                  0                          0                       8000.0                              1024.0                      False                      NaN                       NaN\n",
       "192                         inflection/inflection-3-pi                        Inflection: Inflection 3 Pi  1728604800  Inflection 3 Pi powers Inflection's [Pi](https...            8000               None             [max_tokens, temperature, top_p, stop]            text->text                        [text]                         [text]                  Other                       None      0.0000025            0.00001               0             0                  0                          0                       8000.0                              1024.0                      False                      NaN                       NaN\n",
       "193                         google/gemini-flash-1.5-8b                        Google: Gemini 1.5 Flash 8B  1727913600  Gemini Flash 1.5 8B is optimized for speed and...         1000000               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Gemini                       None   0.0000000375         0.00000015               0             0                  0                          0                    1000000.0                              8192.0                      False               0.00000001              0.0000000583\n",
       "194                           thedrummer/rocinante-12b                                      Rocinante 12B  1727654400  Rocinante 12B is designed for engaging storyte...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml     0.00000025          0.0000005               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "195                       anthracite-org/magnum-v2-72b                                      Magnum v2 72B  1727654400  From the maker of [Goliath](https://openrouter...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml       0.000003           0.000003               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "196                                     liquid/lfm-40b                                Liquid: LFM 40B MoE  1727654400  Liquid's 40.3B Mixture of Experts (MoE) model....           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                     chatml     0.00000015         0.00000015               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "197              meta-llama/llama-3.2-3b-instruct:free                 Meta: Llama 3.2 3B Instruct (free)  1727222400  Llama 3.2 3B is a 3-billion-parameter multilin...           20000               None                   [max_tokens, temperature, top_p]            text->text                        [text]                         [text]                 Llama3                     llama3              0                  0               0             0                  0                          0                      20000.0                             20000.0                      False                      NaN                       NaN\n",
       "198                   meta-llama/llama-3.2-3b-instruct                        Meta: Llama 3.2 3B Instruct  1727222400  Llama 3.2 3B is a 3-billion-parameter multilin...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3     0.00000001         0.00000002               0             0                  0                          0                     131072.0                             16384.0                      False                      NaN                       NaN\n",
       "199              meta-llama/llama-3.2-1b-instruct:free                 Meta: Llama 3.2 1B Instruct (free)  1727222400  Llama 3.2 1B is a 1-billion-parameter language...          131000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3              0                  0               0             0                  0                          0                     131000.0                                 NaN                      False                      NaN                       NaN\n",
       "200                   meta-llama/llama-3.2-1b-instruct                        Meta: Llama 3.2 1B Instruct  1727222400  Llama 3.2 1B is a 1-billion-parameter language...          131072               None  [max_tokens, temperature, top_p, top_k, stop, ...            text->text                        [text]                         [text]                 Llama3                     llama3    0.000000005         0.00000001               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "201           meta-llama/llama-3.2-90b-vision-instruct                Meta: Llama 3.2 90B Vision Instruct  1727222400  The Llama 90B Vision model is a top-tier, 90-b...          131072               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Llama3                     llama3      0.0000012          0.0000012               0      0.001734                  0                          0                     131072.0                              2048.0                      False                      NaN                       NaN\n",
       "202      meta-llama/llama-3.2-11b-vision-instruct:free         Meta: Llama 3.2 11B Vision Instruct (free)  1727222400  Llama 3.2 11B Vision is a multimodal model wit...          131072               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Llama3                     llama3              0                  0               0             0                  0                          0                     131072.0                              2048.0                      False                      NaN                       NaN\n",
       "203           meta-llama/llama-3.2-11b-vision-instruct                Meta: Llama 3.2 11B Vision Instruct  1727222400  Llama 3.2 11B Vision is a multimodal model wit...          131072               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Llama3                     llama3    0.000000049        0.000000049               0    0.00007948                  0                          0                     131072.0                             16384.0                      False                      NaN                       NaN\n",
       "204                    qwen/qwen-2.5-72b-instruct:free                        Qwen2.5 72B Instruct (free)  1726704000  Qwen2.5 72B is the latest series of Qwen large...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml              0                  0               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "205                         qwen/qwen-2.5-72b-instruct                               Qwen2.5 72B Instruct  1726704000  Qwen2.5 72B is the latest series of Qwen large...           32768               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                   Qwen                     chatml     0.00000012         0.00000039               0             0                  0                          0                      32768.0                             16384.0                      False                      NaN                       NaN\n",
       "206                      qwen/qwen-2.5-vl-72b-instruct                      Qwen: Qwen2.5-VL 72B Instruct  1726617600  Qwen2.5 VL 72B is a multimodal LLM from the Qw...           32768               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                   Qwen                       None      0.0000006          0.0000006               0      0.000578                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "207                   neversleep/llama-3.1-lumimaid-8b                       NeverSleep: Lumimaid v0.2 8B  1726358400  Lumimaid v0.2 8B is a finetune of [Llama 3.1 8...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3  0.00000009375         0.00000075               0             0                  0                          0                      32768.0                              2048.0                      False                      NaN                       NaN\n",
       "208                                  openai/o1-preview                                 OpenAI: o1-preview  1726099200  The latest and strongest model family from Ope...          128000               None                                 [seed, max_tokens]            text->text                        [text]                         [text]                    GPT                       None       0.000015            0.00006               0             0                  0                          0                     128000.0                             32768.0                       True                0.0000075                       NaN\n",
       "209                       openai/o1-preview-2024-09-12                    OpenAI: o1-preview (2024-09-12)  1726099200  The latest and strongest model family from Ope...          128000               None                                 [seed, max_tokens]            text->text                        [text]                         [text]                    GPT                       None       0.000015            0.00006               0             0                  0                          0                     128000.0                             32768.0                       True                0.0000075                       NaN\n",
       "210                                     openai/o1-mini                                    OpenAI: o1-mini  1726099200  The latest and strongest model family from Ope...          128000               None                                 [seed, max_tokens]            text->text                        [text]                         [text]                    GPT                       None      0.0000011          0.0000044               0             0                  0                          0                     128000.0                             65536.0                       True               0.00000055                       NaN\n",
       "211                          openai/o1-mini-2024-09-12                       OpenAI: o1-mini (2024-09-12)  1726099200  The latest and strongest model family from Ope...          128000               None                                 [seed, max_tokens]            text->text                        [text]                         [text]                    GPT                       None      0.0000011          0.0000044               0             0                  0                          0                     128000.0                             65536.0                       True               0.00000055                       NaN\n",
       "212                              mistralai/pixtral-12b                               Mistral: Pixtral 12B  1725926400  The first multi-modal, text+image-to-text mode...           32768               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                Mistral                       None      0.0000001          0.0000001               0     0.0001445                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "213                      cohere/command-r-plus-08-2024                       Cohere: Command R+ (08-2024)  1724976000  command-r-plus-08-2024 is an update of the [Co...          128000               None  [tools, max_tokens, temperature, top_p, stop, ...            text->text                        [text]                         [text]                 Cohere                       None      0.0000025            0.00001               0             0                  0                          0                     128000.0                              4000.0                      False                      NaN                       NaN\n",
       "214                           cohere/command-r-08-2024                        Cohere: Command R (08-2024)  1724976000  command-r-08-2024 is an update of the [Command...          128000               None  [tools, max_tokens, temperature, top_p, stop, ...            text->text                        [text]                         [text]                 Cohere                       None     0.00000015          0.0000006               0             0                  0                          0                     128000.0                              4000.0                      False                      NaN                       NaN\n",
       "215                  qwen/qwen-2.5-vl-7b-instruct:free                Qwen: Qwen2.5-VL 7B Instruct (free)  1724803200  Qwen2.5 VL 7B is a multimodal LLM from the Qwe...           64000               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                   Qwen                       None              0                  0               0             0                  0                          0                      64000.0                             64000.0                      False                      NaN                       NaN\n",
       "216                       qwen/qwen-2.5-vl-7b-instruct                       Qwen: Qwen2.5-VL 7B Instruct  1724803200  Qwen2.5 VL 7B is a multimodal LLM from the Qwe...           32768               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                   Qwen                       None      0.0000002          0.0000002               0     0.0001445                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "217                            sao10k/l3.1-euryale-70b                 Sao10K: Llama 3.1 Euryale 70B v2.2  1724803200  Euryale L3.1 70B v2.2 is a model focused on cr...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3      0.0000007          0.0000008               0             0                  0                          0                     131072.0                             16384.0                      False                      NaN                       NaN\n",
       "218                     google/gemini-flash-1.5-8b-exp           Google: Gemini 1.5 Flash 8B Experimental  1724803200  Gemini Flash 1.5 8B Experimental is an experim...         1000000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Gemini                       None              0                  0               0             0                  0                          0                    1000000.0                              8192.0                      False                      NaN                       NaN\n",
       "219               microsoft/phi-3.5-mini-128k-instruct              Microsoft: Phi-3.5 Mini 128K Instruct  1724198400  Phi-3.5 models are lightweight, state-of-the-a...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                  Other                       phi3     0.00000003         0.00000009               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "220                nousresearch/hermes-3-llama-3.1-70b                        Nous: Hermes 3 70B Instruct  1723939200  Hermes 3 is a generalist language model with m...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     chatml     0.00000012          0.0000003               0             0                  0                          0                     131072.0                            131072.0                      False                      NaN                       NaN\n",
       "221               nousresearch/hermes-3-llama-3.1-405b                       Nous: Hermes 3 405B Instruct  1723766400  Hermes 3 is a generalist language model with m...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     chatml      0.0000008          0.0000008               0             0                  0                          0                     131072.0                            131072.0                      False                      NaN                       NaN\n",
       "222                           openai/chatgpt-4o-latest                                 OpenAI: ChatGPT-4o  1723593600  OpenAI ChatGPT 4o is continually updated by Op...          128000               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                    GPT                       None       0.000005           0.000015               0      0.007225                  0                          0                     128000.0                             16384.0                       True                      NaN                       NaN\n",
       "223                               sao10k/l3-lunaris-8b                         Sao10K: Llama 3 8B Lunaris  1723507200  Lunaris 8B is a versatile generalist and rolep...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3     0.00000002         0.00000005               0             0                  0                          0                       8192.0                                 NaN                      False                      NaN                       NaN\n",
       "224                      aetherwiing/mn-starcannon-12b                        Aetherwiing: Starcannon 12B  1723507200  Starcannon 12B v2 is a creative roleplay and s...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                     chatml      0.0000008          0.0000012               0             0                  0                          0                      16384.0                              4096.0                      False                      NaN                       NaN\n",
       "225                           openai/gpt-4o-2024-08-06                        OpenAI: GPT-4o (2024-08-06)  1722902400  The 2024-08-06 version of GPT-4o offers improv...          128000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text           [text, image, file]                         [text]                    GPT                       None      0.0000025            0.00001               0      0.003613                  0                          0                     128000.0                             16384.0                       True               0.00000125                       NaN\n",
       "226                     meta-llama/llama-3.1-405b:free                 Meta: Llama 3.1 405B (base) (free)  1722556800  Meta's latest class of model (Llama 3.1) launc...           64000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                       none              0                  0               0             0                  0                          0                      64000.0                                 NaN                      False                      NaN                       NaN\n",
       "227                          meta-llama/llama-3.1-405b                        Meta: Llama 3.1 405B (base)  1722556800  Meta's latest class of model (Llama 3.1) launc...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                       none       0.000002           0.000002               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "228                      nothingiisreal/mn-celeste-12b                           Mistral Nemo 12B Celeste  1722556800  A specialized story writing and roleplaying mo...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                     chatml      0.0000008          0.0000012               0             0                  0                          0                      16384.0                              4096.0                      False                      NaN                       NaN\n",
       "229       perplexity/llama-3.1-sonar-small-128k-online              Perplexity: Llama 3.1 Sonar 8B Online  1722470400  Llama 3.1 Sonar is Perplexity's latest model f...          127072               None  [max_tokens, temperature, top_p, top_k, freque...            text->text                        [text]                         [text]                 Llama3                       None      0.0000002          0.0000002           0.005             0                  0                          0                     127072.0                                 NaN                      False                      NaN                       NaN\n",
       "230       perplexity/llama-3.1-sonar-large-128k-online             Perplexity: Llama 3.1 Sonar 70B Online  1722470400  Llama 3.1 Sonar is Perplexity's latest model f...          127072               None  [max_tokens, temperature, top_p, top_k, freque...            text->text                        [text]                         [text]                 Llama3                       None       0.000001           0.000001           0.005             0                  0                          0                     127072.0                                 NaN                      False                      NaN                       NaN\n",
       "231              meta-llama/llama-3.1-8b-instruct:free                 Meta: Llama 3.1 8B Instruct (free)  1721692800  Meta's latest class of model (Llama 3.1) launc...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3              0                  0               0             0                  0                          0                     131072.0                              4096.0                      False                      NaN                       NaN\n",
       "232                   meta-llama/llama-3.1-8b-instruct                        Meta: Llama 3.1 8B Instruct  1721692800  Meta's latest class of model (Llama 3.1) launc...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3     0.00000002         0.00000003               0             0                  0                          0                      16384.0                             16384.0                      False                      NaN                       NaN\n",
       "233                 meta-llama/llama-3.1-405b-instruct                      Meta: Llama 3.1 405B Instruct  1721692800  The highly anticipated 400B class of Llama3 is...           32768               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                 Llama3                     llama3      0.0000008          0.0000008               0             0                  0                          0                      32768.0                             16384.0                      False                      NaN                       NaN\n",
       "234                  meta-llama/llama-3.1-70b-instruct                       Meta: Llama 3.1 70B Instruct  1721692800  Meta's latest class of model (Llama 3.1) launc...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                 Llama3                     llama3      0.0000001         0.00000028               0             0                  0                          0                     131072.0                             16384.0                      False                      NaN                       NaN\n",
       "235                          mistralai/codestral-mamba                           Mistral: Codestral Mamba  1721347200  A 7.3B parameter Mamba-based model designed fo...          262144               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None     0.00000025         0.00000025               0             0                  0                          0                     262144.0                                 NaN                      False                      NaN                       NaN\n",
       "236                        mistralai/mistral-nemo:free                       Mistral: Mistral Nemo (free)  1721347200  A 12B parameter model with a 128k token contex...          128000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                    mistral              0                  0               0             0                  0                          0                     128000.0                            128000.0                      False                      NaN                       NaN\n",
       "237                             mistralai/mistral-nemo                              Mistral: Mistral Nemo  1721347200  A 12B parameter model with a 128k token contex...           98304               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                    mistral     0.00000003         0.00000007               0             0                  0                          0                      98304.0                             49152.0                      False                      NaN                       NaN\n",
       "238                                 openai/gpt-4o-mini                                OpenAI: GPT-4o-mini  1721260800  GPT-4o mini is OpenAI's newest model after [GP...          128000               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text           [text, image, file]                         [text]                    GPT                       None     0.00000015          0.0000006               0      0.000217                  0                          0                     128000.0                             16384.0                       True              0.000000075                       NaN\n",
       "239                      openai/gpt-4o-mini-2024-07-18                   OpenAI: GPT-4o-mini (2024-07-18)  1721260800  GPT-4o mini is OpenAI's newest model after [GP...          128000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text           [text, image, file]                         [text]                    GPT                       None     0.00000015          0.0000006               0      0.007225                  0                          0                     128000.0                             16384.0                       True              0.000000075                       NaN\n",
       "240                              google/gemma-2-27b-it                                Google: Gemma 2 27B  1720828800  Gemma 2 27B by Google is an open model built f...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Gemini                      gemma      0.0000001          0.0000003               0             0                  0                          0                       8192.0                                 NaN                      False                      NaN                       NaN\n",
       "241                               alpindale/magnum-72b                                         Magnum 72B  1720656000  From the maker of [Goliath](https://openrouter...           16384               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml       0.000004           0.000006               0             0                  0                          0                      16384.0                              4096.0                      False                      NaN                       NaN\n",
       "242                          google/gemma-2-9b-it:free                          Google: Gemma 2 9B (free)  1719532800  Gemma 2 9B by Google is an advanced, open-sour...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Gemini                      gemma              0                  0               0             0                  0                          0                       8192.0                              8192.0                      False                      NaN                       NaN\n",
       "243                               google/gemma-2-9b-it                                 Google: Gemma 2 9B  1719532800  Gemma 2 9B by Google is an advanced, open-sour...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Gemini                      gemma     0.00000002         0.00000006               0             0                  0                          0                       8192.0                                 NaN                      False                      NaN                       NaN\n",
       "244                                     01-ai/yi-large                                    01.AI: Yi Large  1719273600  The Yi Large model was designed by 01.AI with ...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                     Yi                       None       0.000003           0.000003               0             0                  0                          0                      32768.0                              4096.0                      False                      NaN                       NaN\n",
       "245                                ai21/jamba-instruct                               AI21: Jamba Instruct  1719273600  The Jamba-Instruct model, introduced by AI21 L...          256000               None             [max_tokens, temperature, top_p, stop]            text->text                        [text]                         [text]                  Other                       None      0.0000005          0.0000007               0             0                  0                          0                     256000.0                              4096.0                      False                      NaN                       NaN\n",
       "246          anthropic/claude-3.5-sonnet-20240620:beta  Anthropic: Claude 3.5 Sonnet (2024-06-20) (sel...  1718841600  Claude 3.5 Sonnet delivers better-than-Opus ca...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None       0.000003           0.000015               0        0.0048                  0                          0                     200000.0                              8192.0                      False                0.0000003                0.00000375\n",
       "247               anthropic/claude-3.5-sonnet-20240620          Anthropic: Claude 3.5 Sonnet (2024-06-20)  1718841600  Claude 3.5 Sonnet delivers better-than-Opus ca...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None       0.000003           0.000015               0        0.0048                  0                          0                     200000.0                              8192.0                       True                0.0000003                0.00000375\n",
       "248                              sao10k/l3-euryale-70b                   Sao10k: Llama 3 Euryale 70B v2.1  1718668800  Euryale 70B v2.1 is a model focused on creativ...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3     0.00000148         0.00000148               0             0                  0                          0                       8192.0                              8192.0                      False                      NaN                       NaN\n",
       "249        cognitivecomputations/dolphin-mixtral-8x22b                      Dolphin 2.9.2 Mixtral 8x22B 🐬  1717804800  Dolphin 2.9 is designed for instruction follow...           16000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                     chatml      0.0000009          0.0000009               0             0                  0                          0                      16000.0                                 NaN                      False                      NaN                       NaN\n",
       "250                           qwen/qwen-2-72b-instruct                                Qwen 2 72B Instruct  1717718400  Qwen2 72B is a transformer-based model that ex...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                   Qwen                     chatml      0.0000009          0.0000009               0             0                  0                          0                      32768.0                              4096.0                      False                      NaN                       NaN\n",
       "251                 mistralai/mistral-7b-instruct:free                Mistral: Mistral 7B Instruct (free)  1716768000  A high-performing, industry-standard 7.3B para...           32768               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                    mistral              0                  0               0             0                  0                          0                      32768.0                             16384.0                      False                      NaN                       NaN\n",
       "252                      mistralai/mistral-7b-instruct                       Mistral: Mistral 7B Instruct  1716768000  A high-performing, industry-standard 7.3B para...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                    mistral    0.000000028        0.000000054               0             0                  0                          0                      32768.0                             16384.0                      False                      NaN                       NaN\n",
       "253               nousresearch/hermes-2-pro-llama-3-8b            NousResearch: Hermes 2 Pro - Llama-3 8B  1716768000  Hermes 2 Pro is an upgraded, retrained version...          131072               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     chatml    0.000000025         0.00000004               0             0                  0                          0                     131072.0                            131072.0                      False                      NaN                       NaN\n",
       "254                 mistralai/mistral-7b-instruct-v0.3                  Mistral: Mistral 7B Instruct v0.3  1716768000  A high-performing, industry-standard 7.3B para...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                    mistral    0.000000028        0.000000054               0             0                  0                          0                      32768.0                             16384.0                      False                      NaN                       NaN\n",
       "255                 microsoft/phi-3-mini-128k-instruct                Microsoft: Phi-3 Mini 128K Instruct  1716681600  Phi-3 Mini is a powerful 3.8B parameter model ...          128000               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                  Other                       phi3      0.0000001          0.0000001               0             0                  0                          0                     128000.0                                 NaN                      False                      NaN                       NaN\n",
       "256               microsoft/phi-3-medium-128k-instruct              Microsoft: Phi-3 Medium 128K Instruct  1716508800  Phi-3 128K Medium is a powerful 14-billion par...          131072               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                  Other                       phi3      0.0000001          0.0000003               0             0                  0                          0                     131072.0                                 NaN                      False                      NaN                       NaN\n",
       "257                    neversleep/llama-3-lumimaid-70b                   NeverSleep: Llama 3 Lumimaid 70B  1715817600  The NeverSleep team is back, with a Llama 3 70...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3       0.000004           0.000006               0             0                  0                          0                       8192.0                              4096.0                      False                      NaN                       NaN\n",
       "258                            deepseek/deepseek-coder                                  DeepSeek-Coder-V2  1715644800  DeepSeek-Coder-V2, an open-source Mixture-of-E...          128000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                       None     0.00000004         0.00000012               0             0                  0                          0                     128000.0                                 NaN                      False                      NaN                       NaN\n",
       "259                            google/gemini-flash-1.5                          Google: Gemini 1.5 Flash   1715644800  Gemini 1.5 Flash is a foundation model that pe...         1000000               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Gemini                       None    0.000000075          0.0000003               0       0.00004                  0                          0                    1000000.0                              8192.0                      False            0.00000001875              0.0000001583\n",
       "260                                      openai/gpt-4o                                     OpenAI: GPT-4o  1715558400  GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI ...          128000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text           [text, image, file]                         [text]                    GPT                       None      0.0000025            0.00001               0      0.003613                  0                          0                     128000.0                             16384.0                       True               0.00000125                       NaN\n",
       "261                             openai/gpt-4o:extended                          OpenAI: GPT-4o (extended)  1715558400  GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI ...          128000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text           [text, image, file]                         [text]                    GPT                       None       0.000006           0.000018               0      0.007225                  0                          0                     128000.0                             64000.0                       True                      NaN                       NaN\n",
       "262                        meta-llama/llama-guard-2-8b                              Meta: LlamaGuard 2 8B  1715558400  This safeguard model has 8B parameters and is ...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                       none      0.0000002          0.0000002               0             0                  0                          0                       8192.0                                 NaN                      False                      NaN                       NaN\n",
       "263                           openai/gpt-4o-2024-05-13                        OpenAI: GPT-4o (2024-05-13)  1715558400  GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI ...          128000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text           [text, image, file]                         [text]                    GPT                       None       0.000005           0.000015               0      0.007225                  0                          0                     128000.0                              4096.0                       True                      NaN                       NaN\n",
       "264                           allenai/olmo-7b-instruct                                   OLMo 7B Instruct  1715299200  OLMo 7B Instruct by the Allen Institute for AI...            2048               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                  Other                     zephyr     0.00000008         0.00000024               0             0                  0                          0                       2048.0                                 NaN                      False                      NaN                       NaN\n",
       "265            neversleep/llama-3-lumimaid-8b:extended         NeverSleep: Llama 3 Lumimaid 8B (extended)  1714780800  The NeverSleep team is back, with a Llama 3 8B...           24576               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3  0.00000009375         0.00000075               0             0                  0                          0                      24576.0                              2048.0                      False                      NaN                       NaN\n",
       "266                     neversleep/llama-3-lumimaid-8b                    NeverSleep: Llama 3 Lumimaid 8B  1714780800  The NeverSleep team is back, with a Llama 3 8B...           24576               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3  0.00000009375         0.00000075               0             0                  0                          0                      24576.0                              2048.0                      False                      NaN                       NaN\n",
       "267                           sao10k/fimbulvetr-11b-v2                                  Fimbulvetr 11B v2  1713657600  Creative writing model, routed with permission...            4096               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama2                     alpaca      0.0000008          0.0000012               0             0                  0                          0                       4096.0                              4096.0                      False                      NaN                       NaN\n",
       "268                     meta-llama/llama-3-8b-instruct                          Meta: Llama 3 8B Instruct  1713398400  Meta's latest class of model (Llama 3) launche...            8192               None  [max_tokens, temperature, top_p, top_k, seed, ...            text->text                        [text]                         [text]                 Llama3                     llama3     0.00000003         0.00000006               0             0                  0                          0                       8192.0                             16384.0                      False                      NaN                       NaN\n",
       "269                    meta-llama/llama-3-70b-instruct                         Meta: Llama 3 70B Instruct  1713398400  Meta's latest class of model (Llama 3) launche...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama3                     llama3      0.0000003          0.0000004               0             0                  0                          0                       8192.0                             16384.0                      False                      NaN                       NaN\n",
       "270                   mistralai/mixtral-8x22b-instruct                    Mistral: Mixtral 8x22B Instruct  1713312000  Mistral's official instruct fine-tuned version...           65536               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                    mistral      0.0000004          0.0000012               0             0                  0                          0                      65536.0                                 NaN                      False                      NaN                       NaN\n",
       "271                         microsoft/wizardlm-2-8x22b                                   WizardLM-2 8x22B  1713225600  WizardLM-2 8x22B is Microsoft AI's most advanc...           65536               None  [max_tokens, temperature, top_p, presence_pena...            text->text                        [text]                         [text]                Mistral                     vicuna      0.0000005          0.0000005               0             0                  0                          0                      65536.0                             16384.0                      False                      NaN                       NaN\n",
       "272                              google/gemini-pro-1.5                             Google: Gemini 1.5 Pro  1712620800  Google's latest multimodal model, supports ima...         2000000               None  [max_tokens, temperature, top_p, stop, frequen...      text+image->text                 [text, image]                         [text]                 Gemini                       None     0.00000125           0.000005               0     0.0006575                  0                          0                    2000000.0                              8192.0                      False                      NaN                       NaN\n",
       "273                                 openai/gpt-4-turbo                                OpenAI: GPT-4 Turbo  1712620800  The latest GPT-4 Turbo model with vision capab...          128000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                    GPT                       None        0.00001            0.00003               0       0.01445                  0                          0                     128000.0                              4096.0                       True                      NaN                       NaN\n",
       "274                              cohere/command-r-plus                                 Cohere: Command R+  1712188800  Command R+ is a new, 104B-parameter LLM from C...          128000               None  [tools, max_tokens, temperature, top_p, stop, ...            text->text                        [text]                         [text]                 Cohere                       None       0.000003           0.000015               0             0                  0                          0                     128000.0                              4000.0                      False                      NaN                       NaN\n",
       "275                      cohere/command-r-plus-04-2024                       Cohere: Command R+ (04-2024)  1712016000  Command R+ is a new, 104B-parameter LLM from C...          128000               None  [tools, max_tokens, temperature, top_p, stop, ...            text->text                        [text]                         [text]                 Cohere                       None       0.000003           0.000015               0             0                  0                          0                     128000.0                              4000.0                      False                      NaN                       NaN\n",
       "276                  sophosympatheia/midnight-rose-70b                                  Midnight Rose 70B  1711065600  A merge with a complex family tree, this model...            4096               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama2                  airoboros      0.0000008          0.0000008               0             0                  0                          0                       4096.0                                 NaN                      False                      NaN                       NaN\n",
       "277                                     cohere/command                                    Cohere: Command  1710374400  Command is an instruction-following conversati...            4096               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Cohere                       None       0.000001           0.000002               0             0                  0                          0                       4096.0                              4000.0                      False                      NaN                       NaN\n",
       "278                                   cohere/command-r                                  Cohere: Command R  1710374400  Command-R is a 35B parameter model that perfor...          128000               None  [tools, max_tokens, temperature, top_p, stop, ...            text->text                        [text]                         [text]                 Cohere                       None      0.0000005          0.0000015               0             0                  0                          0                     128000.0                              4000.0                      False                      NaN                       NaN\n",
       "279                      anthropic/claude-3-haiku:beta         Anthropic: Claude 3 Haiku (self-moderated)  1710288000  Claude 3 Haiku is Anthropic's fastest and most...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None     0.00000025         0.00000125               0        0.0004                  0                          0                     200000.0                              4096.0                      False               0.00000003                 0.0000003\n",
       "280                           anthropic/claude-3-haiku                          Anthropic: Claude 3 Haiku  1710288000  Claude 3 Haiku is Anthropic's fastest and most...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None     0.00000025         0.00000125               0        0.0004                  0                          0                     200000.0                              4096.0                       True               0.00000003                 0.0000003\n",
       "281                       anthropic/claude-3-opus:beta          Anthropic: Claude 3 Opus (self-moderated)  1709596800  Claude 3 Opus is Anthropic's most powerful mod...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None       0.000015           0.000075               0         0.024                  0                          0                     200000.0                              4096.0                      False                0.0000015                0.00001875\n",
       "282                            anthropic/claude-3-opus                           Anthropic: Claude 3 Opus  1709596800  Claude 3 Opus is Anthropic's most powerful mod...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None       0.000015           0.000075               0         0.024                  0                          0                     200000.0                              4096.0                       True                0.0000015                0.00001875\n",
       "283                     anthropic/claude-3-sonnet:beta        Anthropic: Claude 3 Sonnet (self-moderated)  1709596800  Claude 3 Sonnet is an ideal balance of intelli...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None       0.000003           0.000015               0        0.0048                  0                          0                     200000.0                              4096.0                      False                0.0000003                0.00000375\n",
       "284                          anthropic/claude-3-sonnet                         Anthropic: Claude 3 Sonnet  1709596800  Claude 3 Sonnet is an ideal balance of intelli...          200000               None  [tools, tool_choice, max_tokens, temperature, ...      text+image->text                 [text, image]                         [text]                 Claude                       None       0.000003           0.000015               0        0.0048                  0                          0                     200000.0                              4096.0                       True                0.0000003                0.00000375\n",
       "285                           cohere/command-r-03-2024                        Cohere: Command R (03-2024)  1709341200  Command-R is a 35B parameter model that perfor...          128000               None  [tools, max_tokens, temperature, top_p, stop, ...            text->text                        [text]                         [text]                 Cohere                       None      0.0000005          0.0000015               0             0                  0                          0                     128000.0                              4000.0                      False                      NaN                       NaN\n",
       "286                            mistralai/mistral-large                                      Mistral Large  1708905600  This is Mistral AI's flagship model, Mistral L...          128000               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None       0.000002           0.000006               0             0                  0                          0                     128000.0                                 NaN                      False                      NaN                       NaN\n",
       "287                          openai/gpt-3.5-turbo-0613                OpenAI: GPT-3.5 Turbo (older v0613)  1706140800  GPT-3.5 Turbo is OpenAI's fastest model. It ca...            4095               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                    GPT                       None       0.000001           0.000002               0             0                  0                          0                       4095.0                              4096.0                      False                      NaN                       NaN\n",
       "288                         openai/gpt-4-turbo-preview                        OpenAI: GPT-4 Turbo Preview  1706140800  The preview GPT-4 model with improved instruct...          128000               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                    GPT                       None        0.00001            0.00003               0             0                  0                          0                     128000.0                              4096.0                       True                      NaN                       NaN\n",
       "289        nousresearch/nous-hermes-2-mixtral-8x7b-dpo                    Nous: Hermes 2 Mixtral 8x7B DPO  1705363200  Nous Hermes 2 Mixtral 8x7B DPO is the new flag...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                     chatml      0.0000006          0.0000006               0             0                  0                          0                      32768.0                              2048.0                      False                      NaN                       NaN\n",
       "290                           mistralai/mistral-medium                                     Mistral Medium  1704844800  This is Mistral AI's closed-source, medium-sid...           32768               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None     0.00000275          0.0000081               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "291                            mistralai/mistral-small                                      Mistral Small  1704844800  With 22 billion parameters, Mistral Small v24....           32768               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None      0.0000002          0.0000006               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "292                             mistralai/mistral-tiny                                       Mistral Tiny  1704844800  Note: This model is being deprecated. Recommen...           32768               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                       None     0.00000025         0.00000025               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "293                 mistralai/mistral-7b-instruct-v0.2                  Mistral: Mistral 7B Instruct v0.2  1703721600  A high-performing, industry-standard 7.3B para...           32768               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                    mistral      0.0000002          0.0000002               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "294                    mistralai/mixtral-8x7b-instruct                     Mistral: Mixtral 8x7B Instruct  1702166400  Mixtral 8x7B Instruct is a pretrained generati...           32768               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                    mistral     0.00000008         0.00000024               0             0                  0                          0                      32768.0                                 NaN                      False                      NaN                       NaN\n",
       "295                            neversleep/noromaid-20b                                       Noromaid 20B  1700956800  A collab between IkariDev and Undi. This merge...            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama2                     alpaca     0.00000075          0.0000015               0             0                  0                          0                       8192.0                              2048.0                      False                      NaN                       NaN\n",
       "296                          anthropic/claude-2.1:beta            Anthropic: Claude v2.1 (self-moderated)  1700611200  Claude 2 delivers advancements in key capabili...          200000               None      [max_tokens, temperature, top_p, top_k, stop]            text->text                        [text]                         [text]                 Claude                       None       0.000008           0.000024               0             0                  0                          0                     200000.0                              4096.0                      False                      NaN                       NaN\n",
       "297                               anthropic/claude-2.1                             Anthropic: Claude v2.1  1700611200  Claude 2 delivers advancements in key capabili...          200000               None      [max_tokens, temperature, top_p, top_k, stop]            text->text                        [text]                         [text]                 Claude                       None       0.000008           0.000024               0             0                  0                          0                     200000.0                              4096.0                       True                      NaN                       NaN\n",
       "298                            anthropic/claude-2:beta              Anthropic: Claude v2 (self-moderated)  1700611200  Claude 2 delivers advancements in key capabili...          200000               None      [max_tokens, temperature, top_p, top_k, stop]            text->text                        [text]                         [text]                 Claude                       None       0.000008           0.000024               0             0                  0                          0                     200000.0                              4096.0                      False                      NaN                       NaN\n",
       "299                                 anthropic/claude-2                               Anthropic: Claude v2  1700611200  Claude 2 delivers advancements in key capabili...          200000               None      [max_tokens, temperature, top_p, top_k, stop]            text->text                        [text]                         [text]                 Claude                       None       0.000008           0.000024               0             0                  0                          0                     200000.0                              4096.0                       True                      NaN                       NaN\n",
       "300                                  undi95/toppy-m-7b                                         Toppy M 7B  1699574400  A wild 7B parameter model that merges several ...            4096               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                Mistral                     alpaca      0.0000008          0.0000012               0             0                  0                          0                       4096.0                              4096.0                      False                      NaN                       NaN\n",
       "301                             alpindale/goliath-120b                                       Goliath 120B  1699574400  A large LLM created by combining two fine-tune...            6144               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama2                  airoboros   0.0000065625        0.000009375               0             0                  0                          0                       6144.0                               512.0                      False                      NaN                       NaN\n",
       "302                                    openrouter/auto                                        Auto Router  1699401600  Your prompt will be processed by a meta-model ...         2000000               None                                                 []            text->text                        [text]                         [text]                 Router                       None             -1                 -1             NaN           NaN                NaN                        NaN                          NaN                                 NaN                      False                      NaN                       NaN\n",
       "303                          openai/gpt-3.5-turbo-1106            OpenAI: GPT-3.5 Turbo 16k (older v1106)  1699228800  An older GPT-3.5 Turbo model with improved ins...           16385               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                    GPT                       None       0.000001           0.000002               0             0                  0                          0                      16385.0                              4096.0                       True                      NaN                       NaN\n",
       "304                          openai/gpt-4-1106-preview                  OpenAI: GPT-4 Turbo (older v1106)  1699228800  The latest GPT-4 Turbo model with vision capab...          128000               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                    GPT                       None        0.00001            0.00003               0             0                  0                          0                     128000.0                              4096.0                       True                      NaN                       NaN\n",
       "305                         jondurbin/airoboros-l2-70b                                      Airoboros 70B  1698537600  A Llama 2 70B fine-tune using synthetic data (...            4096               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama2                  airoboros      0.0000005          0.0000005               0             0                  0                          0                       4096.0                                 NaN                      False                      NaN                       NaN\n",
       "306                      openai/gpt-3.5-turbo-instruct                     OpenAI: GPT-3.5 Turbo Instruct  1695859200  This model is a variant of GPT-3.5 Turbo tuned...            4095               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                    GPT                     chatml      0.0000015           0.000002               0             0                  0                          0                       4095.0                              4096.0                       True                      NaN                       NaN\n",
       "307                 mistralai/mistral-7b-instruct-v0.1                  Mistral: Mistral 7B Instruct v0.1  1695859200  A 7.3B parameter model that outperforms Llama ...            2824               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                Mistral                    mistral     0.00000011         0.00000019               0             0                  0                          0                       2824.0                                 NaN                      False                      NaN                       NaN\n",
       "308                          pygmalionai/mythalion-13b                           Pygmalion: Mythalion 13B  1693612800  A blend of the new Pygmalion-13b and MythoMax....            8192               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama2                     alpaca   0.0000005625        0.000001125               0             0                  0                          0                       8192.0                              1024.0                      False                      NaN                       NaN\n",
       "309                           openai/gpt-3.5-turbo-16k                          OpenAI: GPT-3.5 Turbo 16k  1693180800  This model offers four times the context lengt...           16385               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                    GPT                       None       0.000003           0.000004               0             0                  0                          0                      16385.0                              4096.0                       True                      NaN                       NaN\n",
       "310                                   openai/gpt-4-32k                                  OpenAI: GPT-4 32k  1693180800  GPT-4-32k is an extended version of GPT-4, wit...           32767               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                    GPT                       None        0.00006            0.00012               0             0                  0                          0                      32767.0                              4096.0                       True                      NaN                       NaN\n",
       "311                              openai/gpt-4-32k-0314                    OpenAI: GPT-4 32k (older v0314)  1693180800  GPT-4-32k is an extended version of GPT-4, wit...           32767               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                    GPT                       None        0.00006            0.00012               0             0                  0                          0                      32767.0                              4096.0                       True                      NaN                       NaN\n",
       "312                                      mancer/weaver                             Mancer: Weaver (alpha)  1690934400  An attempt to recreate Claude-style verbosity,...            8000               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama2                     alpaca    0.000001125        0.000001125               0             0                  0                          0                       8000.0                              1000.0                      False                      NaN                       NaN\n",
       "313                          anthropic/claude-2.0:beta            Anthropic: Claude v2.0 (self-moderated)  1690502400  Anthropic's flagship model. Superior performan...          100000               None      [max_tokens, temperature, top_p, top_k, stop]            text->text                        [text]                         [text]                 Claude                       None       0.000008           0.000024               0             0                  0                          0                     100000.0                              4096.0                      False                      NaN                       NaN\n",
       "314                               anthropic/claude-2.0                             Anthropic: Claude v2.0  1690502400  Anthropic's flagship model. Superior performan...          100000               None      [max_tokens, temperature, top_p, top_k, stop]            text->text                        [text]                         [text]                 Claude                       None       0.000008           0.000024               0             0                  0                          0                     100000.0                              4096.0                       True                      NaN                       NaN\n",
       "315                           undi95/remm-slerp-l2-13b                                     ReMM SLERP 13B  1689984000  A recreation trial of the original MythoMax-L2...            6144               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama2                     alpaca   0.0000005625        0.000001125               0             0                  0                          0                       6144.0                              1024.0                      False                      NaN                       NaN\n",
       "316                             gryphe/mythomax-l2-13b                                       MythoMax 13B  1688256000  One of the highest performing and most popular...            4096               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama2                     alpaca    0.000000065        0.000000065               0             0                  0                          0                       4096.0                              4096.0                      False                      NaN                       NaN\n",
       "317                        meta-llama/llama-2-70b-chat                             Meta: Llama 2 70B Chat  1687219200  The flagship, 70 billion parameter language mo...            4096               None  [max_tokens, temperature, top_p, stop, frequen...            text->text                        [text]                         [text]                 Llama2                     llama2      0.0000009          0.0000009               0             0                  0                          0                       4096.0                                 NaN                      False                      NaN                       NaN\n",
       "318                               openai/gpt-3.5-turbo                              OpenAI: GPT-3.5 Turbo  1685232000  GPT-3.5 Turbo is OpenAI's fastest model. It ca...           16385               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                    GPT                       None      0.0000005          0.0000015               0             0                  0                          0                      16385.0                              4096.0                       True                      NaN                       NaN\n",
       "319                          openai/gpt-3.5-turbo-0125                          OpenAI: GPT-3.5 Turbo 16k  1685232000  The latest GPT-3.5 Turbo model with improved i...           16385               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                    GPT                       None      0.0000005          0.0000015               0             0                  0                          0                      16385.0                              4096.0                       True                      NaN                       NaN\n",
       "320                                       openai/gpt-4                                      OpenAI: GPT-4  1685232000  OpenAI's flagship model, GPT-4 is a large-scal...            8191               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                    GPT                       None        0.00003            0.00006               0             0                  0                          0                       8191.0                              4096.0                       True                      NaN                       NaN\n",
       "321                                  openai/gpt-4-0314                        OpenAI: GPT-4 (older v0314)  1685232000  GPT-4-0314 is the first version of GPT-4 relea...            8191               None  [tools, tool_choice, max_tokens, temperature, ...            text->text                        [text]                         [text]                    GPT                       None        0.00003            0.00006               0             0                  0                          0                       8191.0                              4096.0                       True                      NaN                       NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the nested JSON\n",
    "df = pd.json_normalize(val, sep=\"_\")\n",
    "df\n",
    "# View the resulting DataFrame\n",
    "# print(df.T)  # Transpose just for readable vertical inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                           mistralai/mistral-medium-3\n",
       "name                                                          Mistral: Mistral Medium 3\n",
       "created                                                                      1746627341\n",
       "description                           Mistral Medium 3 is a high-performance enterpr...\n",
       "context_length                                                                   131072\n",
       "per_request_limits                                                                 None\n",
       "supported_parameters                  [tools, tool_choice, max_tokens, temperature, ...\n",
       "architecture_modality                                                  text+image->text\n",
       "architecture_input_modalities                                             [text, image]\n",
       "architecture_output_modalities                                                   [text]\n",
       "architecture_tokenizer                                                          Mistral\n",
       "architecture_instruct_type                                                         None\n",
       "pricing_prompt                                                                0.0000004\n",
       "pricing_completion                                                             0.000002\n",
       "pricing_request                                                                       0\n",
       "pricing_image                                                                         0\n",
       "pricing_web_search                                                                    0\n",
       "pricing_internal_reasoning                                                            0\n",
       "top_provider_context_length                                                    131072.0\n",
       "top_provider_max_completion_tokens                                                  NaN\n",
       "top_provider_is_moderated                                                         False\n",
       "pricing_input_cache_read                                                            NaN\n",
       "pricing_input_cache_write                                                           NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"id\", \"context_length\", \"pricing_prompt\", \"pricing_completion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                     object\n",
       "name                                   object\n",
       "created                                 int64\n",
       "description                            object\n",
       "context_length                          int64\n",
       "per_request_limits                     object\n",
       "supported_parameters                   object\n",
       "architecture_modality                  object\n",
       "architecture_input_modalities          object\n",
       "architecture_output_modalities         object\n",
       "architecture_tokenizer                 object\n",
       "architecture_instruct_type             object\n",
       "pricing_prompt                         object\n",
       "pricing_completion                     object\n",
       "pricing_request                        object\n",
       "pricing_image                          object\n",
       "pricing_web_search                     object\n",
       "pricing_internal_reasoning             object\n",
       "top_provider_context_length           float64\n",
       "top_provider_max_completion_tokens    float64\n",
       "top_provider_is_moderated                bool\n",
       "pricing_input_cache_read               object\n",
       "pricing_input_cache_write              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_numeric': 0.0, 'is_bool': 0.0, 'is_string': 1.0, 'type': 'is_bool'}\n",
      "{'is_numeric': 0.0, 'is_bool': 0.0, 'is_string': 1.0, 'type': 'is_bool'}\n",
      "{'is_numeric': 1.0, 'is_bool': 0.0, 'is_string': 0.0, 'type': 'is_numeric'}\n",
      "{'is_numeric': 0.0, 'is_bool': 0.0, 'is_string': 1.0, 'type': 'is_bool'}\n",
      "{'is_numeric': 1.0, 'is_bool': 0.0, 'is_string': 0.0, 'type': 'is_numeric'}\n",
      "{'is_numeric': 0.0, 'is_bool': 0.0, 'is_string': 0.0, 'type': 'is_bool'}\n",
      "{'is_numeric': 0.0, 'is_bool': 0.0, 'is_string': 0.0, 'type': 'is_bool'}\n",
      "{'is_numeric': 0.0, 'is_bool': 0.0, 'is_string': 1.0, 'type': 'is_bool'}\n",
      "{'is_numeric': 0.0, 'is_bool': 0.0, 'is_string': 0.0, 'type': 'is_bool'}\n",
      "{'is_numeric': 0.0, 'is_bool': 0.0, 'is_string': 0.0, 'type': 'is_bool'}\n",
      "{'is_numeric': 0.0, 'is_bool': 0.0, 'is_string': 1.0, 'type': 'is_bool'}\n",
      "{'is_numeric': 0.0, 'is_bool': 0.0, 'is_string': 0.38819875776397517, 'type': 'is_bool'}\n",
      "{'is_numeric': 1.0, 'is_bool': 0.0, 'is_string': 1.0, 'type': 'is_numeric'}\n",
      "{'is_numeric': 1.0, 'is_bool': 0.0, 'is_string': 1.0, 'type': 'is_numeric'}\n",
      "{'is_numeric': 0.9968944099378882, 'is_bool': 0.0, 'is_string': 0.9968944099378882, 'type': 'is_numeric'}\n",
      "{'is_numeric': 0.9968944099378882, 'is_bool': 0.0, 'is_string': 0.9968944099378882, 'type': 'is_numeric'}\n",
      "{'is_numeric': 0.9968944099378882, 'is_bool': 0.0, 'is_string': 0.9968944099378882, 'type': 'is_numeric'}\n",
      "{'is_numeric': 0.9968944099378882, 'is_bool': 0.0, 'is_string': 0.9968944099378882, 'type': 'is_numeric'}\n",
      "{'is_numeric': 0.9968944099378882, 'is_bool': 0.0, 'is_string': 0.0, 'type': 'is_numeric'}\n",
      "{'is_numeric': 0.5962732919254659, 'is_bool': 0.0, 'is_string': 0.0, 'type': 'is_numeric'}\n",
      "{'is_numeric': 1.0, 'is_bool': 1.0, 'is_string': 0.0, 'type': 'is_bool'}\n",
      "{'is_numeric': 0.13043478260869565, 'is_bool': 0.0, 'is_string': 0.13043478260869565, 'type': 'is_numeric'}\n",
      "{'is_numeric': 0.07142857142857142, 'is_bool': 0.0, 'is_string': 0.07142857142857142, 'type': 'is_numeric'}\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(hpandas.infer_column_types(df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_numeric</th>\n",
       "      <th>is_bool</th>\n",
       "      <th>is_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_request_limits</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supported_parameters</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture_modality</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture_input_modalities</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture_output_modalities</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture_tokenizer</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture_instruct_type</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_prompt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_completion</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_request</th>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_image</th>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_web_search</th>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_internal_reasoning</th>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_provider_context_length</th>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_provider_max_completion_tokens</th>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_provider_is_moderated</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_input_cache_read</th>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_input_cache_write</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    is_numeric  is_bool  is_string\n",
       "id                                    0.000000      0.0   1.000000\n",
       "name                                  0.000000      0.0   1.000000\n",
       "created                               1.000000      0.0   0.000000\n",
       "description                           0.000000      0.0   1.000000\n",
       "context_length                        1.000000      0.0   0.000000\n",
       "per_request_limits                    0.000000      0.0   0.000000\n",
       "supported_parameters                  0.000000      0.0   0.000000\n",
       "architecture_modality                 0.000000      0.0   1.000000\n",
       "architecture_input_modalities         0.000000      0.0   0.000000\n",
       "architecture_output_modalities        0.000000      0.0   0.000000\n",
       "architecture_tokenizer                0.000000      0.0   1.000000\n",
       "architecture_instruct_type            0.000000      0.0   0.388199\n",
       "pricing_prompt                        1.000000      0.0   1.000000\n",
       "pricing_completion                    1.000000      0.0   1.000000\n",
       "pricing_request                       0.996894      0.0   0.996894\n",
       "pricing_image                         0.996894      0.0   0.996894\n",
       "pricing_web_search                    0.996894      0.0   0.996894\n",
       "pricing_internal_reasoning            0.996894      0.0   0.996894\n",
       "top_provider_context_length           0.996894      0.0   0.000000\n",
       "top_provider_max_completion_tokens    0.596273      0.0   0.000000\n",
       "top_provider_is_moderated             1.000000      1.0   0.000000\n",
       "pricing_input_cache_read              0.130435      0.0   0.130435\n",
       "pricing_input_cache_write             0.071429      0.0   0.071429"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda x: pd.Series(hpandas.infer_column_types(x))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_numeric</th>\n",
       "      <th>is_bool</th>\n",
       "      <th>is_string</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>is_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>is_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>is_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context_length</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_request_limits</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>is_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supported_parameters</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>is_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture_modality</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>is_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture_input_modalities</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>is_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture_output_modalities</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>is_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture_tokenizer</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>is_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture_instruct_type</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388199</td>\n",
       "      <td>is_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_prompt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_completion</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_request</th>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_image</th>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_web_search</th>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_internal_reasoning</th>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_provider_context_length</th>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_provider_max_completion_tokens</th>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_provider_is_moderated</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>is_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_input_cache_read</th>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_input_cache_write</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>is_numeric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   is_numeric is_bool is_string        type\n",
       "id                                        0.0     0.0       1.0     is_bool\n",
       "name                                      0.0     0.0       1.0     is_bool\n",
       "created                                   1.0     0.0       0.0  is_numeric\n",
       "description                               0.0     0.0       1.0     is_bool\n",
       "context_length                            1.0     0.0       0.0  is_numeric\n",
       "per_request_limits                        0.0     0.0       0.0     is_bool\n",
       "supported_parameters                      0.0     0.0       0.0     is_bool\n",
       "architecture_modality                     0.0     0.0       1.0     is_bool\n",
       "architecture_input_modalities             0.0     0.0       0.0     is_bool\n",
       "architecture_output_modalities            0.0     0.0       0.0     is_bool\n",
       "architecture_tokenizer                    0.0     0.0       1.0     is_bool\n",
       "architecture_instruct_type                0.0     0.0  0.388199     is_bool\n",
       "pricing_prompt                            1.0     0.0       1.0  is_numeric\n",
       "pricing_completion                        1.0     0.0       1.0  is_numeric\n",
       "pricing_request                      0.996894     0.0  0.996894  is_numeric\n",
       "pricing_image                        0.996894     0.0  0.996894  is_numeric\n",
       "pricing_web_search                   0.996894     0.0  0.996894  is_numeric\n",
       "pricing_internal_reasoning           0.996894     0.0  0.996894  is_numeric\n",
       "top_provider_context_length          0.996894     0.0       0.0  is_numeric\n",
       "top_provider_max_completion_tokens   0.596273     0.0       0.0  is_numeric\n",
       "top_provider_is_moderated                 1.0     1.0       0.0     is_bool\n",
       "pricing_input_cache_read             0.130435     0.0  0.130435  is_numeric\n",
       "pricing_input_cache_write            0.071429     0.0  0.071429  is_numeric"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpandas.infer_column_types_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "5       True\n",
       "6       True\n",
       "7       True\n",
       "8       True\n",
       "9       True\n",
       "10      True\n",
       "11      True\n",
       "12      True\n",
       "13      True\n",
       "14      True\n",
       "15      True\n",
       "16      True\n",
       "17      True\n",
       "18      True\n",
       "19      True\n",
       "20      True\n",
       "21      True\n",
       "22      True\n",
       "23      True\n",
       "24      True\n",
       "25      True\n",
       "26      True\n",
       "27      True\n",
       "28      True\n",
       "29      True\n",
       "30      True\n",
       "31      True\n",
       "32      True\n",
       "33      True\n",
       "34      True\n",
       "35      True\n",
       "36      True\n",
       "37      True\n",
       "38      True\n",
       "39      True\n",
       "40      True\n",
       "41      True\n",
       "42      True\n",
       "43      True\n",
       "44      True\n",
       "45      True\n",
       "46      True\n",
       "47      True\n",
       "48      True\n",
       "49      True\n",
       "50      True\n",
       "51      True\n",
       "52      True\n",
       "53      True\n",
       "54      True\n",
       "55      True\n",
       "56      True\n",
       "57      True\n",
       "58      True\n",
       "59      True\n",
       "60      True\n",
       "61      True\n",
       "62      True\n",
       "63      True\n",
       "64      True\n",
       "65      True\n",
       "66      True\n",
       "67      True\n",
       "68      True\n",
       "69      True\n",
       "70      True\n",
       "71      True\n",
       "72      True\n",
       "73      True\n",
       "74      True\n",
       "75      True\n",
       "76      True\n",
       "77      True\n",
       "78      True\n",
       "79      True\n",
       "80      True\n",
       "81      True\n",
       "82      True\n",
       "83      True\n",
       "84      True\n",
       "85      True\n",
       "86      True\n",
       "87      True\n",
       "88      True\n",
       "89      True\n",
       "90      True\n",
       "91      True\n",
       "92      True\n",
       "93      True\n",
       "94      True\n",
       "95      True\n",
       "96      True\n",
       "97      True\n",
       "98      True\n",
       "99      True\n",
       "100     True\n",
       "101     True\n",
       "102     True\n",
       "103     True\n",
       "104     True\n",
       "105     True\n",
       "106     True\n",
       "107     True\n",
       "108     True\n",
       "109     True\n",
       "110     True\n",
       "111     True\n",
       "112     True\n",
       "113     True\n",
       "114     True\n",
       "115     True\n",
       "116     True\n",
       "117     True\n",
       "118     True\n",
       "119     True\n",
       "120     True\n",
       "121     True\n",
       "122     True\n",
       "123     True\n",
       "124     True\n",
       "125     True\n",
       "126     True\n",
       "127     True\n",
       "128     True\n",
       "129     True\n",
       "130     True\n",
       "131     True\n",
       "132     True\n",
       "133     True\n",
       "134     True\n",
       "135     True\n",
       "136     True\n",
       "137     True\n",
       "138     True\n",
       "139     True\n",
       "140     True\n",
       "141     True\n",
       "142     True\n",
       "143     True\n",
       "144     True\n",
       "145     True\n",
       "146     True\n",
       "147     True\n",
       "148     True\n",
       "149     True\n",
       "150     True\n",
       "151     True\n",
       "152     True\n",
       "153     True\n",
       "154     True\n",
       "155     True\n",
       "156     True\n",
       "157     True\n",
       "158     True\n",
       "159     True\n",
       "160     True\n",
       "161     True\n",
       "162     True\n",
       "163     True\n",
       "164     True\n",
       "165     True\n",
       "166     True\n",
       "167     True\n",
       "168     True\n",
       "169     True\n",
       "170     True\n",
       "171     True\n",
       "172     True\n",
       "173     True\n",
       "174     True\n",
       "175     True\n",
       "176     True\n",
       "177     True\n",
       "178     True\n",
       "179     True\n",
       "180     True\n",
       "181     True\n",
       "182     True\n",
       "183     True\n",
       "184     True\n",
       "185     True\n",
       "186     True\n",
       "187     True\n",
       "188     True\n",
       "189     True\n",
       "190     True\n",
       "191     True\n",
       "192     True\n",
       "193     True\n",
       "194     True\n",
       "195     True\n",
       "196     True\n",
       "197     True\n",
       "198     True\n",
       "199     True\n",
       "200     True\n",
       "201     True\n",
       "202     True\n",
       "203     True\n",
       "204     True\n",
       "205     True\n",
       "206     True\n",
       "207     True\n",
       "208     True\n",
       "209     True\n",
       "210     True\n",
       "211     True\n",
       "212     True\n",
       "213     True\n",
       "214     True\n",
       "215     True\n",
       "216     True\n",
       "217     True\n",
       "218     True\n",
       "219     True\n",
       "220     True\n",
       "221     True\n",
       "222     True\n",
       "223     True\n",
       "224     True\n",
       "225     True\n",
       "226     True\n",
       "227     True\n",
       "228     True\n",
       "229     True\n",
       "230     True\n",
       "231     True\n",
       "232     True\n",
       "233     True\n",
       "234     True\n",
       "235     True\n",
       "236     True\n",
       "237     True\n",
       "238     True\n",
       "239     True\n",
       "240     True\n",
       "241     True\n",
       "242     True\n",
       "243     True\n",
       "244     True\n",
       "245     True\n",
       "246     True\n",
       "247     True\n",
       "248     True\n",
       "249     True\n",
       "250     True\n",
       "251     True\n",
       "252     True\n",
       "253     True\n",
       "254     True\n",
       "255     True\n",
       "256     True\n",
       "257     True\n",
       "258     True\n",
       "259     True\n",
       "260     True\n",
       "261     True\n",
       "262     True\n",
       "263     True\n",
       "264     True\n",
       "265     True\n",
       "266     True\n",
       "267     True\n",
       "268     True\n",
       "269     True\n",
       "270     True\n",
       "271     True\n",
       "272     True\n",
       "273     True\n",
       "274     True\n",
       "275     True\n",
       "276     True\n",
       "277     True\n",
       "278     True\n",
       "279     True\n",
       "280     True\n",
       "281     True\n",
       "282     True\n",
       "283     True\n",
       "284     True\n",
       "285     True\n",
       "286     True\n",
       "287     True\n",
       "288     True\n",
       "289     True\n",
       "290     True\n",
       "291     True\n",
       "292     True\n",
       "293     True\n",
       "294     True\n",
       "295     True\n",
       "296     True\n",
       "297     True\n",
       "298     True\n",
       "299     True\n",
       "300     True\n",
       "301     True\n",
       "302    False\n",
       "303     True\n",
       "304     True\n",
       "305     True\n",
       "306     True\n",
       "307     True\n",
       "308     True\n",
       "309     True\n",
       "310     True\n",
       "311     True\n",
       "312     True\n",
       "313     True\n",
       "314     True\n",
       "315     True\n",
       "316     True\n",
       "317     True\n",
       "318     True\n",
       "319     True\n",
       "320     True\n",
       "321     True\n",
       "Name: pricing_request, dtype: bool"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(df[\"pricing_request\"], errors=\"coerce\").notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.000002\n",
       "1          0.00001\n",
       "2       0.00000085\n",
       "3       0.00000018\n",
       "4        0.0000033\n",
       "5        0.0000012\n",
       "6        0.0000008\n",
       "7        0.0000008\n",
       "8       0.00000075\n",
       "9                0\n",
       "10      0.00000035\n",
       "11               0\n",
       "12               0\n",
       "13        0.000001\n",
       "14               0\n",
       "15               0\n",
       "16               0\n",
       "17               0\n",
       "18               0\n",
       "19      0.00000218\n",
       "20      0.00000005\n",
       "21               0\n",
       "22       0.0000003\n",
       "23               0\n",
       "24     0.000000138\n",
       "25               0\n",
       "26      0.00000024\n",
       "27               0\n",
       "28       0.0000003\n",
       "29               0\n",
       "30        0.000002\n",
       "31               0\n",
       "32      0.00000024\n",
       "33               0\n",
       "34               0\n",
       "35               0\n",
       "36               0\n",
       "37      0.00000024\n",
       "38               0\n",
       "39      0.00000024\n",
       "40       0.0000006\n",
       "41       0.0000035\n",
       "42       0.0000044\n",
       "43         0.00004\n",
       "44       0.0000044\n",
       "45               0\n",
       "46      0.00000003\n",
       "47        0.000008\n",
       "48       0.0000016\n",
       "49       0.0000004\n",
       "50       0.0000012\n",
       "51       0.0000012\n",
       "52               0\n",
       "53               0\n",
       "54               0\n",
       "55       0.0000005\n",
       "56        0.000015\n",
       "57               0\n",
       "58       0.0000004\n",
       "59               0\n",
       "60               0\n",
       "61       0.0000006\n",
       "62               0\n",
       "63       0.0000003\n",
       "64       0.0000034\n",
       "65       0.0000001\n",
       "66               0\n",
       "67      0.00000018\n",
       "68      0.00000088\n",
       "69               0\n",
       "70               0\n",
       "71               0\n",
       "72               0\n",
       "73               0\n",
       "74       0.0000009\n",
       "75               0\n",
       "76      0.00000088\n",
       "77               0\n",
       "78          0.0006\n",
       "79               0\n",
       "80      0.00000015\n",
       "81               0\n",
       "82               0\n",
       "83               0\n",
       "84      0.00000004\n",
       "85        0.000008\n",
       "86       0.0000004\n",
       "87               0\n",
       "88       0.0000001\n",
       "89         0.00001\n",
       "90       0.0000006\n",
       "91         0.00001\n",
       "92               0\n",
       "93               0\n",
       "94       0.0000002\n",
       "95        0.000001\n",
       "96       0.0000008\n",
       "97       0.0000001\n",
       "98        0.000008\n",
       "99        0.000015\n",
       "100       0.000008\n",
       "101              0\n",
       "102              0\n",
       "103      0.0000002\n",
       "104              0\n",
       "105              0\n",
       "106        0.00015\n",
       "107      0.0000003\n",
       "108       0.000015\n",
       "109       0.000015\n",
       "110       0.000015\n",
       "111       0.000008\n",
       "112      0.0000006\n",
       "113              0\n",
       "114              0\n",
       "115     0.00000006\n",
       "116      0.0000044\n",
       "117     0.00000004\n",
       "118      0.0000004\n",
       "119     0.00000063\n",
       "120       0.000008\n",
       "121      0.0000014\n",
       "122      0.0000002\n",
       "123      0.0000032\n",
       "124      0.0000002\n",
       "125              0\n",
       "126     0.00000075\n",
       "127      0.0000012\n",
       "128      0.0000064\n",
       "129      0.0000044\n",
       "130     0.00000018\n",
       "131              0\n",
       "132     0.00000012\n",
       "133              0\n",
       "134     0.00000018\n",
       "135              0\n",
       "136     0.00000015\n",
       "137       0.000005\n",
       "138       0.000001\n",
       "139     0.00000001\n",
       "140     0.00000002\n",
       "141              0\n",
       "142      0.0000004\n",
       "143              0\n",
       "144     0.00000218\n",
       "145      0.0000011\n",
       "146      0.0000009\n",
       "147     0.00000014\n",
       "148              0\n",
       "149     0.00000089\n",
       "150      0.0000008\n",
       "151        0.00006\n",
       "152       0.000006\n",
       "153        0.00001\n",
       "154        0.00001\n",
       "155     0.00000015\n",
       "156              0\n",
       "157              0\n",
       "158     0.00000035\n",
       "159     0.00000024\n",
       "160     0.00000014\n",
       "161      0.0000032\n",
       "162              0\n",
       "163     0.00000027\n",
       "164              0\n",
       "165       0.000006\n",
       "166        0.00001\n",
       "167       0.000006\n",
       "168       0.000006\n",
       "169       0.000006\n",
       "170       0.000015\n",
       "171      0.0000012\n",
       "172              0\n",
       "173     0.00000015\n",
       "174      0.0000045\n",
       "175      0.0000034\n",
       "176     0.00000045\n",
       "177       0.000004\n",
       "178       0.000004\n",
       "179       0.000004\n",
       "180       0.000004\n",
       "181     0.00000225\n",
       "182     0.00000225\n",
       "183       0.000015\n",
       "184       0.000015\n",
       "185       0.000015\n",
       "186      0.0000001\n",
       "187     0.00000004\n",
       "188              0\n",
       "189      0.0000001\n",
       "190      0.0000003\n",
       "191        0.00001\n",
       "192        0.00001\n",
       "193     0.00000015\n",
       "194      0.0000005\n",
       "195       0.000003\n",
       "196     0.00000015\n",
       "197              0\n",
       "198     0.00000002\n",
       "199              0\n",
       "200     0.00000001\n",
       "201      0.0000012\n",
       "202              0\n",
       "203    0.000000049\n",
       "204              0\n",
       "205     0.00000039\n",
       "206      0.0000006\n",
       "207     0.00000075\n",
       "208        0.00006\n",
       "209        0.00006\n",
       "210      0.0000044\n",
       "211      0.0000044\n",
       "212      0.0000001\n",
       "213        0.00001\n",
       "214      0.0000006\n",
       "215              0\n",
       "216      0.0000002\n",
       "217      0.0000008\n",
       "218              0\n",
       "219     0.00000009\n",
       "220      0.0000003\n",
       "221      0.0000008\n",
       "222       0.000015\n",
       "223     0.00000005\n",
       "224      0.0000012\n",
       "225        0.00001\n",
       "226              0\n",
       "227       0.000002\n",
       "228      0.0000012\n",
       "229      0.0000002\n",
       "230       0.000001\n",
       "231              0\n",
       "232     0.00000003\n",
       "233      0.0000008\n",
       "234     0.00000028\n",
       "235     0.00000025\n",
       "236              0\n",
       "237     0.00000007\n",
       "238      0.0000006\n",
       "239      0.0000006\n",
       "240      0.0000003\n",
       "241       0.000006\n",
       "242              0\n",
       "243     0.00000006\n",
       "244       0.000003\n",
       "245      0.0000007\n",
       "246       0.000015\n",
       "247       0.000015\n",
       "248     0.00000148\n",
       "249      0.0000009\n",
       "250      0.0000009\n",
       "251              0\n",
       "252    0.000000054\n",
       "253     0.00000004\n",
       "254    0.000000054\n",
       "255      0.0000001\n",
       "256      0.0000003\n",
       "257       0.000006\n",
       "258     0.00000012\n",
       "259      0.0000003\n",
       "260        0.00001\n",
       "261       0.000018\n",
       "262      0.0000002\n",
       "263       0.000015\n",
       "264     0.00000024\n",
       "265     0.00000075\n",
       "266     0.00000075\n",
       "267      0.0000012\n",
       "268     0.00000006\n",
       "269      0.0000004\n",
       "270      0.0000012\n",
       "271      0.0000005\n",
       "272       0.000005\n",
       "273        0.00003\n",
       "274       0.000015\n",
       "275       0.000015\n",
       "276      0.0000008\n",
       "277       0.000002\n",
       "278      0.0000015\n",
       "279     0.00000125\n",
       "280     0.00000125\n",
       "281       0.000075\n",
       "282       0.000075\n",
       "283       0.000015\n",
       "284       0.000015\n",
       "285      0.0000015\n",
       "286       0.000006\n",
       "287       0.000002\n",
       "288        0.00003\n",
       "289      0.0000006\n",
       "290      0.0000081\n",
       "291      0.0000006\n",
       "292     0.00000025\n",
       "293      0.0000002\n",
       "294     0.00000024\n",
       "295      0.0000015\n",
       "296       0.000024\n",
       "297       0.000024\n",
       "298       0.000024\n",
       "299       0.000024\n",
       "300      0.0000012\n",
       "301    0.000009375\n",
       "302             -1\n",
       "303       0.000002\n",
       "304        0.00003\n",
       "305      0.0000005\n",
       "306       0.000002\n",
       "307     0.00000019\n",
       "308    0.000001125\n",
       "309       0.000004\n",
       "310        0.00012\n",
       "311        0.00012\n",
       "312    0.000001125\n",
       "313       0.000024\n",
       "314       0.000024\n",
       "315    0.000001125\n",
       "316    0.000000065\n",
       "317      0.0000009\n",
       "318      0.0000015\n",
       "319      0.0000015\n",
       "320        0.00006\n",
       "321        0.00006\n",
       "Name: pricing_completion, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pricing_completion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context_length</th>\n",
       "      <th>pricing_prompt</th>\n",
       "      <th>pricing_completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>openrouter/auto</td>\n",
       "      <td>2000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>deepseek/deepseek-r1-distill-qwen-32b:free</td>\n",
       "      <td>16000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>nvidia/llama-3.1-nemotron-ultra-253b-v1:free</td>\n",
       "      <td>131072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>cognitivecomputations/dolphin3.0-r1-mistral-24...</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>nvidia/llama-3.3-nemotron-super-49b-v1:free</td>\n",
       "      <td>131072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>cognitivecomputations/dolphin3.0-mistral-24b:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>moonshotai/kimi-vl-a3b-thinking:free</td>\n",
       "      <td>131072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>agentica-org/deepcoder-14b-preview:free</td>\n",
       "      <td>96000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>arliai/qwq-32b-arliai-rpr-v1:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>meta-llama/llama-3.1-8b-instruct:free</td>\n",
       "      <td>131072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>meta-llama/llama-3.1-405b:free</td>\n",
       "      <td>64000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>qwen/qwen2.5-vl-72b-instruct:free</td>\n",
       "      <td>131072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>shisa-ai/shisa-v2-llama3.3-70b:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>google/gemma-3-12b-it:free</td>\n",
       "      <td>131072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>rekaai/reka-flash-3:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>mistralai/mistral-small-24b-instruct-2501:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>open-r1/olympiccoder-32b:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>meta-llama/llama-4-maverick:free</td>\n",
       "      <td>256000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>mistralai/mistral-nemo:free</td>\n",
       "      <td>128000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>meta-llama/llama-4-scout:free</td>\n",
       "      <td>512000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>google/gemma-3-4b-it:free</td>\n",
       "      <td>131072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>google/gemma-3-27b-it:free</td>\n",
       "      <td>96000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>mistralai/mistral-small-3.1-24b-instruct:free</td>\n",
       "      <td>96000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>mistralai/mistral-7b-instruct:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>featherless/qwerky-72b:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324:free</td>\n",
       "      <td>163840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>google/gemma-2-9b-it:free</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>qwen/qwen2.5-vl-32b-instruct:free</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>deepseek/deepseek-r1-distill-qwen-14b:free</td>\n",
       "      <td>64000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>google/gemini-2.5-pro-exp-03-25</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>bytedance-research/ui-tars-72b:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>allenai/molmo-7b-d:free</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>deepseek/deepseek-r1-zero:free</td>\n",
       "      <td>163840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>qwen/qwq-32b:free</td>\n",
       "      <td>40000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>deepseek/deepseek-v3-base:free</td>\n",
       "      <td>163840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>moonshotai/moonlight-16b-a3b-instruct:free</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>nousresearch/deephermes-3-llama-3-8b-preview:free</td>\n",
       "      <td>131072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>qwen/qwen2.5-vl-3b-instruct:free</td>\n",
       "      <td>64000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>google/gemini-flash-1.5-8b-exp</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>google/gemma-3-1b-it:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>google/gemini-2.0-flash-exp:free</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>qwen/qwen-2.5-72b-instruct:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qwen/qwen3-30b-a3b:free</td>\n",
       "      <td>40960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>thudm/glm-4-32b:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>meta-llama/llama-3.3-70b-instruct:free</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deepseek/deepseek-prover-v2:free</td>\n",
       "      <td>163840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>opengvlab/internvl3-2b:free</td>\n",
       "      <td>32000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qwen/qwen3-8b:free</td>\n",
       "      <td>40960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>opengvlab/internvl3-14b:free</td>\n",
       "      <td>32000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qwen/qwen3-1.7b:free</td>\n",
       "      <td>32000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>meta-llama/llama-3.2-11b-vision-instruct:free</td>\n",
       "      <td>131072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>qwen/qwen3-0.6b-04-28:free</td>\n",
       "      <td>32000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>microsoft/phi-4-reasoning:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>qwen/qwq-32b-preview:free</td>\n",
       "      <td>16384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>microsoft/phi-4-reasoning-plus:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>qwen/qwen3-4b:free</td>\n",
       "      <td>128000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>google/learnlm-1.5-pro-experimental:free</td>\n",
       "      <td>40960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>deepseek/deepseek-chat:free</td>\n",
       "      <td>163840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>meta-llama/llama-3.2-1b-instruct:free</td>\n",
       "      <td>131000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>thudm/glm-z1-32b:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>microsoft/mai-ds-r1:free</td>\n",
       "      <td>163840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>thudm/glm-4-9b:free</td>\n",
       "      <td>32000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>thudm/glm-z1-9b:free</td>\n",
       "      <td>32000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>qwen/qwen-2.5-7b-instruct:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>qwen/qwen-2.5-coder-32b-instruct:free</td>\n",
       "      <td>32768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qwen/qwen3-14b:free</td>\n",
       "      <td>40960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>meta-llama/llama-3.2-3b-instruct:free</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>deepseek/deepseek-r1-distill-llama-70b:free</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>qwen/qwen3-235b-a22b:free</td>\n",
       "      <td>40960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>deepseek/deepseek-r1:free</td>\n",
       "      <td>163840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>qwen/qwen3-32b:free</td>\n",
       "      <td>40960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>qwen/qwen-2.5-vl-7b-instruct:free</td>\n",
       "      <td>64000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tngtech/deepseek-r1t-chimera:free</td>\n",
       "      <td>163840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>meta-llama/llama-3.2-1b-instruct</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.000000005</td>\n",
       "      <td>0.00000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>meta-llama/llama-3.2-3b-instruct</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000001</td>\n",
       "      <td>0.00000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>liquid/lfm-7b</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000001</td>\n",
       "      <td>0.00000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>qwen/qwen2.5-coder-7b-instruct</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000001</td>\n",
       "      <td>0.00000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>meta-llama/llama-3.1-8b-instruct</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>google/gemma-3-4b-it</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>liquid/lfm-3b</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>meta-llama/llama-guard-3-8b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>sao10k/l3-lunaris-8b</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.00000002</td>\n",
       "      <td>0.00000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>nousresearch/hermes-2-pro-llama-3-8b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.000000025</td>\n",
       "      <td>0.00000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>mistralai/mistral-7b-instruct-v0.3</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.000000028</td>\n",
       "      <td>0.000000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>mistralai/mistral-7b-instruct</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.000000028</td>\n",
       "      <td>0.000000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>meta-llama/llama-3-8b-instruct</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.00000003</td>\n",
       "      <td>0.00000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>microsoft/phi-3.5-mini-128k-instruct</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000003</td>\n",
       "      <td>0.00000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>mistralai/mistral-nemo</td>\n",
       "      <td>98304</td>\n",
       "      <td>0.00000003</td>\n",
       "      <td>0.00000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>amazon/nova-micro-v1</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000000035</td>\n",
       "      <td>0.00000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qwen/qwen3-8b</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000000035</td>\n",
       "      <td>0.000000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>google/gemini-flash-1.5-8b</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0.0000000375</td>\n",
       "      <td>0.00000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>cohere/command-r7b-12-2024</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000000375</td>\n",
       "      <td>0.00000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>mistralai/ministral-3b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000004</td>\n",
       "      <td>0.00000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>deepseek/deepseek-r1-distill-llama-8b</td>\n",
       "      <td>32000</td>\n",
       "      <td>0.00000004</td>\n",
       "      <td>0.00000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>deepseek/deepseek-coder</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.00000004</td>\n",
       "      <td>0.00000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>meta-llama/llama-3.2-11b-vision-instruct</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.000000049</td>\n",
       "      <td>0.000000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>mistralai/mistral-small-3.1-24b-instruct</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.00000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>meta-llama/llama-guard-4-12b</td>\n",
       "      <td>163840</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.00000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>qwen/qwen-2.5-7b-instruct</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>microsoft/phi-4-multimodal-instruct</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>google/gemma-3-12b-it</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>qwen/qwen-turbo</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0.00000005</td>\n",
       "      <td>0.0000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>mistralai/mistral-small-24b-instruct-2501</td>\n",
       "      <td>28000</td>\n",
       "      <td>0.00000006</td>\n",
       "      <td>0.00000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>qwen/qwen-2.5-coder-32b-instruct</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000006</td>\n",
       "      <td>0.00000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>amazon/nova-lite-v1</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.00000006</td>\n",
       "      <td>0.00000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>gryphe/mythomax-l2-13b</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.000000065</td>\n",
       "      <td>0.000000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>microsoft/phi-4-reasoning-plus</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000007</td>\n",
       "      <td>0.00000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>microsoft/phi-4</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.00000007</td>\n",
       "      <td>0.00000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>qwen/qwen3-14b</td>\n",
       "      <td>40960</td>\n",
       "      <td>0.00000007</td>\n",
       "      <td>0.00000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>google/gemini-flash-1.5</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0.000000075</td>\n",
       "      <td>0.0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>google/gemini-2.0-flash-lite-001</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0.000000075</td>\n",
       "      <td>0.0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>meta-llama/llama-4-scout</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0.00000008</td>\n",
       "      <td>0.0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>mistralai/mixtral-8x7b-instruct</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000008</td>\n",
       "      <td>0.00000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>allenai/olmo-7b-instruct</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.00000008</td>\n",
       "      <td>0.00000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>qwen/qwq-32b-preview</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000009</td>\n",
       "      <td>0.00000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>meta-llama/llama-3.3-70b-instruct</td>\n",
       "      <td>131000</td>\n",
       "      <td>0.00000009</td>\n",
       "      <td>0.00000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>neversleep/llama-3-lumimaid-8b</td>\n",
       "      <td>24576</td>\n",
       "      <td>0.00000009375</td>\n",
       "      <td>0.00000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>neversleep/llama-3.1-lumimaid-8b</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000009375</td>\n",
       "      <td>0.00000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>neversleep/llama-3-lumimaid-8b:extended</td>\n",
       "      <td>24576</td>\n",
       "      <td>0.00000009375</td>\n",
       "      <td>0.00000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>mistralai/pixtral-12b</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>qwen/qwen3-32b</td>\n",
       "      <td>40960</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>openai/gpt-4.1-nano</td>\n",
       "      <td>1047576</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>mistralai/ministral-8b</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>google/gemini-2.0-flash-001</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>meta-llama/llama-3.1-70b-instruct</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.00000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>mistral/ministral-8b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>google/gemma-2-27b-it</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>microsoft/phi-3-medium-128k-instruct</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>microsoft/phi-3-mini-128k-instruct</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>google/gemma-3-27b-it</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qwen/qwen3-30b-a3b</td>\n",
       "      <td>40960</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>deepseek/deepseek-r1-distill-llama-70b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000001</td>\n",
       "      <td>0.0000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>mistralai/mistral-7b-instruct-v0.1</td>\n",
       "      <td>2824</td>\n",
       "      <td>0.00000011</td>\n",
       "      <td>0.00000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>qwen/qwen-2.5-72b-instruct</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000012</td>\n",
       "      <td>0.00000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>nvidia/llama-3.1-nemotron-70b-instruct</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000012</td>\n",
       "      <td>0.0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>deepseek/deepseek-r1-distill-qwen-32b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000012</td>\n",
       "      <td>0.00000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-70b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000012</td>\n",
       "      <td>0.0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>nvidia/llama-3.3-nemotron-super-49b-v1</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000013</td>\n",
       "      <td>0.0000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>qwen/qwen3-235b-a22b</td>\n",
       "      <td>40960</td>\n",
       "      <td>0.00000014</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>openai/gpt-4o-mini-search-preview</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>deepseek/deepseek-r1-distill-qwen-14b</td>\n",
       "      <td>64000</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.00000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>cohere/command-r-08-2024</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>openai/gpt-4o-mini</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>qwen/qwq-32b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>liquid/lfm-40b</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.00000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>google/gemini-2.5-flash-preview:thinking</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>google/gemini-2.5-flash-preview</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>openai/gpt-4o-mini-2024-07-18</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.00000015</td>\n",
       "      <td>0.0000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>meta-llama/llama-4-maverick</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0.00000017</td>\n",
       "      <td>0.0000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>scb10x/llama3.1-typhoon2-8b-instruct</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.00000018</td>\n",
       "      <td>0.00000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>deepseek/deepseek-r1-distill-qwen-1.5b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000018</td>\n",
       "      <td>0.00000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arcee-ai/spotlight</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000018</td>\n",
       "      <td>0.00000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>qwen/qwen-2.5-vl-7b-instruct</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>meta-llama/llama-guard-2-8b</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>mistralai/mistral-7b-instruct-v0.2</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ai21/jamba-1.6-mini</td>\n",
       "      <td>256000</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>aion-labs/aion-rp-llama-3.1-8b</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>perplexity/llama-3.1-sonar-small-128k-online</td>\n",
       "      <td>127072</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>minimax/minimax-01</td>\n",
       "      <td>1000192</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>mistralai/mistral-small</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>mistralai/mistral-saba</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000002</td>\n",
       "      <td>0.0000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>qwen/qwen-vl-plus</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.00000021</td>\n",
       "      <td>0.00000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>thudm/glm-4-32b</td>\n",
       "      <td>32000</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0.00000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>thudm/glm-z1-rumination-32b</td>\n",
       "      <td>32000</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0.00000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>thudm/glm-z1-32b</td>\n",
       "      <td>32000</td>\n",
       "      <td>0.00000024</td>\n",
       "      <td>0.00000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>inception/mercury-coder-small-beta</td>\n",
       "      <td>32000</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>mistralai/mistral-tiny</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.00000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>qwen/qwen2.5-vl-72b-instruct</td>\n",
       "      <td>32000</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.00000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>thedrummer/rocinante-12b</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.0000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>anthropic/claude-3-haiku:beta</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.00000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>mistralai/codestral-mamba</td>\n",
       "      <td>262144</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.00000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>anthropic/claude-3-haiku</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.00000025</td>\n",
       "      <td>0.00000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.0000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>meta-llama/llama-3-70b-instruct</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.0000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>mistralai/codestral-2501</td>\n",
       "      <td>262144</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.0000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324</td>\n",
       "      <td>163840</td>\n",
       "      <td>0.0000003</td>\n",
       "      <td>0.00000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>deepseek/deepseek-chat</td>\n",
       "      <td>163840</td>\n",
       "      <td>0.00000038</td>\n",
       "      <td>0.00000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>mistralai/mixtral-8x22b-instruct</td>\n",
       "      <td>65536</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0.0000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistralai/mistral-medium-3</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>openai/gpt-4.1-mini</td>\n",
       "      <td>1047576</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0.0000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>qwen/qwen-plus</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000004</td>\n",
       "      <td>0.0000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arcee-ai/arcee-blitz</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000045</td>\n",
       "      <td>0.00000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>thedrummer/unslopnemo-12b</td>\n",
       "      <td>32000</td>\n",
       "      <td>0.00000045</td>\n",
       "      <td>0.00000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>cohere/command-r</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>deepseek/deepseek-prover-v2</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.00000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>cohere/command-r-03-2024</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arcee-ai/virtuoso-medium-v2</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arcee-ai/coder-large</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>microsoft/wizardlm-2-8x22b</td>\n",
       "      <td>65536</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>thedrummer/skyfall-36b-v2</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>deepseek/deepseek-r1</td>\n",
       "      <td>163840</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.00000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>jondurbin/airoboros-l2-70b</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>openai/gpt-3.5-turbo</td>\n",
       "      <td>16385</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>openai/gpt-3.5-turbo-0125</td>\n",
       "      <td>16385</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>ai21/jamba-instruct</td>\n",
       "      <td>256000</td>\n",
       "      <td>0.0000005</td>\n",
       "      <td>0.0000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arcee-ai/caller-large</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000055</td>\n",
       "      <td>0.00000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>pygmalionai/mythalion-13b</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.0000005625</td>\n",
       "      <td>0.000001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>undi95/remm-slerp-l2-13b</td>\n",
       "      <td>6144</td>\n",
       "      <td>0.0000005625</td>\n",
       "      <td>0.000001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>qwen/qwen-2.5-vl-72b-instruct</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0.0000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>nousresearch/nous-hermes-2-mixtral-8x7b-dpo</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000006</td>\n",
       "      <td>0.0000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>sao10k/l3.3-euryale-70b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000007</td>\n",
       "      <td>0.0000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>aion-labs/aion-1.0-mini</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000007</td>\n",
       "      <td>0.0000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>sao10k/l3.1-euryale-70b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000007</td>\n",
       "      <td>0.0000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arcee-ai/virtuoso-large</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.00000075</td>\n",
       "      <td>0.0000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>neversleep/noromaid-20b</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.00000075</td>\n",
       "      <td>0.0000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-405b</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>meta-llama/llama-3.1-405b-instruct</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>aetherwiing/mn-starcannon-12b</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>anthropic/claude-3.5-haiku-20241022:beta</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>thedrummer/anubis-pro-105b-v1</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>anthropic/claude-3.5-haiku-20241022</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>alfredpros/codellama-7b-instruct-solidity</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>eleutherai/llemma_7b</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>sao10k/fimbulvetr-11b-v2</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>sophosympatheia/midnight-rose-70b</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>qwen/qwen-vl-max</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>amazon/nova-pro-v1</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>infermatic/mn-inferor-12b</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>undi95/toppy-m-7b</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>anthropic/claude-3.5-haiku:beta</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>anthropic/claude-3.5-haiku</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>nothingiisreal/mn-celeste-12b</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0000008</td>\n",
       "      <td>0.0000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>scb10x/llama3.1-typhoon2-70b-instruct</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.00000088</td>\n",
       "      <td>0.00000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>qwen/qwen2.5-vl-32b-instruct</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0.0000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>cognitivecomputations/dolphin-mixtral-8x22b</td>\n",
       "      <td>16000</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0.0000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arcee-ai/maestro-reasoning</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0.0000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>meta-llama/llama-2-70b-chat</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0.0000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>qwen/qwen-2-72b-instruct</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000009</td>\n",
       "      <td>0.0000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>perplexity/llama-3.1-sonar-large-128k-online</td>\n",
       "      <td>127072</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>openai/gpt-3.5-turbo-0613</td>\n",
       "      <td>4095</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>cohere/command</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>perplexity/sonar</td>\n",
       "      <td>127072</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>perplexity/sonar-reasoning</td>\n",
       "      <td>127000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>openai/gpt-3.5-turbo-1106</td>\n",
       "      <td>16385</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>openai/o4-mini-high</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>openai/o1-mini</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>openai/o1-mini-2024-09-12</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>openai/o3-mini</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>openai/o3-mini-high</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.0000011</td>\n",
       "      <td>0.0000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>mancer/weaver</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.000001125</td>\n",
       "      <td>0.000001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>meta-llama/llama-3.2-90b-vision-instruct</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.0000012</td>\n",
       "      <td>0.0000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>google/gemini-pro-1.5</td>\n",
       "      <td>2000000</td>\n",
       "      <td>0.00000125</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google/gemini-2.5-pro-preview</td>\n",
       "      <td>1048576</td>\n",
       "      <td>0.00000125</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>sao10k/l3-euryale-70b</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.00000148</td>\n",
       "      <td>0.00000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>neversleep/llama-3.1-lumimaid-70b</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0.00000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>openai/gpt-3.5-turbo-instruct</td>\n",
       "      <td>4095</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>anthracite-org/magnum-v4-72b</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0000015</td>\n",
       "      <td>0.00000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>qwen/qwen-max</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0000016</td>\n",
       "      <td>0.0000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>mistralai/pixtral-large-2411</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>mistralai/mistral-large</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>ai21/jamba-1.6-large</td>\n",
       "      <td>256000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>x-ai/grok-2-1212</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>openai/gpt-4.1</td>\n",
       "      <td>1047576</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>perplexity/sonar-deep-research</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>meta-llama/llama-3.1-405b</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>x-ai/grok-2-vision-1212</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>mistralai/mistral-large-2407</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>perplexity/sonar-reasoning-pro</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>perplexity/r1-1776</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>mistralai/mistral-large-2411</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>openai/gpt-4o-2024-11-20</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>openai/gpt-4o-2024-08-06</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>openai/gpt-4o</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>inflection/inflection-3-pi</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>openai/gpt-4o-search-preview</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>cohere/command-r-plus-08-2024</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>inflection/inflection-3-productivity</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>cohere/command-a</td>\n",
       "      <td>256000</td>\n",
       "      <td>0.0000025</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>all-hands/openhands-lm-32b-v0.1</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0000026</td>\n",
       "      <td>0.0000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>eva-unit-01/eva-qwen-2.5-32b</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0000026</td>\n",
       "      <td>0.0000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>mistralai/mistral-medium</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.00000275</td>\n",
       "      <td>0.0000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>anthracite-org/magnum-v2-72b</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>anthropic/claude-3-sonnet</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>anthropic/claude-3-sonnet:beta</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>openai/gpt-3.5-turbo-16k</td>\n",
       "      <td>16385</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>anthropic/claude-3.5-sonnet</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>anthropic/claude-3.5-sonnet:beta</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>cohere/command-r-plus-04-2024</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>cohere/command-r-plus</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:beta</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>perplexity/sonar-pro</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>01-ai/yi-large</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>anthropic/claude-3.5-sonnet-20240620:beta</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>anthropic/claude-3.5-sonnet-20240620</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>x-ai/grok-3-beta</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>anthropic/claude-3.7-sonnet</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>eva-unit-01/eva-llama-3.33-70b</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>neversleep/llama-3-lumimaid-70b</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>alpindale/magnum-72b</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>eva-unit-01/eva-qwen-2.5-72b</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>aion-labs/aion-1.0</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>raifle/sorcererlm-8x22b</td>\n",
       "      <td>16000</td>\n",
       "      <td>0.0000045</td>\n",
       "      <td>0.0000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>openai/gpt-4o-2024-05-13</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>openai/chatgpt-4o-latest</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>x-ai/grok-vision-beta</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>x-ai/grok-beta</td>\n",
       "      <td>131072</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>openai/gpt-4o:extended</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>alpindale/goliath-120b</td>\n",
       "      <td>6144</td>\n",
       "      <td>0.0000065625</td>\n",
       "      <td>0.000009375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>anthropic/claude-2.0:beta</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>anthropic/claude-2.1</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>anthropic/claude-2</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>anthropic/claude-2:beta</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>anthropic/claude-2.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>anthropic/claude-2.1:beta</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>openai/gpt-4-1106-preview</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>openai/o3</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>openai/gpt-4-turbo</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>openai/gpt-4-turbo-preview</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>openai/o1</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>anthropic/claude-3-opus</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>anthropic/claude-3-opus:beta</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>openai/o1-preview</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>openai/o1-preview-2024-09-12</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>openai/gpt-4-0314</td>\n",
       "      <td>8191</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>openai/gpt-4</td>\n",
       "      <td>8191</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>openai/gpt-4-32k-0314</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>openai/gpt-4-32k</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>openai/gpt-4.5-preview</td>\n",
       "      <td>128000</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.00015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>openai/o1-pro</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id  context_length pricing_prompt pricing_completion\n",
       "302                                    openrouter/auto         2000000             -1                 -1\n",
       "133         deepseek/deepseek-r1-distill-qwen-32b:free           16000              0                  0\n",
       "59        nvidia/llama-3.1-nemotron-ultra-253b-v1:free          131072              0                  0\n",
       "113  cognitivecomputations/dolphin3.0-r1-mistral-24...           32768              0                  0\n",
       "57         nvidia/llama-3.3-nemotron-super-49b-v1:free          131072              0                  0\n",
       "114  cognitivecomputations/dolphin3.0-mistral-24b:free           32768              0                  0\n",
       "54                moonshotai/kimi-vl-a3b-thinking:free          131072              0                  0\n",
       "53             agentica-org/deepcoder-14b-preview:free           96000              0                  0\n",
       "52                   arliai/qwq-32b-arliai-rpr-v1:free           32768              0                  0\n",
       "231              meta-llama/llama-3.1-8b-instruct:free          131072              0                  0\n",
       "226                     meta-llama/llama-3.1-405b:free           64000              0                  0\n",
       "125                  qwen/qwen2.5-vl-72b-instruct:free          131072              0                  0\n",
       "45                 shisa-ai/shisa-v2-llama3.3-70b:free           32768              0                  0\n",
       "87                          google/gemma-3-12b-it:free          131072              0                  0\n",
       "92                            rekaai/reka-flash-3:free           32768              0                  0\n",
       "131     mistralai/mistral-small-24b-instruct-2501:free           32768              0                  0\n",
       "81                       open-r1/olympiccoder-32b:free           32768              0                  0\n",
       "60                    meta-llama/llama-4-maverick:free          256000              0                  0\n",
       "236                        mistralai/mistral-nemo:free          128000              0                  0\n",
       "62                       meta-llama/llama-4-scout:free          512000              0                  0\n",
       "83                           google/gemma-3-4b-it:free          131072              0                  0\n",
       "93                          google/gemma-3-27b-it:free           96000              0                  0\n",
       "79       mistralai/mistral-small-3.1-24b-instruct:free           96000              0                  0\n",
       "251                 mistralai/mistral-7b-instruct:free           32768              0                  0\n",
       "77                         featherless/qwerky-72b:free           32768              0                  0\n",
       "75                 deepseek/deepseek-chat-v3-0324:free          163840              0                  0\n",
       "242                          google/gemma-2-9b-it:free            8192              0                  0\n",
       "73                   qwen/qwen2.5-vl-32b-instruct:free            8192              0                  0\n",
       "135         deepseek/deepseek-r1-distill-qwen-14b:free           64000              0                  0\n",
       "72                     google/gemini-2.5-pro-exp-03-25         1000000              0                  0\n",
       "70                 bytedance-research/ui-tars-72b:free           32768              0                  0\n",
       "69                             allenai/molmo-7b-d:free            4096              0                  0\n",
       "101                     deepseek/deepseek-r1-zero:free          163840              0                  0\n",
       "102                                  qwen/qwq-32b:free           40000              0                  0\n",
       "66                      deepseek/deepseek-v3-base:free          163840              0                  0\n",
       "104         moonshotai/moonlight-16b-a3b-instruct:free            8192              0                  0\n",
       "105  nousresearch/deephermes-3-llama-3-8b-preview:free          131072              0                  0\n",
       "71                    qwen/qwen2.5-vl-3b-instruct:free           64000              0                  0\n",
       "218                     google/gemini-flash-1.5-8b-exp         1000000              0                  0\n",
       "82                           google/gemma-3-1b-it:free           32768              0                  0\n",
       "156                   google/gemini-2.0-flash-exp:free         1048576              0                  0\n",
       "204                    qwen/qwen-2.5-72b-instruct:free           32768              0                  0\n",
       "21                             qwen/qwen3-30b-a3b:free           40960              0                  0\n",
       "38                                thudm/glm-4-32b:free           32768              0                  0\n",
       "157             meta-llama/llama-3.3-70b-instruct:free            8000              0                  0\n",
       "18                    deepseek/deepseek-prover-v2:free          163840              0                  0\n",
       "17                         opengvlab/internvl3-2b:free           32000              0                  0\n",
       "23                                  qwen/qwen3-8b:free           40960              0                  0\n",
       "16                        opengvlab/internvl3-14b:free           32000              0                  0\n",
       "14                                qwen/qwen3-1.7b:free           32000              0                  0\n",
       "202      meta-llama/llama-3.2-11b-vision-instruct:free          131072              0                  0\n",
       "12                          qwen/qwen3-0.6b-04-28:free           32000              0                  0\n",
       "11                      microsoft/phi-4-reasoning:free           32768              0                  0\n",
       "162                          qwen/qwq-32b-preview:free           16384              0                  0\n",
       "9                  microsoft/phi-4-reasoning-plus:free           32768              0                  0\n",
       "15                                  qwen/qwen3-4b:free          128000              0                  0\n",
       "164           google/learnlm-1.5-pro-experimental:free           40960              0                  0\n",
       "148                        deepseek/deepseek-chat:free          163840              0                  0\n",
       "199              meta-llama/llama-3.2-1b-instruct:free          131000              0                  0\n",
       "36                               thudm/glm-z1-32b:free           32768              0                  0\n",
       "35                            microsoft/mai-ds-r1:free          163840              0                  0\n",
       "34                                 thudm/glm-4-9b:free           32000              0                  0\n",
       "33                                thudm/glm-z1-9b:free           32000              0                  0\n",
       "188                     qwen/qwen-2.5-7b-instruct:free           32768              0                  0\n",
       "172              qwen/qwen-2.5-coder-32b-instruct:free           32768              0                  0\n",
       "25                                 qwen/qwen3-14b:free           40960              0                  0\n",
       "197              meta-llama/llama-3.2-3b-instruct:free           20000              0                  0\n",
       "141        deepseek/deepseek-r1-distill-llama-70b:free            8192              0                  0\n",
       "29                           qwen/qwen3-235b-a22b:free           40960              0                  0\n",
       "143                          deepseek/deepseek-r1:free          163840              0                  0\n",
       "27                                 qwen/qwen3-32b:free           40960              0                  0\n",
       "215                  qwen/qwen-2.5-vl-7b-instruct:free           64000              0                  0\n",
       "31                   tngtech/deepseek-r1t-chimera:free          163840              0                  0\n",
       "200                   meta-llama/llama-3.2-1b-instruct          131072    0.000000005         0.00000001\n",
       "198                   meta-llama/llama-3.2-3b-instruct          131072     0.00000001         0.00000002\n",
       "139                                      liquid/lfm-7b           32768     0.00000001         0.00000001\n",
       "46                      qwen/qwen2.5-coder-7b-instruct           32768     0.00000001         0.00000003\n",
       "243                               google/gemma-2-9b-it            8192     0.00000002         0.00000006\n",
       "232                   meta-llama/llama-3.1-8b-instruct           16384     0.00000002         0.00000003\n",
       "84                                google/gemma-3-4b-it          131072     0.00000002         0.00000004\n",
       "140                                      liquid/lfm-3b           32768     0.00000002         0.00000002\n",
       "115                        meta-llama/llama-guard-3-8b          131072     0.00000002         0.00000006\n",
       "223                               sao10k/l3-lunaris-8b            8192     0.00000002         0.00000005\n",
       "253               nousresearch/hermes-2-pro-llama-3-8b          131072    0.000000025         0.00000004\n",
       "254                 mistralai/mistral-7b-instruct-v0.3           32768    0.000000028        0.000000054\n",
       "252                      mistralai/mistral-7b-instruct           32768    0.000000028        0.000000054\n",
       "268                     meta-llama/llama-3-8b-instruct            8192     0.00000003         0.00000006\n",
       "219               microsoft/phi-3.5-mini-128k-instruct          131072     0.00000003         0.00000009\n",
       "237                             mistralai/mistral-nemo           98304     0.00000003         0.00000007\n",
       "160                               amazon/nova-micro-v1          128000    0.000000035         0.00000014\n",
       "24                                       qwen/qwen3-8b          128000    0.000000035        0.000000138\n",
       "193                         google/gemini-flash-1.5-8b         1000000   0.0000000375         0.00000015\n",
       "155                         cohere/command-r7b-12-2024          128000   0.0000000375         0.00000015\n",
       "187                             mistralai/ministral-3b          131072     0.00000004         0.00000004\n",
       "117              deepseek/deepseek-r1-distill-llama-8b           32000     0.00000004         0.00000004\n",
       "258                            deepseek/deepseek-coder          128000     0.00000004         0.00000012\n",
       "203           meta-llama/llama-3.2-11b-vision-instruct          131072    0.000000049        0.000000049\n",
       "80            mistralai/mistral-small-3.1-24b-instruct          131072     0.00000005         0.00000015\n",
       "20                        meta-llama/llama-guard-4-12b          163840     0.00000005         0.00000005\n",
       "189                          qwen/qwen-2.5-7b-instruct           32768     0.00000005          0.0000001\n",
       "97                 microsoft/phi-4-multimodal-instruct          131072     0.00000005          0.0000001\n",
       "88                               google/gemma-3-12b-it          131072     0.00000005          0.0000001\n",
       "124                                    qwen/qwen-turbo         1000000     0.00000005          0.0000002\n",
       "132          mistralai/mistral-small-24b-instruct-2501           28000     0.00000006         0.00000012\n",
       "173                   qwen/qwen-2.5-coder-32b-instruct           32768     0.00000006         0.00000015\n",
       "159                                amazon/nova-lite-v1          300000     0.00000006         0.00000024\n",
       "316                             gryphe/mythomax-l2-13b            4096    0.000000065        0.000000065\n",
       "10                      microsoft/phi-4-reasoning-plus           32768     0.00000007         0.00000035\n",
       "147                                    microsoft/phi-4           16384     0.00000007         0.00000014\n",
       "26                                      qwen/qwen3-14b           40960     0.00000007         0.00000024\n",
       "259                            google/gemini-flash-1.5         1000000    0.000000075          0.0000003\n",
       "107                   google/gemini-2.0-flash-lite-001         1048576    0.000000075          0.0000003\n",
       "63                            meta-llama/llama-4-scout         1048576     0.00000008          0.0000003\n",
       "294                    mistralai/mixtral-8x7b-instruct           32768     0.00000008         0.00000024\n",
       "264                           allenai/olmo-7b-instruct            2048     0.00000008         0.00000024\n",
       "163                               qwen/qwq-32b-preview           32768     0.00000009         0.00000027\n",
       "158                  meta-llama/llama-3.3-70b-instruct          131000     0.00000009         0.00000035\n",
       "266                     neversleep/llama-3-lumimaid-8b           24576  0.00000009375         0.00000075\n",
       "207                   neversleep/llama-3.1-lumimaid-8b           32768  0.00000009375         0.00000075\n",
       "265            neversleep/llama-3-lumimaid-8b:extended           24576  0.00000009375         0.00000075\n",
       "212                              mistralai/pixtral-12b           32768      0.0000001          0.0000001\n",
       "28                                      qwen/qwen3-32b           40960      0.0000001          0.0000003\n",
       "49                                 openai/gpt-4.1-nano         1047576      0.0000001          0.0000004\n",
       "186                             mistralai/ministral-8b          128000      0.0000001          0.0000001\n",
       "118                        google/gemini-2.0-flash-001         1000000      0.0000001          0.0000004\n",
       "234                  meta-llama/llama-3.1-70b-instruct          131072      0.0000001         0.00000028\n",
       "65                                mistral/ministral-8b          131072      0.0000001          0.0000001\n",
       "240                              google/gemma-2-27b-it            8192      0.0000001          0.0000003\n",
       "256               microsoft/phi-3-medium-128k-instruct          131072      0.0000001          0.0000003\n",
       "255                 microsoft/phi-3-mini-128k-instruct          128000      0.0000001          0.0000001\n",
       "94                               google/gemma-3-27b-it          131072      0.0000001          0.0000002\n",
       "22                                  qwen/qwen3-30b-a3b           40960      0.0000001          0.0000003\n",
       "142             deepseek/deepseek-r1-distill-llama-70b          131072      0.0000001          0.0000004\n",
       "307                 mistralai/mistral-7b-instruct-v0.1            2824     0.00000011         0.00000019\n",
       "205                         qwen/qwen-2.5-72b-instruct           32768     0.00000012         0.00000039\n",
       "190             nvidia/llama-3.1-nemotron-70b-instruct          131072     0.00000012          0.0000003\n",
       "134              deepseek/deepseek-r1-distill-qwen-32b          131072     0.00000012         0.00000018\n",
       "220                nousresearch/hermes-3-llama-3.1-70b          131072     0.00000012          0.0000003\n",
       "58              nvidia/llama-3.3-nemotron-super-49b-v1          131072     0.00000013          0.0000004\n",
       "30                                qwen/qwen3-235b-a22b           40960     0.00000014           0.000002\n",
       "90                   openai/gpt-4o-mini-search-preview          128000     0.00000015          0.0000006\n",
       "136              deepseek/deepseek-r1-distill-qwen-14b           64000     0.00000015         0.00000015\n",
       "214                           cohere/command-r-08-2024          128000     0.00000015          0.0000006\n",
       "238                                 openai/gpt-4o-mini          128000     0.00000015          0.0000006\n",
       "103                                       qwen/qwq-32b          131072     0.00000015          0.0000002\n",
       "196                                     liquid/lfm-40b           32768     0.00000015         0.00000015\n",
       "41            google/gemini-2.5-flash-preview:thinking         1048576     0.00000015          0.0000035\n",
       "40                     google/gemini-2.5-flash-preview         1048576     0.00000015          0.0000006\n",
       "239                      openai/gpt-4o-mini-2024-07-18          128000     0.00000015          0.0000006\n",
       "61                         meta-llama/llama-4-maverick         1048576     0.00000017          0.0000006\n",
       "67                scb10x/llama3.1-typhoon2-8b-instruct            8192     0.00000018         0.00000018\n",
       "130             deepseek/deepseek-r1-distill-qwen-1.5b          131072     0.00000018         0.00000018\n",
       "3                                   arcee-ai/spotlight          131072     0.00000018         0.00000018\n",
       "216                       qwen/qwen-2.5-vl-7b-instruct           32768      0.0000002          0.0000002\n",
       "262                        meta-llama/llama-guard-2-8b            8192      0.0000002          0.0000002\n",
       "293                 mistralai/mistral-7b-instruct-v0.2           32768      0.0000002          0.0000002\n",
       "86                                 ai21/jamba-1.6-mini          256000      0.0000002          0.0000004\n",
       "122                     aion-labs/aion-rp-llama-3.1-8b           32768      0.0000002          0.0000002\n",
       "229       perplexity/llama-3.1-sonar-small-128k-online          127072      0.0000002          0.0000002\n",
       "145                                 minimax/minimax-01         1000192      0.0000002          0.0000011\n",
       "291                            mistralai/mistral-small           32768      0.0000002          0.0000006\n",
       "112                             mistralai/mistral-saba           32768      0.0000002          0.0000006\n",
       "119                                  qwen/qwen-vl-plus            7500     0.00000021         0.00000063\n",
       "39                                     thudm/glm-4-32b           32000     0.00000024         0.00000024\n",
       "32                         thudm/glm-z1-rumination-32b           32000     0.00000024         0.00000024\n",
       "37                                    thudm/glm-z1-32b           32000     0.00000024         0.00000024\n",
       "13                  inception/mercury-coder-small-beta           32000     0.00000025           0.000001\n",
       "292                             mistralai/mistral-tiny           32768     0.00000025         0.00000025\n",
       "126                       qwen/qwen2.5-vl-72b-instruct           32000     0.00000025         0.00000075\n",
       "194                           thedrummer/rocinante-12b           32768     0.00000025          0.0000005\n",
       "279                      anthropic/claude-3-haiku:beta          200000     0.00000025         0.00000125\n",
       "235                          mistralai/codestral-mamba          262144     0.00000025         0.00000025\n",
       "280                           anthropic/claude-3-haiku          200000     0.00000025         0.00000125\n",
       "55                               x-ai/grok-3-mini-beta          131072      0.0000003          0.0000005\n",
       "269                    meta-llama/llama-3-70b-instruct            8192      0.0000003          0.0000004\n",
       "146                           mistralai/codestral-2501          262144      0.0000003          0.0000009\n",
       "76                      deepseek/deepseek-chat-v3-0324          163840      0.0000003         0.00000088\n",
       "149                             deepseek/deepseek-chat          163840     0.00000038         0.00000089\n",
       "270                   mistralai/mixtral-8x22b-instruct           65536      0.0000004          0.0000012\n",
       "0                           mistralai/mistral-medium-3          131072      0.0000004           0.000002\n",
       "48                                 openai/gpt-4.1-mini         1047576      0.0000004          0.0000016\n",
       "127                                     qwen/qwen-plus          131072      0.0000004          0.0000012\n",
       "8                                 arcee-ai/arcee-blitz           32768     0.00000045         0.00000075\n",
       "176                          thedrummer/unslopnemo-12b           32000     0.00000045         0.00000045\n",
       "278                                   cohere/command-r          128000      0.0000005          0.0000015\n",
       "19                         deepseek/deepseek-prover-v2          131072      0.0000005         0.00000218\n",
       "285                           cohere/command-r-03-2024          128000      0.0000005          0.0000015\n",
       "7                          arcee-ai/virtuoso-medium-v2          131072      0.0000005          0.0000008\n",
       "6                                 arcee-ai/coder-large           32768      0.0000005          0.0000008\n",
       "271                         microsoft/wizardlm-2-8x22b           65536      0.0000005          0.0000005\n",
       "96                           thedrummer/skyfall-36b-v2           32768      0.0000005          0.0000008\n",
       "144                               deepseek/deepseek-r1          163840      0.0000005         0.00000218\n",
       "305                         jondurbin/airoboros-l2-70b            4096      0.0000005          0.0000005\n",
       "318                               openai/gpt-3.5-turbo           16385      0.0000005          0.0000015\n",
       "319                          openai/gpt-3.5-turbo-0125           16385      0.0000005          0.0000015\n",
       "245                                ai21/jamba-instruct          256000      0.0000005          0.0000007\n",
       "2                                arcee-ai/caller-large           32768     0.00000055         0.00000085\n",
       "308                          pygmalionai/mythalion-13b            8192   0.0000005625        0.000001125\n",
       "315                           undi95/remm-slerp-l2-13b            6144   0.0000005625        0.000001125\n",
       "206                      qwen/qwen-2.5-vl-72b-instruct           32768      0.0000006          0.0000006\n",
       "289        nousresearch/nous-hermes-2-mixtral-8x7b-dpo           32768      0.0000006          0.0000006\n",
       "150                            sao10k/l3.3-euryale-70b          131072      0.0000007          0.0000008\n",
       "121                            aion-labs/aion-1.0-mini          131072      0.0000007          0.0000014\n",
       "217                            sao10k/l3.1-euryale-70b          131072      0.0000007          0.0000008\n",
       "5                              arcee-ai/virtuoso-large          131072     0.00000075          0.0000012\n",
       "295                            neversleep/noromaid-20b            8192     0.00000075          0.0000015\n",
       "221               nousresearch/hermes-3-llama-3.1-405b          131072      0.0000008          0.0000008\n",
       "233                 meta-llama/llama-3.1-405b-instruct           32768      0.0000008          0.0000008\n",
       "224                      aetherwiing/mn-starcannon-12b           16384      0.0000008          0.0000012\n",
       "179           anthropic/claude-3.5-haiku-20241022:beta          200000      0.0000008           0.000004\n",
       "95                       thedrummer/anubis-pro-105b-v1          131072      0.0000008           0.000001\n",
       "180                anthropic/claude-3.5-haiku-20241022          200000      0.0000008           0.000004\n",
       "51           alfredpros/codellama-7b-instruct-solidity            4096      0.0000008          0.0000012\n",
       "50                                eleutherai/llemma_7b            4096      0.0000008          0.0000012\n",
       "267                           sao10k/fimbulvetr-11b-v2            4096      0.0000008          0.0000012\n",
       "276                  sophosympatheia/midnight-rose-70b            4096      0.0000008          0.0000008\n",
       "123                                   qwen/qwen-vl-max            7500      0.0000008          0.0000032\n",
       "161                                 amazon/nova-pro-v1          300000      0.0000008          0.0000032\n",
       "171                          infermatic/mn-inferor-12b           16384      0.0000008          0.0000012\n",
       "300                                  undi95/toppy-m-7b            4096      0.0000008          0.0000012\n",
       "177                    anthropic/claude-3.5-haiku:beta          200000      0.0000008           0.000004\n",
       "178                         anthropic/claude-3.5-haiku          200000      0.0000008           0.000004\n",
       "228                      nothingiisreal/mn-celeste-12b           16384      0.0000008          0.0000012\n",
       "68               scb10x/llama3.1-typhoon2-70b-instruct            8192     0.00000088         0.00000088\n",
       "74                        qwen/qwen2.5-vl-32b-instruct          128000      0.0000009          0.0000009\n",
       "249        cognitivecomputations/dolphin-mixtral-8x22b           16000      0.0000009          0.0000009\n",
       "4                           arcee-ai/maestro-reasoning          131072      0.0000009          0.0000033\n",
       "317                        meta-llama/llama-2-70b-chat            4096      0.0000009          0.0000009\n",
       "250                           qwen/qwen-2-72b-instruct           32768      0.0000009          0.0000009\n",
       "230       perplexity/llama-3.1-sonar-large-128k-online          127072       0.000001           0.000001\n",
       "287                          openai/gpt-3.5-turbo-0613            4095       0.000001           0.000002\n",
       "277                                     cohere/command            4096       0.000001           0.000002\n",
       "138                                   perplexity/sonar          127072       0.000001           0.000001\n",
       "137                         perplexity/sonar-reasoning          127000       0.000001           0.000005\n",
       "303                          openai/gpt-3.5-turbo-1106           16385       0.000001           0.000002\n",
       "42                                 openai/o4-mini-high          200000      0.0000011          0.0000044\n",
       "210                                     openai/o1-mini          128000      0.0000011          0.0000044\n",
       "211                          openai/o1-mini-2024-09-12          128000      0.0000011          0.0000044\n",
       "44                                      openai/o4-mini          200000      0.0000011          0.0000044\n",
       "129                                     openai/o3-mini          200000      0.0000011          0.0000044\n",
       "116                                openai/o3-mini-high          200000      0.0000011          0.0000044\n",
       "312                                      mancer/weaver            8000    0.000001125        0.000001125\n",
       "201           meta-llama/llama-3.2-90b-vision-instruct          131072      0.0000012          0.0000012\n",
       "272                              google/gemini-pro-1.5         2000000     0.00000125           0.000005\n",
       "1                        google/gemini-2.5-pro-preview         1048576     0.00000125            0.00001\n",
       "248                              sao10k/l3-euryale-70b            8192     0.00000148         0.00000148\n",
       "181                  neversleep/llama-3.1-lumimaid-70b           16384      0.0000015         0.00000225\n",
       "306                      openai/gpt-3.5-turbo-instruct            4095      0.0000015           0.000002\n",
       "182                       anthracite-org/magnum-v4-72b           16384      0.0000015         0.00000225\n",
       "128                                      qwen/qwen-max           32768      0.0000016          0.0000064\n",
       "169                       mistralai/pixtral-large-2411          131072       0.000002           0.000006\n",
       "286                            mistralai/mistral-large          128000       0.000002           0.000006\n",
       "85                                ai21/jamba-1.6-large          256000       0.000002           0.000008\n",
       "154                                   x-ai/grok-2-1212          131072       0.000002            0.00001\n",
       "47                                      openai/gpt-4.1         1047576       0.000002           0.000008\n",
       "100                     perplexity/sonar-deep-research          128000       0.000002           0.000008\n",
       "227                          meta-llama/llama-3.1-405b           32768       0.000002           0.000002\n",
       "153                            x-ai/grok-2-vision-1212           32768       0.000002            0.00001\n",
       "168                       mistralai/mistral-large-2407          131072       0.000002           0.000006\n",
       "98                      perplexity/sonar-reasoning-pro          128000       0.000002           0.000008\n",
       "111                                 perplexity/r1-1776          128000       0.000002           0.000008\n",
       "167                       mistralai/mistral-large-2411          131072       0.000002           0.000006\n",
       "166                           openai/gpt-4o-2024-11-20          128000      0.0000025            0.00001\n",
       "225                           openai/gpt-4o-2024-08-06          128000      0.0000025            0.00001\n",
       "260                                      openai/gpt-4o          128000      0.0000025            0.00001\n",
       "192                         inflection/inflection-3-pi            8000      0.0000025            0.00001\n",
       "91                        openai/gpt-4o-search-preview          128000      0.0000025            0.00001\n",
       "213                      cohere/command-r-plus-08-2024          128000      0.0000025            0.00001\n",
       "191               inflection/inflection-3-productivity            8000      0.0000025            0.00001\n",
       "89                                    cohere/command-a          256000      0.0000025            0.00001\n",
       "64                     all-hands/openhands-lm-32b-v0.1           16384      0.0000026          0.0000034\n",
       "175                       eva-unit-01/eva-qwen-2.5-32b           16384      0.0000026          0.0000034\n",
       "290                           mistralai/mistral-medium           32768     0.00000275          0.0000081\n",
       "195                       anthracite-org/magnum-v2-72b           32768       0.000003           0.000003\n",
       "284                          anthropic/claude-3-sonnet          200000       0.000003           0.000015\n",
       "283                     anthropic/claude-3-sonnet:beta          200000       0.000003           0.000015\n",
       "309                           openai/gpt-3.5-turbo-16k           16385       0.000003           0.000004\n",
       "184                        anthropic/claude-3.5-sonnet          200000       0.000003           0.000015\n",
       "183                   anthropic/claude-3.5-sonnet:beta          200000       0.000003           0.000015\n",
       "275                      cohere/command-r-plus-04-2024          128000       0.000003           0.000015\n",
       "274                              cohere/command-r-plus          128000       0.000003           0.000015\n",
       "109               anthropic/claude-3.7-sonnet:thinking          200000       0.000003           0.000015\n",
       "110                   anthropic/claude-3.7-sonnet:beta          200000       0.000003           0.000015\n",
       "99                                perplexity/sonar-pro          200000       0.000003           0.000015\n",
       "244                                     01-ai/yi-large           32768       0.000003           0.000003\n",
       "246          anthropic/claude-3.5-sonnet-20240620:beta          200000       0.000003           0.000015\n",
       "247               anthropic/claude-3.5-sonnet-20240620          200000       0.000003           0.000015\n",
       "56                                    x-ai/grok-3-beta          131072       0.000003           0.000015\n",
       "108                        anthropic/claude-3.7-sonnet          200000       0.000003           0.000015\n",
       "152                     eva-unit-01/eva-llama-3.33-70b           16384       0.000004           0.000006\n",
       "257                    neversleep/llama-3-lumimaid-70b            8192       0.000004           0.000006\n",
       "241                               alpindale/magnum-72b           16384       0.000004           0.000006\n",
       "165                       eva-unit-01/eva-qwen-2.5-72b           16384       0.000004           0.000006\n",
       "120                                 aion-labs/aion-1.0          131072       0.000004           0.000008\n",
       "174                            raifle/sorcererlm-8x22b           16000      0.0000045          0.0000045\n",
       "263                           openai/gpt-4o-2024-05-13          128000       0.000005           0.000015\n",
       "222                           openai/chatgpt-4o-latest          128000       0.000005           0.000015\n",
       "170                              x-ai/grok-vision-beta            8192       0.000005           0.000015\n",
       "185                                     x-ai/grok-beta          131072       0.000005           0.000015\n",
       "261                             openai/gpt-4o:extended          128000       0.000006           0.000018\n",
       "301                             alpindale/goliath-120b            6144   0.0000065625        0.000009375\n",
       "313                          anthropic/claude-2.0:beta          100000       0.000008           0.000024\n",
       "297                               anthropic/claude-2.1          200000       0.000008           0.000024\n",
       "299                                 anthropic/claude-2          200000       0.000008           0.000024\n",
       "298                            anthropic/claude-2:beta          200000       0.000008           0.000024\n",
       "314                               anthropic/claude-2.0          100000       0.000008           0.000024\n",
       "296                          anthropic/claude-2.1:beta          200000       0.000008           0.000024\n",
       "304                          openai/gpt-4-1106-preview          128000        0.00001            0.00003\n",
       "43                                           openai/o3          200000        0.00001            0.00004\n",
       "273                                 openai/gpt-4-turbo          128000        0.00001            0.00003\n",
       "288                         openai/gpt-4-turbo-preview          128000        0.00001            0.00003\n",
       "151                                          openai/o1          200000       0.000015            0.00006\n",
       "282                            anthropic/claude-3-opus          200000       0.000015           0.000075\n",
       "281                       anthropic/claude-3-opus:beta          200000       0.000015           0.000075\n",
       "208                                  openai/o1-preview          128000       0.000015            0.00006\n",
       "209                       openai/o1-preview-2024-09-12          128000       0.000015            0.00006\n",
       "321                                  openai/gpt-4-0314            8191        0.00003            0.00006\n",
       "320                                       openai/gpt-4            8191        0.00003            0.00006\n",
       "311                              openai/gpt-4-32k-0314           32767        0.00006            0.00012\n",
       "310                                   openai/gpt-4-32k           32767        0.00006            0.00012\n",
       "106                             openai/gpt-4.5-preview          128000       0.000075            0.00015\n",
       "78                                       openai/o1-pro          200000        0.00015             0.0006"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"pricing_prompt\")[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='pricing_prompt', ylabel='pricing_completion'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[[\"pricing_prompt\", \"pricing_completion\"]].plot.scatter(\n",
    "    x=\"pricing_prompt\", y=\"pricing_completion\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/pandas/core/computation/expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/pandas/core/computation/expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpricing_completion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpricing_prompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/pandas/core/arraylike.py:210\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__truediv__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruediv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/pandas/core/series.py:6135\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   6134\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 6135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/pandas/core/base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:227\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    222\u001b[0m     ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:163\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 163\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "df[\"price_ratio\"] = df[\"pricing_completion\"] / df[\"pricing_prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"total_price\"] ="
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
